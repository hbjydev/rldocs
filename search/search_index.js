const local_index = {"config":{"indexing":"full","lang":["en","es","fr"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Table of Contents \u00b6 This document contains the section and subsection headers for Rocky Linux documentation, as well as links to articles in each section/subsection. The order of these sections is very important, but has not been finalized yet, so feel free to reorder as desired. OS Installation and Setup \u00b6 Classic Rocky Installation Rocky on Windows SubSystem For Linux (WSL) Rocky 8 Installation Rocky & WSL (rinse method) Rocky & WSL2 (virtualbox and docker) Development and Packaging \u00b6 Start Here Sourcing SRPM Rebranding Building Signing Deployment Setup Development Environment Rebranding HowTo Signing HowTo Build Troubleshooting Security \u00b6 Firewalls Network Security Cryptographic Security IPTABLES Networking Configuration SSH Keys SSL Keys Generating SSL Keys and LetsEncrypt Daemons/Servers \u00b6 Web Server FTP Content Management System Database Hardened Apache Web server VSFTPD DokuWiki MariaDB server Enabling Website Nextcloud ModSecurity Ossec-Hids RkHunter System Maintenance and Administration \u00b6 Data Security System Management and Debugging Managing Users and Groups Rsync over SSH Postfix RSnapshot Cron(tab) Lsyncd Bind Virtualization \u00b6 QEMU KVM","title":"Table of Contents"},{"location":"#table-of-contents","text":"This document contains the section and subsection headers for Rocky Linux documentation, as well as links to articles in each section/subsection. The order of these sections is very important, but has not been finalized yet, so feel free to reorder as desired.","title":"Table of Contents"},{"location":"#os-installation-and-setup","text":"Classic Rocky Installation Rocky on Windows SubSystem For Linux (WSL) Rocky 8 Installation Rocky & WSL (rinse method) Rocky & WSL2 (virtualbox and docker)","title":"OS Installation and Setup"},{"location":"#development-and-packaging","text":"Start Here Sourcing SRPM Rebranding Building Signing Deployment Setup Development Environment Rebranding HowTo Signing HowTo Build Troubleshooting","title":"Development and Packaging"},{"location":"#security","text":"Firewalls Network Security Cryptographic Security IPTABLES Networking Configuration SSH Keys SSL Keys Generating SSL Keys and LetsEncrypt","title":"Security"},{"location":"#daemonsservers","text":"Web Server FTP Content Management System Database Hardened Apache Web server VSFTPD DokuWiki MariaDB server Enabling Website Nextcloud ModSecurity Ossec-Hids RkHunter","title":"Daemons/Servers"},{"location":"#system-maintenance-and-administration","text":"Data Security System Management and Debugging Managing Users and Groups Rsync over SSH Postfix RSnapshot Cron(tab) Lsyncd Bind","title":"System Maintenance and Administration"},{"location":"#virtualization","text":"QEMU KVM","title":"Virtualization"},{"location":"guides/add_mirror_manager/","text":"Adding a public mirror to Rocky's mirror manager \u00b6 Rocky uses Fedora's Mirror Manager for organizing community mirrors. What You Need \u00b6 An account on https://accounts.rockylinux.org/ Creating a site \u00b6 Access Rocky's Mirror Manager here: https://mirrors.rockylinux.org/mirrormanager/ After a successful login, your profile will be on the top right. Select the drop down then click \"My sites\". A new page will load listing all of the sites under the account. The first time will be empty. Click \"Register a new site\". A new page will load with an important Export Compliance statement to read. Then fill out the following information: * \"Site Name\" * \"Site Password\" - used by report_mirrors script, you make this anything you want * \"Organization URL\" - Company/School/Organization URL e.g. https://rockylinux.org/ * \"Private\" - Checking this box hides this site from public use. * \"User active\" - Uncheck this box to temporarily disable this site, it will be removed from public listings. * \"All sites can pull from me?\" - Enable all mirror sites to pull from me without explicitly adding them to my list. * \"Comments for downstream siteadmins\" Upon clicking \"Submit\" you will be returned to the main mirror page. Configuring the site \u00b6 From the main mirror page, select the drop down then click \"My sites\". The account site page will load and the site should be listed. Click it to go to the Information Site. All of the options from the last section are listed again. At the bottom of the page are three new options: Admins, Hosts, and Delete site. Click on the \"Hosts [add]\". Create new host \u00b6 Fill out the following options that are appropriate for the site: * \"Host name\" - required: FQDN of server as seen by a public end user * \"User active\" - Uncheck this box to temporarily disable this host, it will be removed from public listings. * \"Country\" - required: 2-letter ISO country code * \"Bandwidth\" - required: integer megabits/sec, how much bandwidth this host can serve * \"Private\" - e.g. not available to the public, an internal private mirror * \"Internet2\" - on Internet2 * \"Internet2 clients\" - serves Internet2 clients, even if private * \"ASN - Autonomous System Number, used in BGP routing tables. * \"ASN Clients? - Serve all clients from the same ASN. Used for ISPs, companies, or schools, not personal networks. * \"Robot email\" - email address, will receive notice of upstream content updates * \"Comment\" - text, anything else you'd like a public end user to know about your mirror * \"Max connections\" - Maximum parallel download connections per client, suggested via metalinks. Click \"Create\" and it will redirect back to the Information site for the host. Update host \u00b6 At the bottom of the Information site, the option for \"Hosts\" should now display the host title next to it. Click on the name to load the host page. All of the same options from the previous step are listed again. There are new options at the bottom. \"Site-local Netblocks\": Netblocks are used to try to guide and end user to a site-specific mirror. For example, a university might list their netblocks, and the mirrorlist CGI would return the university-local mirror rather than a country-local mirror. Format is one of 18.0.0.0/255.0.0.0, 18.0.0.0/8, an IPv6 prefix/length, or a DNS hostname. Values must be public IP addresses (no RFC1918 private space addresses). \"Peer ASNs\": Peer ASNs are used to guide an end user on nearby networks to our mirror. For example, a university might list their peer ASNs, and the mirrorlist CGI would return the university-local mirror rather than a country-local mirror. You must be in the MirrorManager administrators group in order to create new entries here. \"Countries Allowed\": Some mirrors need to restrict themselves to serving only end users from their country. If you're one of these, list the 2-letter ISO code for the countries you will allow end users to be from. The mirrorlist CGI will honor this. \"Categories Carried\": Hosts carry categories of software. Example Fedora categories include Fedora and Fedora Archive. Click on the \"[add]\" link under \"Categories Carried\". Categories Carried \u00b6 For the Category, select \"Rocky Linux\" then \"Create\" to load the URL page. Then click \"[add]\" to load the \"Add host category URL\" page. There is one option. Repeat as needed for each of the mirrors supported protocols. \"URL\" - URL (rsync, https, http) pointing to the top directory Examples: * http://rocky.example.com * https://rocky.example.com * rsync://rocky.example.com Wrap up \u00b6 Once the information is filled out, the site should appear on the mirror list as soon as the next mirror refresh occurs. Sync your mirror from rsync://msync.rockylinux.org","title":"Adding a public mirror to Rocky's mirror manager"},{"location":"guides/add_mirror_manager/#adding-a-public-mirror-to-rockys-mirror-manager","text":"Rocky uses Fedora's Mirror Manager for organizing community mirrors.","title":"Adding a public mirror to Rocky's mirror manager"},{"location":"guides/add_mirror_manager/#what-you-need","text":"An account on https://accounts.rockylinux.org/","title":"What You Need"},{"location":"guides/add_mirror_manager/#creating-a-site","text":"Access Rocky's Mirror Manager here: https://mirrors.rockylinux.org/mirrormanager/ After a successful login, your profile will be on the top right. Select the drop down then click \"My sites\". A new page will load listing all of the sites under the account. The first time will be empty. Click \"Register a new site\". A new page will load with an important Export Compliance statement to read. Then fill out the following information: * \"Site Name\" * \"Site Password\" - used by report_mirrors script, you make this anything you want * \"Organization URL\" - Company/School/Organization URL e.g. https://rockylinux.org/ * \"Private\" - Checking this box hides this site from public use. * \"User active\" - Uncheck this box to temporarily disable this site, it will be removed from public listings. * \"All sites can pull from me?\" - Enable all mirror sites to pull from me without explicitly adding them to my list. * \"Comments for downstream siteadmins\" Upon clicking \"Submit\" you will be returned to the main mirror page.","title":"Creating a site"},{"location":"guides/add_mirror_manager/#configuring-the-site","text":"From the main mirror page, select the drop down then click \"My sites\". The account site page will load and the site should be listed. Click it to go to the Information Site. All of the options from the last section are listed again. At the bottom of the page are three new options: Admins, Hosts, and Delete site. Click on the \"Hosts [add]\".","title":"Configuring the site"},{"location":"guides/add_mirror_manager/#create-new-host","text":"Fill out the following options that are appropriate for the site: * \"Host name\" - required: FQDN of server as seen by a public end user * \"User active\" - Uncheck this box to temporarily disable this host, it will be removed from public listings. * \"Country\" - required: 2-letter ISO country code * \"Bandwidth\" - required: integer megabits/sec, how much bandwidth this host can serve * \"Private\" - e.g. not available to the public, an internal private mirror * \"Internet2\" - on Internet2 * \"Internet2 clients\" - serves Internet2 clients, even if private * \"ASN - Autonomous System Number, used in BGP routing tables. * \"ASN Clients? - Serve all clients from the same ASN. Used for ISPs, companies, or schools, not personal networks. * \"Robot email\" - email address, will receive notice of upstream content updates * \"Comment\" - text, anything else you'd like a public end user to know about your mirror * \"Max connections\" - Maximum parallel download connections per client, suggested via metalinks. Click \"Create\" and it will redirect back to the Information site for the host.","title":"Create new host"},{"location":"guides/add_mirror_manager/#update-host","text":"At the bottom of the Information site, the option for \"Hosts\" should now display the host title next to it. Click on the name to load the host page. All of the same options from the previous step are listed again. There are new options at the bottom. \"Site-local Netblocks\": Netblocks are used to try to guide and end user to a site-specific mirror. For example, a university might list their netblocks, and the mirrorlist CGI would return the university-local mirror rather than a country-local mirror. Format is one of 18.0.0.0/255.0.0.0, 18.0.0.0/8, an IPv6 prefix/length, or a DNS hostname. Values must be public IP addresses (no RFC1918 private space addresses). \"Peer ASNs\": Peer ASNs are used to guide an end user on nearby networks to our mirror. For example, a university might list their peer ASNs, and the mirrorlist CGI would return the university-local mirror rather than a country-local mirror. You must be in the MirrorManager administrators group in order to create new entries here. \"Countries Allowed\": Some mirrors need to restrict themselves to serving only end users from their country. If you're one of these, list the 2-letter ISO code for the countries you will allow end users to be from. The mirrorlist CGI will honor this. \"Categories Carried\": Hosts carry categories of software. Example Fedora categories include Fedora and Fedora Archive. Click on the \"[add]\" link under \"Categories Carried\".","title":"Update host"},{"location":"guides/add_mirror_manager/#categories-carried","text":"For the Category, select \"Rocky Linux\" then \"Create\" to load the URL page. Then click \"[add]\" to load the \"Add host category URL\" page. There is one option. Repeat as needed for each of the mirrors supported protocols. \"URL\" - URL (rsync, https, http) pointing to the top directory Examples: * http://rocky.example.com * https://rocky.example.com * rsync://rocky.example.com","title":"Categories Carried"},{"location":"guides/add_mirror_manager/#wrap-up","text":"Once the information is filled out, the site should appear on the mirror list as soon as the next mirror refresh occurs. Sync your mirror from rsync://msync.rockylinux.org","title":"Wrap up"},{"location":"guides/apache-sites-enabled/","text":"What You Need \u00b6 A server running Rocky Linux Knowledge of the command-line and text editors (This example uses vi , but can be adapted to your favorite editor.) If you'd like to learn about the vi text editor, here's a handy tutorial . Basic knowledge about installing and running web services Apache Web Server Multi-Site Setup \u00b6 Rocky Linux has many ways for you to set up a web site. This is just one method, using Apache, and is designed for use as a multi-site setup on a single server. While this method is designed for multi-site servers, it can also act as a base configuration for a single site server as well. History fact: This server setup appears to have started with Debian-based systems, but it is perfectly adaptable to any Linux OS running Apache. Install Apache \u00b6 You'll likely need other packages for your web site. For instance, a version of PHP will almost certainly be required, and maybe a database or other package will be needed as well. Installing PHP along with httpd will get you the latest version of both from the Rocky Linux repositories. Just remember that you may need modules as well, like perhaps php-bcmath or php-mysqlind. Your web application specifications should detail what is needed. These can be installed at any time. For now, we will install httpd and PHP, as those are almost a forgone conclusion: From the command-line run dnf install httpd php Add Extra Directories \u00b6 This method uses a couple of additional directories, but they don't currently exist on the system. We need to add two directories in /etc/httpd/ called \"sites-available\" and \"sites-enabled.\" From the command-line type mkdir /etc/httpd/sites-available and then mkdir /etc/httpd/sites-enabled We also need a directory where our sites are going to reside. This can be anywhere, but a good way to keep things organized is to create a directory called sub-domains. To keep things simple, put this in /var/www: mkdir /var/www/sub-domains/ Configuration \u00b6 We also need to add a line to the very bottom of the httpd.conf file. To do this, type vi /etc/httpd/conf/httpd.conf and go to the bottom of the file and add Include /etc/httpd/sites-enabled . Our actual configuration files will reside in /etc/httpd/sites-available and we will simply symlink to them in /etc/httpd/sites-enabled . Why do we do this? The reason here is pretty simple. Let's say you have 10 web sites all running on the same server on different IP addresses. Let's say that site B has some major updates and you have to make changes to the configuration for that site. Let's say too, that there is something wrong with the changes made, so when you restart httpd to read in the new changes, httpd doesn't start. Not only will the site you were working on not start, but neither will the rest of them. With this method, you can simply remove the symbolic link for the site that caused the failure, and restart httpd. It\u2019ll start working again, and you can go to work, trying to fix the broken site configuration. It sure takes the pressure off, knowing that the phone isn't going to ring with some angry customer, or an angry boss, because a service is off-line. The Site Configuration \u00b6 The other benefit of this method is that it allows us to fully specify everything outside of the default httpd.conf file. Let the default httpd.conf file load the defaults, and let your site configurations do everything else. Sweet, right? Plus again, it makes it very easy to trouble-shoot a broken site configuration. Now, let's say you have a web site that loads a wiki. You\u2019ll need a configuration file, which makes the site available via port 80. If you want to serve the website with SSL (and let's face it, we all should be doing that by now) then you need to add another (nearly identical) section to the same file, in order to enable port 443. You can take a look at that below in the Configuration https - Using An SSL Certificate section. So we first need to create this configuration file in sites-available : vi /etc/httpd/sites-available/com.wiki.www The configuration file configuration content would look something like this: <VirtualHost *:80> ServerName www.ourownwiki.com ServerAdmin username@rockylinux.org DocumentRoot /var/www/sub-domains/com.ourownwiki.www/html DirectoryIndex index.php index.htm index.html Alias /icons/ /var/www/icons/ # ScriptAlias /cgi-bin/ /var/www/sub-domains/com.ourownwiki.www/cgi-bin/ CustomLog \"/var/log/httpd/com.ourownwiki.www-access_log\" combined ErrorLog \"/var/log/httpd/com.ourownwiki.www-error_log\" <Directory /var/www/sub-domains/com.ourownwiki.www/html> Options -ExecCGI -Indexes AllowOverride None Order deny,allow Deny from all Allow from all Satisfy all </Directory> </VirtualHost> Once the file is created, we need to write (save) it with: shift : wq In our example above, the wiki site is loaded from the html sub-directory of com.ourownwiki.www , which means that the path we created in /var/www (above) will need some additional directories to satisfy this: mkdir -p /var/www/sub-domains/com.ourownwiki.www/html ... which will create the entire path with a single command. Next we would want to install our files to this directory that will actually run the web site. This could be something you made yourself, or an installable web application (in this case a wiki that you downloaded). Copy your files to the path above: cp -Rf wiki_source/* /var/www/sub-domains/com.ourownwiki.www/html/ Configuration https - Using an SSL Certificate \u00b6 As stated earlier, every web server created these days should be running with SSL (AKA the secure socket layer). This process starts by generating a private key and a CSR (which stands for certificate signing request) and then submitting the CSR to the certificate authority to purchase the SSL certificate. The process of generating these keys is somewhat extensive, so it has its own document. If you are new to generating keys for SSL, please take a look at: Generating SSL Keys You can also use this alternate process for using an SSL certificate from Let's Encrypt Placement of the SSL keys and Certificate's \u00b6 Now that you have your keys and certificate files, we need to place them logically in your file system on the web server. As we've seen with the example configuration file (above), we are placing our web files in /var/www/sub-domains/com.ourownwiki.www/html . We want to place our certificate and key files with the domain, but NOT in the document root, (which in this case is the html folder. We never want our certificates and keys to potentially be exposed to the web. That would be bad! Instead, we will create a new directory structure for our SSL files, outside of the document root: mkdir -p /var/www/sub-domains/com.ourownwiki.www/ssl/{ssl.key,ssl.crt,ssl.csr} If you are new to the \"tree\" syntax for making directories, what the above says is: \"Make a directory called ssl and then make three directories inside of that called ssl.key, ssl.crt, and ssl.csr.\" Just a note ahead of time: It is not necessary for the functioning of the web server that the CSR file be stored in the tree. If you ever need to re-issue the certificate from a different provider, etc., it's a good idea to have a stored copy of the CSR file. The question becomes where can you store it so that you will remember, and storing it within the tree of your web site is logical. Assuming that you have named your key, csr, and crt (certificate) files with the name of your site, and that you have them stored in /root , we will then copy them up to their respective locations that we just created: cp /root/com.wiki.www.key /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.key/ cp /root/com.wiki.www.csr /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.csr/ cp /root/com.wiki.www.crt /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.crt/ The Site Configuration - https \u00b6 Once you have generated your keys and purchased the SSL certificate, you can now move forward with the configuration of the web site using your new keys. For starters, let's break down the beginning of the configuration file. For instance, even though we still want to listen on port 80 (standard http) for incoming requests, we don't want any of those requests to actually go to port 80. We want them to go to port 443 (or http secure, better known as SSL). Our port 80 configuration section will be minimal: <VirtualHost *:80> ServerName www.ourownwiki.com ServerAdmin username@rockylinux.org Redirect / https://www.ourownwiki.com/ </VirtualHost> What this says is to send any regular web request to the https configuration instead. The apache \"Redirect\" option shown above, can be changed to \"Redirect permanent\" once all testing is complete and you can see that the site operates as you want it to. The \"Redirect\" we have chosen is a temporary redirect. A permanent redirect will be learned by search engines, and soon, any traffic to your site that comes from search engines will go only to port 443 (https) without hitting port 80 (http) first. Next, we need to define the https portion of the configuration file. The http section is duplicated here for clarity to show that this all happens in the same configuration file: <VirtualHost *:80> ServerName www.ourownwiki.com ServerAdmin username@rockylinux.org Redirect / https://www.ourownwiki.com/ </VirtualHost> <Virtual Host *:443> ServerName www.ourownwiki.com ServerAdmin username@rockylinux.org DocumentRoot /var/www/sub-domains/com.ourownwiki.www/html DirectoryIndex index.php index.htm index.html Alias /icons/ /var/www/icons/ # ScriptAlias /cgi-bin/ /var/www/sub-domains/com.ourownwiki.www/cgi-bin/ CustomLog \"/var/log/httpd/com.ourownwiki.www-access_log\" combined ErrorLog \"/var/log/httpd/com.ourownwiki.www-error_log\" SSLEngine on SSLProtocol all -SSLv2 -SSLv3 -TLSv1 SSLHonorCipherOrder on SSLCipherSuite EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384 :EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS SSLCertificateFile /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.crt/com.wiki.www.crt SSLCertificateKeyFile /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.key/com.wiki.www.key SSLCertificateChainFile /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.crt/your_providers_intermediate_certificate.crt <Directory /var/www/sub-domains/com.ourownwiki.www/html> Options -ExecCGI -Indexes AllowOverride None Order deny,allow Deny from all Allow from all Satisfy all </Directory> </VirtualHost> So, breaking down this configuration further, after the normal portions of the configuration and down to the SSL portion: SSLEngine on - simply says to use SSL SSLProtocol all -SSLv2 -SSLv3 -TLSv1 - says to use all available protocols, except those that have been found to have vulnerabilities. You should research periodically which protocols are currently acceptable for use. SSLHonorCipherOrder on - this deals with the next line that regarding the cipher suites, and says to deal with them in the order that they are given. This is another area where you should review the cipher suites that you want to include periodically SSLCertificateFile - is exactly what it sounds like, the newly purchased and applied certificate file and its location SSLCertificateKeyFile - the key you generated when creating your certificate signing request SSLCertificateChainFile - the certificate from your certificate provider, often referred to as the intermediate certificate. Next, take everything live and if there are no errors starting the web service and if going to your web site reveals https without errors, then you are ready to go. Taking It Live \u00b6 Remember that our httpd.conf file is including /etc/httpd/sites-enabled at the very end of the file, so when httpd restarts, it will load whatever configuration files are in that sites-enabled directory. Thing is, all of our configuration files are in sites-available . That's by design, so that we can easily remove things in the event that httpd fails to restart. So to enable our configuration file, we need to create a symbolic link to that file in sites-enabled and then start or restart the web service. To do this, we use this command: ln -s /etc/httpd/sites-available/com.ourownwiki.www /etc/httpd/sites-enabled/ This will create the link to the configuration file in sites-enabled , just like we want. Now just start httpd with systemctl start httpd . Or restart it if it\u2019s already running: systemctl restart httpd , and assuming the web service restarts, you can now go and do some testing on your new site.","title":"Apache Web Server Multi-Site Setup"},{"location":"guides/apache-sites-enabled/#what-you-need","text":"A server running Rocky Linux Knowledge of the command-line and text editors (This example uses vi , but can be adapted to your favorite editor.) If you'd like to learn about the vi text editor, here's a handy tutorial . Basic knowledge about installing and running web services","title":"What You Need"},{"location":"guides/apache-sites-enabled/#apache-web-server-multi-site-setup","text":"Rocky Linux has many ways for you to set up a web site. This is just one method, using Apache, and is designed for use as a multi-site setup on a single server. While this method is designed for multi-site servers, it can also act as a base configuration for a single site server as well. History fact: This server setup appears to have started with Debian-based systems, but it is perfectly adaptable to any Linux OS running Apache.","title":"Apache Web Server Multi-Site Setup"},{"location":"guides/apache-sites-enabled/#install-apache","text":"You'll likely need other packages for your web site. For instance, a version of PHP will almost certainly be required, and maybe a database or other package will be needed as well. Installing PHP along with httpd will get you the latest version of both from the Rocky Linux repositories. Just remember that you may need modules as well, like perhaps php-bcmath or php-mysqlind. Your web application specifications should detail what is needed. These can be installed at any time. For now, we will install httpd and PHP, as those are almost a forgone conclusion: From the command-line run dnf install httpd php","title":"Install Apache"},{"location":"guides/apache-sites-enabled/#add-extra-directories","text":"This method uses a couple of additional directories, but they don't currently exist on the system. We need to add two directories in /etc/httpd/ called \"sites-available\" and \"sites-enabled.\" From the command-line type mkdir /etc/httpd/sites-available and then mkdir /etc/httpd/sites-enabled We also need a directory where our sites are going to reside. This can be anywhere, but a good way to keep things organized is to create a directory called sub-domains. To keep things simple, put this in /var/www: mkdir /var/www/sub-domains/","title":"Add Extra Directories"},{"location":"guides/apache-sites-enabled/#configuration","text":"We also need to add a line to the very bottom of the httpd.conf file. To do this, type vi /etc/httpd/conf/httpd.conf and go to the bottom of the file and add Include /etc/httpd/sites-enabled . Our actual configuration files will reside in /etc/httpd/sites-available and we will simply symlink to them in /etc/httpd/sites-enabled . Why do we do this? The reason here is pretty simple. Let's say you have 10 web sites all running on the same server on different IP addresses. Let's say that site B has some major updates and you have to make changes to the configuration for that site. Let's say too, that there is something wrong with the changes made, so when you restart httpd to read in the new changes, httpd doesn't start. Not only will the site you were working on not start, but neither will the rest of them. With this method, you can simply remove the symbolic link for the site that caused the failure, and restart httpd. It\u2019ll start working again, and you can go to work, trying to fix the broken site configuration. It sure takes the pressure off, knowing that the phone isn't going to ring with some angry customer, or an angry boss, because a service is off-line.","title":"Configuration"},{"location":"guides/apache-sites-enabled/#the-site-configuration","text":"The other benefit of this method is that it allows us to fully specify everything outside of the default httpd.conf file. Let the default httpd.conf file load the defaults, and let your site configurations do everything else. Sweet, right? Plus again, it makes it very easy to trouble-shoot a broken site configuration. Now, let's say you have a web site that loads a wiki. You\u2019ll need a configuration file, which makes the site available via port 80. If you want to serve the website with SSL (and let's face it, we all should be doing that by now) then you need to add another (nearly identical) section to the same file, in order to enable port 443. You can take a look at that below in the Configuration https - Using An SSL Certificate section. So we first need to create this configuration file in sites-available : vi /etc/httpd/sites-available/com.wiki.www The configuration file configuration content would look something like this: <VirtualHost *:80> ServerName www.ourownwiki.com ServerAdmin username@rockylinux.org DocumentRoot /var/www/sub-domains/com.ourownwiki.www/html DirectoryIndex index.php index.htm index.html Alias /icons/ /var/www/icons/ # ScriptAlias /cgi-bin/ /var/www/sub-domains/com.ourownwiki.www/cgi-bin/ CustomLog \"/var/log/httpd/com.ourownwiki.www-access_log\" combined ErrorLog \"/var/log/httpd/com.ourownwiki.www-error_log\" <Directory /var/www/sub-domains/com.ourownwiki.www/html> Options -ExecCGI -Indexes AllowOverride None Order deny,allow Deny from all Allow from all Satisfy all </Directory> </VirtualHost> Once the file is created, we need to write (save) it with: shift : wq In our example above, the wiki site is loaded from the html sub-directory of com.ourownwiki.www , which means that the path we created in /var/www (above) will need some additional directories to satisfy this: mkdir -p /var/www/sub-domains/com.ourownwiki.www/html ... which will create the entire path with a single command. Next we would want to install our files to this directory that will actually run the web site. This could be something you made yourself, or an installable web application (in this case a wiki that you downloaded). Copy your files to the path above: cp -Rf wiki_source/* /var/www/sub-domains/com.ourownwiki.www/html/","title":"The Site Configuration"},{"location":"guides/apache-sites-enabled/#configuration-https-using-an-ssl-certificate","text":"As stated earlier, every web server created these days should be running with SSL (AKA the secure socket layer). This process starts by generating a private key and a CSR (which stands for certificate signing request) and then submitting the CSR to the certificate authority to purchase the SSL certificate. The process of generating these keys is somewhat extensive, so it has its own document. If you are new to generating keys for SSL, please take a look at: Generating SSL Keys You can also use this alternate process for using an SSL certificate from Let's Encrypt","title":"Configuration https - Using an SSL Certificate"},{"location":"guides/apache-sites-enabled/#placement-of-the-ssl-keys-and-certificates","text":"Now that you have your keys and certificate files, we need to place them logically in your file system on the web server. As we've seen with the example configuration file (above), we are placing our web files in /var/www/sub-domains/com.ourownwiki.www/html . We want to place our certificate and key files with the domain, but NOT in the document root, (which in this case is the html folder. We never want our certificates and keys to potentially be exposed to the web. That would be bad! Instead, we will create a new directory structure for our SSL files, outside of the document root: mkdir -p /var/www/sub-domains/com.ourownwiki.www/ssl/{ssl.key,ssl.crt,ssl.csr} If you are new to the \"tree\" syntax for making directories, what the above says is: \"Make a directory called ssl and then make three directories inside of that called ssl.key, ssl.crt, and ssl.csr.\" Just a note ahead of time: It is not necessary for the functioning of the web server that the CSR file be stored in the tree. If you ever need to re-issue the certificate from a different provider, etc., it's a good idea to have a stored copy of the CSR file. The question becomes where can you store it so that you will remember, and storing it within the tree of your web site is logical. Assuming that you have named your key, csr, and crt (certificate) files with the name of your site, and that you have them stored in /root , we will then copy them up to their respective locations that we just created: cp /root/com.wiki.www.key /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.key/ cp /root/com.wiki.www.csr /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.csr/ cp /root/com.wiki.www.crt /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.crt/","title":"Placement of the SSL keys and Certificate's"},{"location":"guides/apache-sites-enabled/#the-site-configuration-https","text":"Once you have generated your keys and purchased the SSL certificate, you can now move forward with the configuration of the web site using your new keys. For starters, let's break down the beginning of the configuration file. For instance, even though we still want to listen on port 80 (standard http) for incoming requests, we don't want any of those requests to actually go to port 80. We want them to go to port 443 (or http secure, better known as SSL). Our port 80 configuration section will be minimal: <VirtualHost *:80> ServerName www.ourownwiki.com ServerAdmin username@rockylinux.org Redirect / https://www.ourownwiki.com/ </VirtualHost> What this says is to send any regular web request to the https configuration instead. The apache \"Redirect\" option shown above, can be changed to \"Redirect permanent\" once all testing is complete and you can see that the site operates as you want it to. The \"Redirect\" we have chosen is a temporary redirect. A permanent redirect will be learned by search engines, and soon, any traffic to your site that comes from search engines will go only to port 443 (https) without hitting port 80 (http) first. Next, we need to define the https portion of the configuration file. The http section is duplicated here for clarity to show that this all happens in the same configuration file: <VirtualHost *:80> ServerName www.ourownwiki.com ServerAdmin username@rockylinux.org Redirect / https://www.ourownwiki.com/ </VirtualHost> <Virtual Host *:443> ServerName www.ourownwiki.com ServerAdmin username@rockylinux.org DocumentRoot /var/www/sub-domains/com.ourownwiki.www/html DirectoryIndex index.php index.htm index.html Alias /icons/ /var/www/icons/ # ScriptAlias /cgi-bin/ /var/www/sub-domains/com.ourownwiki.www/cgi-bin/ CustomLog \"/var/log/httpd/com.ourownwiki.www-access_log\" combined ErrorLog \"/var/log/httpd/com.ourownwiki.www-error_log\" SSLEngine on SSLProtocol all -SSLv2 -SSLv3 -TLSv1 SSLHonorCipherOrder on SSLCipherSuite EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384 :EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS SSLCertificateFile /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.crt/com.wiki.www.crt SSLCertificateKeyFile /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.key/com.wiki.www.key SSLCertificateChainFile /var/www/sub-domains/com.ourownwiki.www/ssl/ssl.crt/your_providers_intermediate_certificate.crt <Directory /var/www/sub-domains/com.ourownwiki.www/html> Options -ExecCGI -Indexes AllowOverride None Order deny,allow Deny from all Allow from all Satisfy all </Directory> </VirtualHost> So, breaking down this configuration further, after the normal portions of the configuration and down to the SSL portion: SSLEngine on - simply says to use SSL SSLProtocol all -SSLv2 -SSLv3 -TLSv1 - says to use all available protocols, except those that have been found to have vulnerabilities. You should research periodically which protocols are currently acceptable for use. SSLHonorCipherOrder on - this deals with the next line that regarding the cipher suites, and says to deal with them in the order that they are given. This is another area where you should review the cipher suites that you want to include periodically SSLCertificateFile - is exactly what it sounds like, the newly purchased and applied certificate file and its location SSLCertificateKeyFile - the key you generated when creating your certificate signing request SSLCertificateChainFile - the certificate from your certificate provider, often referred to as the intermediate certificate. Next, take everything live and if there are no errors starting the web service and if going to your web site reveals https without errors, then you are ready to go.","title":"The Site Configuration - https"},{"location":"guides/apache-sites-enabled/#taking-it-live","text":"Remember that our httpd.conf file is including /etc/httpd/sites-enabled at the very end of the file, so when httpd restarts, it will load whatever configuration files are in that sites-enabled directory. Thing is, all of our configuration files are in sites-available . That's by design, so that we can easily remove things in the event that httpd fails to restart. So to enable our configuration file, we need to create a symbolic link to that file in sites-enabled and then start or restart the web service. To do this, we use this command: ln -s /etc/httpd/sites-available/com.ourownwiki.www /etc/httpd/sites-enabled/ This will create the link to the configuration file in sites-enabled , just like we want. Now just start httpd with systemctl start httpd . Or restart it if it\u2019s already running: systemctl restart httpd , and assuming the web service restarts, you can now go and do some testing on your new site.","title":"Taking It Live"},{"location":"guides/basic_network_configuration/","text":"Rocky Linux - Networking configuration \u00b6 Prerequisites \u00b6 A certain amount of comfort operating from the command line Elevated or administrative privileges on the system (For example root, sudo and so on) Optional: familiarity with networking concepts Introduction \u00b6 Nowadays a computer without network connectivity is almost useless by itself. Whether you need to update the packages on a server or simply browse external Websites from your laptop - you will need network access! This guide aims to provide Rocky Linux users the basic knowledge on how to setup network connectivity on a Rocky Linux system. Using NetworkManager service \u00b6 At the user level, the networking stack is managed by NetworkManager . This tool runs as a service, and you can check its state with the following command: systemctl status NetworkManager Configuration files \u00b6 NetworkManager simply applies a configuration read from the files found in /etc/sysconfig/network-scripts/ifcfg-<IFACE_NAME> . Each network interface has its configuration file. The following example in the default configuration for a server: TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=none DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=no NAME=ens18 UUID=74c5ccee-c1f4-4f45-883f-fc4f765a8477 DEVICE=ens18 ONBOOT=yes IPADDR=192.168.0.1 PREFIX=24 GATEWAY=192.168.0.254 DNS1=192.168.0.254 DNS2=1.1.1.1 IPV6_DISABLED=yes The interface's name is ens18 so this file's name will be /etc/sysconfig/network-scripts/ifcfg-ens18 . Tips: There are a few ways or mechanisms by which systems can be assigned their IP configuration information. The 2 most common methods are - Static IP configuration scheme and Dynamic IP configuration scheme. The static IP configuration scheme is very popular on server class systems or networks. The dynamic IP approach is popular on home and office networks - or workstation and desktop class systems. The dynamic scheme usually needs something extra that is locally available that can supply proper IP configuration information to requesting workstations and desktops. This something is called the Dynamic Host Configuration Protocol (DHCP). Very often, home/office users don't have to worry or know about DHCP. This is because the somebody or something else is automagically taking care of that in the background. The only thing that the end user needs to do is to physically or wirelessly connect to the right network (and of course make sure that their systems are powered on)! IP Address \u00b6 In the previous /etc/sysconfig/network-scripts/ifcfg-ens18 listing, we see that the value of the BOOTPROTO parameter or key is set to none . This means that the system being configured is set to a static IP address scheme. If instead you want to configure the system to use a dynamic IP address scheme, you will have to change the value of the BOOTPROTO parameter from none to dhcp and also remove the IPADDR , PREFIX and GATEWAY lines. This is necessary because all of that information will be automaically obtained from any available DHCP server. To configure a static IP address attribution, set the following: IPADDR: the IP address to assign the interface PREFIX: the subnet mask in CIDR notation GATEWAY: the default gateway The ONBOOT parameter set to yes indicates that this connection will be activated during boot time. DNS resolution \u00b6 To get proper name resolution, the following parameters must be set: DNS1: IP address of the main nameserver DNS2: the secondary nameserver IP address Apply configuration \u00b6 To apply the network configuration, the nmcli command can be used: nmcli connection up ens18 To get the connection state, simply use: nmcli connection show You can also use the ifup and ifdown commands to bring the interface up and down (they are simple wrappers around nmcli ): ifup ens18 ifdown ens18 Checking configuration \u00b6 You can check that the configuration has been correctly applied with the following nmcli command: nmcli device show ens18 which should give you the following output: GENERAL.DEVICE: ens18 GENERAL.TYPE: ethernet GENERAL.HWADDR: 6E:86:C0:4E:15:DB GENERAL.MTU: 1500 GENERAL.STATE: 100 (connect\u00e9) GENERAL.CONNECTION: ens18 GENERAL.CON-PATH: /org/freedesktop/NetworkManager/ActiveConnection/1 WIRED-PROPERTIES.CARRIER: marche IP4.ADDRESS[1]: 192.168.0.1/24 IP4.GATEWAY: 192.168.0.254 IP4.ROUTE[1]: dst = 192.168.0.0/24, nh = 0.0.0.0, mt = 100 IP4.ROUTE[2]: dst = 0.0.0.0/0, nh = 192.168.0.254, mt = 100 IP4.DNS[1]: 192.168.0.254 IP4.DNS[2]: 1.1.1.1 IP6.GATEWAY: -- Using ip utility \u00b6 The ip command (provided by the iproute2 package) is a powerful tool to get information and configure the network of a modern Linux system such as Rocky Linux. In this example, we will assume the following parameters: interface name: ens19 ip address: 192.168.20.10 subnet mask: 24 gateway: 192.168.20.254 Get general information \u00b6 To see the detailed state of all interfaces, use ip a Pro tips: * use the -c flag to get a more readable coloured output: ip -c a . * ip accepts abbreviation so ip a , ip addr and ip address are equivalent Bring interface up or down \u00b6 To bring the ens19 interface up, simply use ip link set ens19 up and to bring it down, use ip link set ens19 down . Assign the interface a static address \u00b6 The command to be used is of the form: ip addr add <IP ADDRESS/CIDR> dev <IFACE NAME> To assign the above example parameters, we will use: ip a add 192.168.20.10/24 dev ens19 Then, checking the result with: ip a show dev ens19 will output: 3: ens19: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 4a:f2:f5:b6:aa:9f brd ff:ff:ff:ff:ff:ff inet 192.168.20.10/24 scope global ens19 valid_lft forever preferred_lft forever Our interface is up and configured, but is still lacking something! Using ifcfg utility \u00b6 To add the ens19 interface our new example IP address, use the following command: ifcfg ens19 add 192.168.20.10/24 To remove the address: ifcfg ens19 del 192.168.20.10/24 To completely disable IP addressing on this interface: ifcfg ens19 stop Note that this does not bring the interface down, it simply unassigns all IP addresses from the interface. Gateway configuration \u00b6 Now that the interface has an address, we have to set its default route, this can be done with: ip route add default via 192.168.20.254 dev ens19 The kernel routing table can be displayed with ip route or ip r for short. Checking network connectivity \u00b6 At this point, you should have your network interface up and properly configured. There are several ways to verify your connectivity. By pinging another IP address in the same network (we will use 192.168.20.42 as an example): ping -c3 192.168.20.42 This command will issue 3 pings (known as ICMP request) and wait for a reply. If everything went fine, you should get this output: PING 192.168.20.42 (192.168.20.42) 56(84) bytes of data. 64 bytes from 192.168.20.42: icmp_seq=1 ttl=64 time=1.07 ms 64 bytes from 192.168.20.42: icmp_seq=2 ttl=64 time=0.915 ms 64 bytes from 192.168.20.42: icmp_seq=3 ttl=64 time=0.850 ms --- 192.168.20.42 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 5ms rtt min/avg/max/mdev = 0.850/0.946/1.074/0.097 ms Then, to make sure your routing configuration is fine, try to ping a external host, such as this well known public DNS resolver: ping -c3 8.8.8.8 If your machine has several network interface and you want to make ICMP request via a specific interface, you can use the -I flag: ping -I ens19 -c3 192.168.20.42 It is now time to make sure that DNS resolution is working correctly. As a reminder, DNS resolution is a mechanism used to convert human friendly machine names into their IP addresses and the other way round (reverse DNS). If the /etc/resolv.conf file indicates a reachable DNS server, then the following should work: host rockylinux.org The result should be: rockylinux.org has address 76.76.21.21","title":"Rocky Linux - Networking configuration"},{"location":"guides/basic_network_configuration/#rocky-linux-networking-configuration","text":"","title":"Rocky Linux - Networking configuration"},{"location":"guides/basic_network_configuration/#prerequisites","text":"A certain amount of comfort operating from the command line Elevated or administrative privileges on the system (For example root, sudo and so on) Optional: familiarity with networking concepts","title":"Prerequisites"},{"location":"guides/basic_network_configuration/#introduction","text":"Nowadays a computer without network connectivity is almost useless by itself. Whether you need to update the packages on a server or simply browse external Websites from your laptop - you will need network access! This guide aims to provide Rocky Linux users the basic knowledge on how to setup network connectivity on a Rocky Linux system.","title":"Introduction"},{"location":"guides/basic_network_configuration/#using-networkmanager-service","text":"At the user level, the networking stack is managed by NetworkManager . This tool runs as a service, and you can check its state with the following command: systemctl status NetworkManager","title":"Using NetworkManager service"},{"location":"guides/basic_network_configuration/#configuration-files","text":"NetworkManager simply applies a configuration read from the files found in /etc/sysconfig/network-scripts/ifcfg-<IFACE_NAME> . Each network interface has its configuration file. The following example in the default configuration for a server: TYPE=Ethernet PROXY_METHOD=none BROWSER_ONLY=no BOOTPROTO=none DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=no NAME=ens18 UUID=74c5ccee-c1f4-4f45-883f-fc4f765a8477 DEVICE=ens18 ONBOOT=yes IPADDR=192.168.0.1 PREFIX=24 GATEWAY=192.168.0.254 DNS1=192.168.0.254 DNS2=1.1.1.1 IPV6_DISABLED=yes The interface's name is ens18 so this file's name will be /etc/sysconfig/network-scripts/ifcfg-ens18 . Tips: There are a few ways or mechanisms by which systems can be assigned their IP configuration information. The 2 most common methods are - Static IP configuration scheme and Dynamic IP configuration scheme. The static IP configuration scheme is very popular on server class systems or networks. The dynamic IP approach is popular on home and office networks - or workstation and desktop class systems. The dynamic scheme usually needs something extra that is locally available that can supply proper IP configuration information to requesting workstations and desktops. This something is called the Dynamic Host Configuration Protocol (DHCP). Very often, home/office users don't have to worry or know about DHCP. This is because the somebody or something else is automagically taking care of that in the background. The only thing that the end user needs to do is to physically or wirelessly connect to the right network (and of course make sure that their systems are powered on)!","title":"Configuration files"},{"location":"guides/basic_network_configuration/#ip-address","text":"In the previous /etc/sysconfig/network-scripts/ifcfg-ens18 listing, we see that the value of the BOOTPROTO parameter or key is set to none . This means that the system being configured is set to a static IP address scheme. If instead you want to configure the system to use a dynamic IP address scheme, you will have to change the value of the BOOTPROTO parameter from none to dhcp and also remove the IPADDR , PREFIX and GATEWAY lines. This is necessary because all of that information will be automaically obtained from any available DHCP server. To configure a static IP address attribution, set the following: IPADDR: the IP address to assign the interface PREFIX: the subnet mask in CIDR notation GATEWAY: the default gateway The ONBOOT parameter set to yes indicates that this connection will be activated during boot time.","title":"IP Address"},{"location":"guides/basic_network_configuration/#dns-resolution","text":"To get proper name resolution, the following parameters must be set: DNS1: IP address of the main nameserver DNS2: the secondary nameserver IP address","title":"DNS resolution"},{"location":"guides/basic_network_configuration/#apply-configuration","text":"To apply the network configuration, the nmcli command can be used: nmcli connection up ens18 To get the connection state, simply use: nmcli connection show You can also use the ifup and ifdown commands to bring the interface up and down (they are simple wrappers around nmcli ): ifup ens18 ifdown ens18","title":"Apply configuration"},{"location":"guides/basic_network_configuration/#checking-configuration","text":"You can check that the configuration has been correctly applied with the following nmcli command: nmcli device show ens18 which should give you the following output: GENERAL.DEVICE: ens18 GENERAL.TYPE: ethernet GENERAL.HWADDR: 6E:86:C0:4E:15:DB GENERAL.MTU: 1500 GENERAL.STATE: 100 (connect\u00e9) GENERAL.CONNECTION: ens18 GENERAL.CON-PATH: /org/freedesktop/NetworkManager/ActiveConnection/1 WIRED-PROPERTIES.CARRIER: marche IP4.ADDRESS[1]: 192.168.0.1/24 IP4.GATEWAY: 192.168.0.254 IP4.ROUTE[1]: dst = 192.168.0.0/24, nh = 0.0.0.0, mt = 100 IP4.ROUTE[2]: dst = 0.0.0.0/0, nh = 192.168.0.254, mt = 100 IP4.DNS[1]: 192.168.0.254 IP4.DNS[2]: 1.1.1.1 IP6.GATEWAY: --","title":"Checking configuration"},{"location":"guides/basic_network_configuration/#using-ip-utility","text":"The ip command (provided by the iproute2 package) is a powerful tool to get information and configure the network of a modern Linux system such as Rocky Linux. In this example, we will assume the following parameters: interface name: ens19 ip address: 192.168.20.10 subnet mask: 24 gateway: 192.168.20.254","title":"Using ip utility"},{"location":"guides/basic_network_configuration/#get-general-information","text":"To see the detailed state of all interfaces, use ip a Pro tips: * use the -c flag to get a more readable coloured output: ip -c a . * ip accepts abbreviation so ip a , ip addr and ip address are equivalent","title":"Get general information"},{"location":"guides/basic_network_configuration/#bring-interface-up-or-down","text":"To bring the ens19 interface up, simply use ip link set ens19 up and to bring it down, use ip link set ens19 down .","title":"Bring interface up or down"},{"location":"guides/basic_network_configuration/#assign-the-interface-a-static-address","text":"The command to be used is of the form: ip addr add <IP ADDRESS/CIDR> dev <IFACE NAME> To assign the above example parameters, we will use: ip a add 192.168.20.10/24 dev ens19 Then, checking the result with: ip a show dev ens19 will output: 3: ens19: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 4a:f2:f5:b6:aa:9f brd ff:ff:ff:ff:ff:ff inet 192.168.20.10/24 scope global ens19 valid_lft forever preferred_lft forever Our interface is up and configured, but is still lacking something!","title":"Assign the interface a static address"},{"location":"guides/basic_network_configuration/#using-ifcfg-utility","text":"To add the ens19 interface our new example IP address, use the following command: ifcfg ens19 add 192.168.20.10/24 To remove the address: ifcfg ens19 del 192.168.20.10/24 To completely disable IP addressing on this interface: ifcfg ens19 stop Note that this does not bring the interface down, it simply unassigns all IP addresses from the interface.","title":"Using ifcfg utility"},{"location":"guides/basic_network_configuration/#gateway-configuration","text":"Now that the interface has an address, we have to set its default route, this can be done with: ip route add default via 192.168.20.254 dev ens19 The kernel routing table can be displayed with ip route or ip r for short.","title":"Gateway configuration"},{"location":"guides/basic_network_configuration/#checking-network-connectivity","text":"At this point, you should have your network interface up and properly configured. There are several ways to verify your connectivity. By pinging another IP address in the same network (we will use 192.168.20.42 as an example): ping -c3 192.168.20.42 This command will issue 3 pings (known as ICMP request) and wait for a reply. If everything went fine, you should get this output: PING 192.168.20.42 (192.168.20.42) 56(84) bytes of data. 64 bytes from 192.168.20.42: icmp_seq=1 ttl=64 time=1.07 ms 64 bytes from 192.168.20.42: icmp_seq=2 ttl=64 time=0.915 ms 64 bytes from 192.168.20.42: icmp_seq=3 ttl=64 time=0.850 ms --- 192.168.20.42 ping statistics --- 3 packets transmitted, 3 received, 0% packet loss, time 5ms rtt min/avg/max/mdev = 0.850/0.946/1.074/0.097 ms Then, to make sure your routing configuration is fine, try to ping a external host, such as this well known public DNS resolver: ping -c3 8.8.8.8 If your machine has several network interface and you want to make ICMP request via a specific interface, you can use the -I flag: ping -I ens19 -c3 192.168.20.42 It is now time to make sure that DNS resolution is working correctly. As a reminder, DNS resolution is a mechanism used to convert human friendly machine names into their IP addresses and the other way round (reverse DNS). If the /etc/resolv.conf file indicates a reachable DNS server, then the following should work: host rockylinux.org The result should be: rockylinux.org has address 76.76.21.21","title":"Checking network connectivity"},{"location":"guides/cloud_server_using_nextcloud/","text":"Cloud Server Using Nextcloud \u00b6 Prerequisites And Assumptions \u00b6 Server running Rocky Linux (you can install Nextcloud on any Linux distribution, but this procedure will assume you're using Rocky). A high degree of comfort operating from the command line for installation and for configuration. Knowledge of a command-line editor. For this example, we are using vi , but you can use your favorite editor if you have one. While Nextcloud can be installed via a snap application, we will be downloading and installing the .zip file. We will be applying concepts from the Apache sites enabled document (linked to later in this document) for directory setup. We will also be using the mariadb-server hardening procedure (also linked to later) for database setup. Throughout this document we will assume that you are root, or that you can be by using sudo . We are using an example domain of \"yourdomain.com\" throughout this document. Introduction \u00b6 If you are in charge of a server environment for a large (or even a small) company, you may be tempted by cloud applications. Doing things in the cloud can free up your own resources for other things, but there is a downside to this, and that is the loss of control of your company's data. If the cloud application is compromised, so too may be your company's data. Taking the cloud back into your own environment is a way to reclaim security of your data at the expense of your time and energy. Sometimes, that is a cost worth paying. Nextcloud offers an open source cloud with security and flexibility in mind. Note that building a Nextcloud server is a good exercise, even if in the end you opt to take your cloud off-site. The following procedure deals with setting up Nextcloud on Rocky Linux. Installing And Configuring Repositories \u00b6 For this installation, we will require two repositories. We need to install the EPEL (Extra Packages for Enterprise Linux) and the Remi Repository for PHP 7.4 (version 7.3 or 7.4 is required and Rocky Linux provides 7.2.x). To install the EPEL run: dnf enable epel-release And then once installed, run an update to make sure you are at the very latest epel version: dnf update To install the Remi repository run: dnf install https://rpms.remirepo.net/enterprise/remi-release-8.rpm Run the following to see a list of php modules that can be enabled: dnf module list php Which should give you output like this: CentOS Linux 8 - AppStream Name Stream Profiles Summary php 7.2 [d] common [d], devel, minimal PHP scripting language php 7.3 common [d], devel, minimal PHP scripting language php 7.4 common [d], devel, minimal PHP scripting language Remi's Modular repository for Enterprise Linux 8 - x86_64 Name Stream Profiles Summary php remi-7.2 common [d], devel, minimal PHP scripting language php remi-7.3 common [d], devel, minimal PHP scripting language php remi-7.4 common [d], devel, minimal PHP scripting language php remi-8.0 common [d], devel, minimal PHP scripting language Hint: [d]efault, [e]nabled, [x]disabled, [i]nstalled We want to grab the newest PHP that Nextcloud is compatible with, which at this moment is 7.4, so we will enable that module by doing: dnf module enable php:remi-7.4 To see how this changes the output of the module list, run that command again and you will see the \"[e]\" next to remi-7.4: dnf module list php And the output again is the same except for this line: php remi-7.4 [e] common [d], devel, minimal PHP scripting language Installing Packages \u00b6 We need a lot of packages installed. Some of these may already be installed with your default Rocky Linux installation, but make sure by running the following command the following: dnf install httpd mariadb-server vim wget zip unzip libxml2 openssl php74-php php74-php-ctype php74-php-curl php74-php-gd php74-php-iconv php74-php-json php74-php-libxml php74-php-mbstring php74-php-openssl php74-php-posix php74-php-session php74-php-xml php74-php-zip php74-php-zlib php74-php-pdo php74-php-mysqlnd php74-php-intl php74-php-bcmath php74-php-gmp Configuring Packages And Directories \u00b6 Configuring apache \u00b6 Set apache to start on boot: systemctl enable httpd As noted earlier, we are using the \"Apache Sites Enabled\" procedure found here to configure Apache. Follow that guide to get the configuration directories setup and the httpd.conf file modified and then return to this document for the remaining steps. Create The Configuration \u00b6 For Nextcloud, we will need to create the following configuration file. vi /etc/httpd/sites-available/com.yourdomain.nextcloud Your configuration file should look something like this: <VirtualHost *:80> DocumentRoot /var/www/sub-domains/com.yourdomain.nextcloud/html/ ServerName nextcloud.yourdomain.com <Directory /var/www/sub-domains/com.yourdomain.nextcloud/html/> Require all granted AllowOverride All Options FollowSymLinks MultiViews <IfModule mod_dav.c> Dav off </IfModule> </Directory> </VirtualHost> Once done, save your changes (with SHIFT:wq! for vi ). Next, create a link to this file in /etc/httpd/sites-enabled: ln -s /etc/httpd/sites-available/com.yourdomain.nextcloud /etc/httpd/sites-enabled/ Creating The Directory \u00b6 As noted in the configuration above, the DocumentRoot needs to be created. This can be done by: mkdir -p /var/www/sub-domains/com.yourdomain.com/html This is where our Nextcloud instance will be installed. Configuring PHP \u00b6 Find your timezone. This can be done by: cd /usr/share/zoneinfo If you are in the Central timezone, for instance, you could either use \"US/Central\" or \"America/Chicago\" and either setting would work. Once you have identified your timezone, the next thing we need to do is populate the php.ini file with this information. To do this: vi /etc/opt/remi/php74/php.ini Then find this line: ;date.timezone = For our example timezone, we would put in either of the two options: date.timezone = \"America/Chicago\" OR date.timezone = \"US/Central\" Note that for the sake of keeping things the same, your timezone in the php.ini file should match up to your machine's timezone setting. You can find out what this is set to by doing the following: ls -al /etc/localtime Which should show you something like this, assuming you set your timezone when you installed Rocky Linux and are living in the Central time zone: /etc/localtime -> /usr/share/zoneinfo/America/Chicago Configuring mariadb-server \u00b6 Set mariadb-server to start on boot: systemctl enable mariadb And then start it: systemctl restart mariadb Again, as indicated earlier, we will be using the setup procedure for hardening mariadb-server found here for the initial configuration. Installing Nextcloud \u00b6 There are several ways to install Nextcloud which you can review on the web site under the manual for installation. What we will be using here is the server install .zip file. Get The Nextcloud .zip File And Unzip \u00b6 The next few steps assume that you are remotely connected to your Nextcloud server via ssh with a remote console open: Navigate to the Nextcloud web site Let your mouse hover over \"Get Nextcloud\" which will bring up a drop down menu. Click on \"Server Packages\". Right-click on \"Download Nextcloud\" and copy the link address. (the exact syntax of this is different browser to browser) In your remote console on the Nextcloud server, type \"wget\" and then a space and paste in what you just copied. You should get something like the following: wget https://download.nextcloud.com/server/releases/nextcloud-21.0.1.zip Once you hit enter, the download of the .zip file will start and will be completed fairly quickly. Once the download is complete, unzip the nextcloud zip file by using the following: unzip nextcloud-21.0.1.zip Copying Content And Changing Permissions \u00b6 After completing the unzip step, you should now have a new directory in /root called \"nextcloud.\" Change into this directory: cd nextcloud And either copy or move the content to our DocumentRoot : cp -Rf * /var/www/sub-domains/com.yourdomain.nextcloud/html/ OR mv * /var/www/sub-domains/com.yourdomain.nextcloud/html/ Now that everything is where it should be, the next step is to make sure that apache owns the directory. To do this: chown -Rf apache.apache /var/www/sub-domains/com.yourdomain.nextcloud/html For security reasons, we also want to move the \"data\" folder from inside to outside of the DocumentRoot . Do this with the following command: mv /var/www/sub-domains/com.yourdomain.nextcloud/html/data /var/www/sub-domains/com.yourdomain.nextcloud/ Configuring Nextcloud \u00b6 Now comes the fun! First, make sure that you have your services running. If you followed the above steps, they should already be running. We have had several steps between those initial service starts, so let's go ahead and restart them, just to be sure: systemctl restart httpd systemctl restart mariadb If everything restarts and there are no issues, then you are ready to move on. To do the initial configuration, we want to actually load the site in a web browser: http://nextcloud.yourdomain.com/ And you should see this screen: There are a couple of things that we want to do differently than the defaults that show up: At the top of the web page, where it says \"Create an admin account\", set the user and password. For the sake of this document, we are entering \"admin\" and setting a strong password. Remember to save this somewhere safe (like a password manager) so that you don't lose it! Even though you have typed into this field, don't hit 'Enter' until we have done all of the setup fields! Under the \"Storage & database\" section, change the \"Data folder\" location from the default document root, to where we moved the data folder earlier: /var/www/sub-domains/com.yourdomain.nextcloud/data Under the \"Configure the database\" section, change from \"SQLite\" to \"MySQL/MariaDB\" by clicking on that button. Type the MariaDB root user and password that you set earlier into the \"Database user\" and \"Database password\" fields In the \"Database name\" field, type \"nextcloud\" In the \"localhost\" field, type \"localhost:3306\" (3306 is the default mariadb connect port) Now cross your fingers and click \"Finish Setup\". The browser window will refresh for a bit and then usually not reload the site. Enter your URL in the browser window again and you should be confronted with the default first pages. Your administrative user is already (or should be) logged in at this point, and there are several informational pages designed to get you up to speed. The \"Dashboard\" is what users will see when they first login. The administrative user can now create other users, install other applications and many other tasks. The \"Nextcloud Manual.pdf\" is the user manual, so that users can get familiar with what is available. The administrative user should read through or at least scan the high points of the admin manual On the Nextcloud web site Next Steps \u00b6 At this point, don't forget that this is a server that you will be storing company data on. It's important to get it locked down with a firewall, get the backups setup , secure the site with an SSL , and any other duties that are required to keep your data safe. Conclusions \u00b6 A decision to take the company cloud in house is one that needs to be evaluated carefully. For those that decide that keeping company data locally is preferable over an external cloud host, Nextcloud is a good alternative.","title":"Cloud Server Using Nextcloud"},{"location":"guides/cloud_server_using_nextcloud/#cloud-server-using-nextcloud","text":"","title":"Cloud Server Using Nextcloud"},{"location":"guides/cloud_server_using_nextcloud/#prerequisites-and-assumptions","text":"Server running Rocky Linux (you can install Nextcloud on any Linux distribution, but this procedure will assume you're using Rocky). A high degree of comfort operating from the command line for installation and for configuration. Knowledge of a command-line editor. For this example, we are using vi , but you can use your favorite editor if you have one. While Nextcloud can be installed via a snap application, we will be downloading and installing the .zip file. We will be applying concepts from the Apache sites enabled document (linked to later in this document) for directory setup. We will also be using the mariadb-server hardening procedure (also linked to later) for database setup. Throughout this document we will assume that you are root, or that you can be by using sudo . We are using an example domain of \"yourdomain.com\" throughout this document.","title":"Prerequisites And Assumptions"},{"location":"guides/cloud_server_using_nextcloud/#introduction","text":"If you are in charge of a server environment for a large (or even a small) company, you may be tempted by cloud applications. Doing things in the cloud can free up your own resources for other things, but there is a downside to this, and that is the loss of control of your company's data. If the cloud application is compromised, so too may be your company's data. Taking the cloud back into your own environment is a way to reclaim security of your data at the expense of your time and energy. Sometimes, that is a cost worth paying. Nextcloud offers an open source cloud with security and flexibility in mind. Note that building a Nextcloud server is a good exercise, even if in the end you opt to take your cloud off-site. The following procedure deals with setting up Nextcloud on Rocky Linux.","title":"Introduction"},{"location":"guides/cloud_server_using_nextcloud/#installing-and-configuring-repositories","text":"For this installation, we will require two repositories. We need to install the EPEL (Extra Packages for Enterprise Linux) and the Remi Repository for PHP 7.4 (version 7.3 or 7.4 is required and Rocky Linux provides 7.2.x). To install the EPEL run: dnf enable epel-release And then once installed, run an update to make sure you are at the very latest epel version: dnf update To install the Remi repository run: dnf install https://rpms.remirepo.net/enterprise/remi-release-8.rpm Run the following to see a list of php modules that can be enabled: dnf module list php Which should give you output like this: CentOS Linux 8 - AppStream Name Stream Profiles Summary php 7.2 [d] common [d], devel, minimal PHP scripting language php 7.3 common [d], devel, minimal PHP scripting language php 7.4 common [d], devel, minimal PHP scripting language Remi's Modular repository for Enterprise Linux 8 - x86_64 Name Stream Profiles Summary php remi-7.2 common [d], devel, minimal PHP scripting language php remi-7.3 common [d], devel, minimal PHP scripting language php remi-7.4 common [d], devel, minimal PHP scripting language php remi-8.0 common [d], devel, minimal PHP scripting language Hint: [d]efault, [e]nabled, [x]disabled, [i]nstalled We want to grab the newest PHP that Nextcloud is compatible with, which at this moment is 7.4, so we will enable that module by doing: dnf module enable php:remi-7.4 To see how this changes the output of the module list, run that command again and you will see the \"[e]\" next to remi-7.4: dnf module list php And the output again is the same except for this line: php remi-7.4 [e] common [d], devel, minimal PHP scripting language","title":"Installing And Configuring Repositories"},{"location":"guides/cloud_server_using_nextcloud/#installing-packages","text":"We need a lot of packages installed. Some of these may already be installed with your default Rocky Linux installation, but make sure by running the following command the following: dnf install httpd mariadb-server vim wget zip unzip libxml2 openssl php74-php php74-php-ctype php74-php-curl php74-php-gd php74-php-iconv php74-php-json php74-php-libxml php74-php-mbstring php74-php-openssl php74-php-posix php74-php-session php74-php-xml php74-php-zip php74-php-zlib php74-php-pdo php74-php-mysqlnd php74-php-intl php74-php-bcmath php74-php-gmp","title":"Installing Packages"},{"location":"guides/cloud_server_using_nextcloud/#configuring-packages-and-directories","text":"","title":"Configuring Packages And Directories"},{"location":"guides/cloud_server_using_nextcloud/#configuring-apache","text":"Set apache to start on boot: systemctl enable httpd As noted earlier, we are using the \"Apache Sites Enabled\" procedure found here to configure Apache. Follow that guide to get the configuration directories setup and the httpd.conf file modified and then return to this document for the remaining steps.","title":"Configuring apache"},{"location":"guides/cloud_server_using_nextcloud/#create-the-configuration","text":"For Nextcloud, we will need to create the following configuration file. vi /etc/httpd/sites-available/com.yourdomain.nextcloud Your configuration file should look something like this: <VirtualHost *:80> DocumentRoot /var/www/sub-domains/com.yourdomain.nextcloud/html/ ServerName nextcloud.yourdomain.com <Directory /var/www/sub-domains/com.yourdomain.nextcloud/html/> Require all granted AllowOverride All Options FollowSymLinks MultiViews <IfModule mod_dav.c> Dav off </IfModule> </Directory> </VirtualHost> Once done, save your changes (with SHIFT:wq! for vi ). Next, create a link to this file in /etc/httpd/sites-enabled: ln -s /etc/httpd/sites-available/com.yourdomain.nextcloud /etc/httpd/sites-enabled/","title":"Create The Configuration"},{"location":"guides/cloud_server_using_nextcloud/#creating-the-directory","text":"As noted in the configuration above, the DocumentRoot needs to be created. This can be done by: mkdir -p /var/www/sub-domains/com.yourdomain.com/html This is where our Nextcloud instance will be installed.","title":"Creating The Directory"},{"location":"guides/cloud_server_using_nextcloud/#configuring-php","text":"Find your timezone. This can be done by: cd /usr/share/zoneinfo If you are in the Central timezone, for instance, you could either use \"US/Central\" or \"America/Chicago\" and either setting would work. Once you have identified your timezone, the next thing we need to do is populate the php.ini file with this information. To do this: vi /etc/opt/remi/php74/php.ini Then find this line: ;date.timezone = For our example timezone, we would put in either of the two options: date.timezone = \"America/Chicago\" OR date.timezone = \"US/Central\" Note that for the sake of keeping things the same, your timezone in the php.ini file should match up to your machine's timezone setting. You can find out what this is set to by doing the following: ls -al /etc/localtime Which should show you something like this, assuming you set your timezone when you installed Rocky Linux and are living in the Central time zone: /etc/localtime -> /usr/share/zoneinfo/America/Chicago","title":"Configuring PHP"},{"location":"guides/cloud_server_using_nextcloud/#configuring-mariadb-server","text":"Set mariadb-server to start on boot: systemctl enable mariadb And then start it: systemctl restart mariadb Again, as indicated earlier, we will be using the setup procedure for hardening mariadb-server found here for the initial configuration.","title":"Configuring mariadb-server"},{"location":"guides/cloud_server_using_nextcloud/#installing-nextcloud","text":"There are several ways to install Nextcloud which you can review on the web site under the manual for installation. What we will be using here is the server install .zip file.","title":"Installing Nextcloud"},{"location":"guides/cloud_server_using_nextcloud/#get-the-nextcloud-zip-file-and-unzip","text":"The next few steps assume that you are remotely connected to your Nextcloud server via ssh with a remote console open: Navigate to the Nextcloud web site Let your mouse hover over \"Get Nextcloud\" which will bring up a drop down menu. Click on \"Server Packages\". Right-click on \"Download Nextcloud\" and copy the link address. (the exact syntax of this is different browser to browser) In your remote console on the Nextcloud server, type \"wget\" and then a space and paste in what you just copied. You should get something like the following: wget https://download.nextcloud.com/server/releases/nextcloud-21.0.1.zip Once you hit enter, the download of the .zip file will start and will be completed fairly quickly. Once the download is complete, unzip the nextcloud zip file by using the following: unzip nextcloud-21.0.1.zip","title":"Get The Nextcloud .zip File And Unzip"},{"location":"guides/cloud_server_using_nextcloud/#copying-content-and-changing-permissions","text":"After completing the unzip step, you should now have a new directory in /root called \"nextcloud.\" Change into this directory: cd nextcloud And either copy or move the content to our DocumentRoot : cp -Rf * /var/www/sub-domains/com.yourdomain.nextcloud/html/ OR mv * /var/www/sub-domains/com.yourdomain.nextcloud/html/ Now that everything is where it should be, the next step is to make sure that apache owns the directory. To do this: chown -Rf apache.apache /var/www/sub-domains/com.yourdomain.nextcloud/html For security reasons, we also want to move the \"data\" folder from inside to outside of the DocumentRoot . Do this with the following command: mv /var/www/sub-domains/com.yourdomain.nextcloud/html/data /var/www/sub-domains/com.yourdomain.nextcloud/","title":"Copying Content And Changing Permissions"},{"location":"guides/cloud_server_using_nextcloud/#configuring-nextcloud","text":"Now comes the fun! First, make sure that you have your services running. If you followed the above steps, they should already be running. We have had several steps between those initial service starts, so let's go ahead and restart them, just to be sure: systemctl restart httpd systemctl restart mariadb If everything restarts and there are no issues, then you are ready to move on. To do the initial configuration, we want to actually load the site in a web browser: http://nextcloud.yourdomain.com/ And you should see this screen: There are a couple of things that we want to do differently than the defaults that show up: At the top of the web page, where it says \"Create an admin account\", set the user and password. For the sake of this document, we are entering \"admin\" and setting a strong password. Remember to save this somewhere safe (like a password manager) so that you don't lose it! Even though you have typed into this field, don't hit 'Enter' until we have done all of the setup fields! Under the \"Storage & database\" section, change the \"Data folder\" location from the default document root, to where we moved the data folder earlier: /var/www/sub-domains/com.yourdomain.nextcloud/data Under the \"Configure the database\" section, change from \"SQLite\" to \"MySQL/MariaDB\" by clicking on that button. Type the MariaDB root user and password that you set earlier into the \"Database user\" and \"Database password\" fields In the \"Database name\" field, type \"nextcloud\" In the \"localhost\" field, type \"localhost:3306\" (3306 is the default mariadb connect port) Now cross your fingers and click \"Finish Setup\". The browser window will refresh for a bit and then usually not reload the site. Enter your URL in the browser window again and you should be confronted with the default first pages. Your administrative user is already (or should be) logged in at this point, and there are several informational pages designed to get you up to speed. The \"Dashboard\" is what users will see when they first login. The administrative user can now create other users, install other applications and many other tasks. The \"Nextcloud Manual.pdf\" is the user manual, so that users can get familiar with what is available. The administrative user should read through or at least scan the high points of the admin manual On the Nextcloud web site","title":"Configuring Nextcloud"},{"location":"guides/cloud_server_using_nextcloud/#next-steps","text":"At this point, don't forget that this is a server that you will be storing company data on. It's important to get it locked down with a firewall, get the backups setup , secure the site with an SSL , and any other duties that are required to keep your data safe.","title":"Next Steps"},{"location":"guides/cloud_server_using_nextcloud/#conclusions","text":"A decision to take the company cloud in house is one that needs to be evaluated carefully. For those that decide that keeping company data locally is preferable over an external cloud host, Nextcloud is a good alternative.","title":"Conclusions"},{"location":"guides/cron_jobs_howto/","text":"Automating Processes with cron and crontab in Rocky Linux \u00b6 Prerequisites \u00b6 A machine running Rocky Linux Some comfort with modifying configuration files from the command-line using your favorite editor ( vi is used here) Assumptions \u00b6 Basic knowledge of bash, python, or other scripting/programming tools, and the desire to have a script run automatically That you are either running as the root user or have switched to root with sudo -s (You can run certain scripts in your own directories as your own user. In this case, switching to root is not necessary.) We assume that you're pretty cool. Introduction \u00b6 Linux provides the cron system, a time-based job scheduler, for automating processes. It's simple and yet quite powerful. Want a script or program to run every day at 5 PM? This is where you set that up. The crontab is essentially a list where users add their own automated tasks and jobs, and it has a number of options that can simplify things even further. This document will explore a number of these. It's a good refresher for those with some experience, new users add the cron system to their repertoire. Starting Easy - The cron Dot Directories \u00b6 Built into every Linux system including Rock Linux, for many versions now, the cron \"dot\" files help to automate processes quickly. These show up as directories that the cron system calls based on their naming conventions. In order to make something run during these auto-defined times, all you need to do is to copy your script file into the directory in question, and make sure it is executable. Here are the directories, and the times that they will run: /etc/cron.hourly/ - Scripts placed here will run at 1 minute past the hour, every hour of every day. /etc/cron.daily - Scripts placed here will run at 4:02 AM every day. /etc/cron.weekly - Scripts placed here will run at 4:22 AM on Sunday every week. /etc/cron.monthly - Scripts placed here will run at 4:42 AM on the first day of the month, every month. So, provided you're alright with just letting the system auto-run your scripts at one of these pre-determined times, then it makes it very easy to automate tasks. Create Your Own cron \u00b6 Of course, if the automated times don't work well for you for whatever reason, then you can create your own. In this example, we are assuming you are doing this as root. see Assumptions To do this, type the following: crontab -e This will pull up root user's crontab as it exists at this moment in your chosen editor, and may look something like this. Go ahead and read through this commented version, as it contains descriptions of each field that we will be using next: # Edit this file to introduce tasks to be run by cron. # # Each task to run has to be defined through a single line # indicating with different fields when the task will be run # and what command to run for the task # # To define the time you can provide concrete values for # minute (m), hour (h), day of month (dom), month (mon), # and day of week (dow) or use '*' in these fields (for 'any'). # # Notice that tasks will be started based on the cron's system # daemon's notion of time and timezones. # # Output of the crontab jobs (including errors) is sent through # email to the user the crontab file belongs to (unless redirected). # cron # For example, you can run a backup of all your user accounts # at 5 a.m every week with: # 0 5 * * 1 tar -zcf /var/backups/home.tgz /home/ # # For more information see the manual pages of crontab(5) and cron(8) # # m h dom mon dow command Notice that this particular crontab file has some of its own documentation built-in. That isn't always the case. When modifying a crontab on a container or minimalist operating system, the crontab will be an empty file, unless an entry has already been placed in it. Let's assume that we have a backup script that we want to run at 10 PM at night. The crontab uses a 24 hour clock, so this would be 22:00. Let's assume that the backup script is called \"backup\" and that it is currently in the /usr/local/sbin directory. Note: Remember that this script needs to also be executable ( chmod +x ) in order for the cron to run it. To add the job, we would: crontab -e \"crontab\" stands for \"cron table\" and the format of the file is, in fact, a loose table layout. Now that we are in the crontab, go to the bottom of the file and add your new entry. If you are using vi as your default system editor, then this is done with the following keys: Shift : $ Now that you are at the bottom of the file, insert a line and type a brief comment to describe what is going on with your entry. This is done by adding a \"#\" to the beginning of the line: # Backing up the system every night at 10PM Now hit enter. You should still be in the insert mode, so the next step is to add your entry. As shown in our empty commented crontab (above) this is m for minutes, h for hours, dom for day of month, mon for month, and dow for day of week. To run our backup script every day at 10:00, the entry would look like this: 00 22 * * * /usr/local/sbin/backup This says run the script at 10 PM, every day of the month, every month, and every day of the week. Obviously, this is a pretty simple example and things can get quite complicated when you need specifics. The @options for crontab \u00b6 As noted in the Starting Easy portion of this document above, scripts in the cron dot directories are run at very specific times. @options offer the ability to use more natural timing. The @options consist of: @hourly runs the script every hour of every day at 0 minutes past the hour. @daily runs the script every day at midnight. @weekly runs the script every week at midnight on Sunday. @monthly runs the script every month at midnight on the first day of the month. @yearly runs the script every year at midnight on the first day of January. @reboot runs the script on system startup only. For our backup script example, if we used use the @daily option to run the backup script at midnight, the entry would look like this: @daily /usr/local/sbin/backup More Complex Options \u00b6 So far, everything we have talked about has had pretty simple options, but what about the more complex task timings? Let's say that you want to run your backup script every 10 minutes during the day (probably not a very practical thing to do, but hey, this is an example!). To do this you would write: */10 * * * * /usr/local/sbin/backup What if you wanted to run the backup every 10 minutes, but only on Monday, Wednesday and Friday?: */10 * 1,3,5 * * /usr/local/sbin/backup What about every 10 minutes every day except Saturday and Sunday?: */10 * 1-5 * * /usr/local/sbin/backup In the table, the commas let you specify individual entries within a field, while the dash lets you specify a range of values within a field. This can happen in any of the fields, and on multiple fields at the same time. As you can see, things can get pretty complicated. When determining when to run a script, you need to take time and plan it out, particularly if the criteria are complex. Conclusions \u00b6 The cron/crontab system is a very powerful tool for the Rocky Linux desktop user or systems administrator. It can allow you to automate tasks and scripts so that you don't have to remember to run them manually. While the basics are pretty easy, you can get a lot more complex. For more information on crontab head up to the crontab manual page . You can also simply do a web search for \"crontab\" which will give you a wealth of results to help you fine-tune your crontab skills.","title":"Automating Processes with cron and crontab in Rocky Linux"},{"location":"guides/cron_jobs_howto/#automating-processes-with-cron-and-crontab-in-rocky-linux","text":"","title":"Automating Processes with cron and crontab in Rocky Linux"},{"location":"guides/cron_jobs_howto/#prerequisites","text":"A machine running Rocky Linux Some comfort with modifying configuration files from the command-line using your favorite editor ( vi is used here)","title":"Prerequisites"},{"location":"guides/cron_jobs_howto/#assumptions","text":"Basic knowledge of bash, python, or other scripting/programming tools, and the desire to have a script run automatically That you are either running as the root user or have switched to root with sudo -s (You can run certain scripts in your own directories as your own user. In this case, switching to root is not necessary.) We assume that you're pretty cool.","title":" Assumptions"},{"location":"guides/cron_jobs_howto/#introduction","text":"Linux provides the cron system, a time-based job scheduler, for automating processes. It's simple and yet quite powerful. Want a script or program to run every day at 5 PM? This is where you set that up. The crontab is essentially a list where users add their own automated tasks and jobs, and it has a number of options that can simplify things even further. This document will explore a number of these. It's a good refresher for those with some experience, new users add the cron system to their repertoire.","title":"Introduction"},{"location":"guides/cron_jobs_howto/#starting-easy-the-cron-dot-directories","text":"Built into every Linux system including Rock Linux, for many versions now, the cron \"dot\" files help to automate processes quickly. These show up as directories that the cron system calls based on their naming conventions. In order to make something run during these auto-defined times, all you need to do is to copy your script file into the directory in question, and make sure it is executable. Here are the directories, and the times that they will run: /etc/cron.hourly/ - Scripts placed here will run at 1 minute past the hour, every hour of every day. /etc/cron.daily - Scripts placed here will run at 4:02 AM every day. /etc/cron.weekly - Scripts placed here will run at 4:22 AM on Sunday every week. /etc/cron.monthly - Scripts placed here will run at 4:42 AM on the first day of the month, every month. So, provided you're alright with just letting the system auto-run your scripts at one of these pre-determined times, then it makes it very easy to automate tasks.","title":"Starting Easy - The cron Dot Directories"},{"location":"guides/cron_jobs_howto/#create-your-own-cron","text":"Of course, if the automated times don't work well for you for whatever reason, then you can create your own. In this example, we are assuming you are doing this as root. see Assumptions To do this, type the following: crontab -e This will pull up root user's crontab as it exists at this moment in your chosen editor, and may look something like this. Go ahead and read through this commented version, as it contains descriptions of each field that we will be using next: # Edit this file to introduce tasks to be run by cron. # # Each task to run has to be defined through a single line # indicating with different fields when the task will be run # and what command to run for the task # # To define the time you can provide concrete values for # minute (m), hour (h), day of month (dom), month (mon), # and day of week (dow) or use '*' in these fields (for 'any'). # # Notice that tasks will be started based on the cron's system # daemon's notion of time and timezones. # # Output of the crontab jobs (including errors) is sent through # email to the user the crontab file belongs to (unless redirected). # cron # For example, you can run a backup of all your user accounts # at 5 a.m every week with: # 0 5 * * 1 tar -zcf /var/backups/home.tgz /home/ # # For more information see the manual pages of crontab(5) and cron(8) # # m h dom mon dow command Notice that this particular crontab file has some of its own documentation built-in. That isn't always the case. When modifying a crontab on a container or minimalist operating system, the crontab will be an empty file, unless an entry has already been placed in it. Let's assume that we have a backup script that we want to run at 10 PM at night. The crontab uses a 24 hour clock, so this would be 22:00. Let's assume that the backup script is called \"backup\" and that it is currently in the /usr/local/sbin directory. Note: Remember that this script needs to also be executable ( chmod +x ) in order for the cron to run it. To add the job, we would: crontab -e \"crontab\" stands for \"cron table\" and the format of the file is, in fact, a loose table layout. Now that we are in the crontab, go to the bottom of the file and add your new entry. If you are using vi as your default system editor, then this is done with the following keys: Shift : $ Now that you are at the bottom of the file, insert a line and type a brief comment to describe what is going on with your entry. This is done by adding a \"#\" to the beginning of the line: # Backing up the system every night at 10PM Now hit enter. You should still be in the insert mode, so the next step is to add your entry. As shown in our empty commented crontab (above) this is m for minutes, h for hours, dom for day of month, mon for month, and dow for day of week. To run our backup script every day at 10:00, the entry would look like this: 00 22 * * * /usr/local/sbin/backup This says run the script at 10 PM, every day of the month, every month, and every day of the week. Obviously, this is a pretty simple example and things can get quite complicated when you need specifics.","title":"Create Your Own cron"},{"location":"guides/cron_jobs_howto/#the-options-for-crontab","text":"As noted in the Starting Easy portion of this document above, scripts in the cron dot directories are run at very specific times. @options offer the ability to use more natural timing. The @options consist of: @hourly runs the script every hour of every day at 0 minutes past the hour. @daily runs the script every day at midnight. @weekly runs the script every week at midnight on Sunday. @monthly runs the script every month at midnight on the first day of the month. @yearly runs the script every year at midnight on the first day of January. @reboot runs the script on system startup only. For our backup script example, if we used use the @daily option to run the backup script at midnight, the entry would look like this: @daily /usr/local/sbin/backup","title":"The @options for crontab"},{"location":"guides/cron_jobs_howto/#more-complex-options","text":"So far, everything we have talked about has had pretty simple options, but what about the more complex task timings? Let's say that you want to run your backup script every 10 minutes during the day (probably not a very practical thing to do, but hey, this is an example!). To do this you would write: */10 * * * * /usr/local/sbin/backup What if you wanted to run the backup every 10 minutes, but only on Monday, Wednesday and Friday?: */10 * 1,3,5 * * /usr/local/sbin/backup What about every 10 minutes every day except Saturday and Sunday?: */10 * 1-5 * * /usr/local/sbin/backup In the table, the commas let you specify individual entries within a field, while the dash lets you specify a range of values within a field. This can happen in any of the fields, and on multiple fields at the same time. As you can see, things can get pretty complicated. When determining when to run a script, you need to take time and plan it out, particularly if the criteria are complex.","title":"More Complex Options"},{"location":"guides/cron_jobs_howto/#conclusions","text":"The cron/crontab system is a very powerful tool for the Rocky Linux desktop user or systems administrator. It can allow you to automate tasks and scripts so that you don't have to remember to run them manually. While the basics are pretty easy, you can get a lot more complex. For more information on crontab head up to the crontab manual page . You can also simply do a web search for \"crontab\" which will give you a wealth of results to help you fine-tune your crontab skills.","title":"Conclusions"},{"location":"guides/database_mariadb-server/","text":"Database mariadb-server \u00b6 Prerequisites \u00b6 A Rocky Linux server Proficiency with a command-line editor (we are using vi in this example) A heavy comfort level with issuing commands from the command-line, viewing logs, and other general systems administrator duties An understanding of mariadb-server databases is helpful All commands are run as the root user or sudo Introduction \u00b6 The mariadb-server and it's client mariadb are the open source alternatives to mysql-server and mysql , and they share command structure. mariadb-server can be found running on many web servers, due to the popular Wordpress CMS which requires it. This database, though, has many other uses. If you'd like to use this along with other tools for hardening a web server, refer back to the Apache Hardened Web Server guide . Installing mariadb-server \u00b6 We need to install mariadb-server : dnf install mariadb-server Securing mariadb-server \u00b6 To strengthen the security of mariadb-server we need to run a script, but before we do, we need to enable and start mariadb: systemctl enable mariadb And then: systemctl start mariadb Next, run this command: mysql_secure_installation This brings up a dialog: NOTE: RUNNING ALL PARTS OF THIS SCRIPT IS RECOMMENDED FOR ALL MariaDB SERVERS IN PRODUCTION USE! PLEASE READ EACH STEP CAREFULLY! In order to log into MariaDB to secure it, we'll need the current password for the root user. If you've just installed MariaDB, and you haven't set the root password yet, the password will be blank, so you should just press enter here. Enter current password for root (enter for none): Since this is a brand new installation, there is no root password set. So just hit enter here. The next part of the dialog continues: OK, successfully used password, moving on... Setting the root password ensures that nobody can log into the MariaDB root user without the proper authorisation. Set root password? [Y/n] You absolutely do want to have a root password set. You'll want to figure out what this should be and document it in a password manager somewhere so that you can pull it up if necessary. Start by hitting 'Enter' to accept the default \"Y\". This will bring up the password dialog: New password: Re-enter new password: Enter your chosen password and then confirm it by entering it again. If this is successful, you will get the following dialog: Password updated successfully! Reloading privilege tables.. ... Success! Next the dialog deals with the anonymous user: By default, a MariaDB installation has an anonymous user, allowing anyone to log into MariaDB without having to have a user account created for them. This is intended only for testing, and to make the installation go a bit smoother. You should remove them before moving into a production environment. Remove anonymous users? [Y/n] The answer here is \"Y\" so just hit 'Enter' to accept the default. The dialog proceeds to the section dealing with allowing the root user to login remotely: ... Success! Normally, root should only be allowed to connect from 'localhost'. This ensures that someone cannot guess at the root password from the network. Disallow root login remotely? [Y/n] root should only be needed locally on the machine. So accept this default as well by hitting 'Enter'. The dialog then moves on to the 'test' database that is automatically installed with mariadb-server : ... Success! By default, MariaDB comes with a database named 'test' that anyone can access. This is also intended only for testing, and should be removed before moving into a production environment. Remove test database and access to it? [Y/n] Again, the answer here is the default, so just hit 'Enter' to remove it. Finally, the dialog ask you if you want to reload the privileges: - Dropping test database... ... Success! - Removing privileges on test database... ... Success! Reloading the privilege tables will ensure that all changes made so far will take effect immediately. Reload privilege tables now? [Y/n] Again, simply hit 'Enter' to do this. If all goes well, you should receive this message: ... Success! Cleaning up... All done! If you've completed all of the above steps, your MariaDB installation should now be secure. Thanks for using MariaDB! MariaDB should now be ready to use. Conclusions \u00b6 A database server, such as mariadb-server , can be used for many purposes. Because of the popularity of the Wordpress CMS, it is often found on web servers. Before we run the database in production, however, it is a good idea to strengthen its security.","title":"Database mariadb-server"},{"location":"guides/database_mariadb-server/#database-mariadb-server","text":"","title":"Database mariadb-server"},{"location":"guides/database_mariadb-server/#prerequisites","text":"A Rocky Linux server Proficiency with a command-line editor (we are using vi in this example) A heavy comfort level with issuing commands from the command-line, viewing logs, and other general systems administrator duties An understanding of mariadb-server databases is helpful All commands are run as the root user or sudo","title":"Prerequisites"},{"location":"guides/database_mariadb-server/#introduction","text":"The mariadb-server and it's client mariadb are the open source alternatives to mysql-server and mysql , and they share command structure. mariadb-server can be found running on many web servers, due to the popular Wordpress CMS which requires it. This database, though, has many other uses. If you'd like to use this along with other tools for hardening a web server, refer back to the Apache Hardened Web Server guide .","title":"Introduction"},{"location":"guides/database_mariadb-server/#installing-mariadb-server","text":"We need to install mariadb-server : dnf install mariadb-server","title":"Installing mariadb-server"},{"location":"guides/database_mariadb-server/#securing-mariadb-server","text":"To strengthen the security of mariadb-server we need to run a script, but before we do, we need to enable and start mariadb: systemctl enable mariadb And then: systemctl start mariadb Next, run this command: mysql_secure_installation This brings up a dialog: NOTE: RUNNING ALL PARTS OF THIS SCRIPT IS RECOMMENDED FOR ALL MariaDB SERVERS IN PRODUCTION USE! PLEASE READ EACH STEP CAREFULLY! In order to log into MariaDB to secure it, we'll need the current password for the root user. If you've just installed MariaDB, and you haven't set the root password yet, the password will be blank, so you should just press enter here. Enter current password for root (enter for none): Since this is a brand new installation, there is no root password set. So just hit enter here. The next part of the dialog continues: OK, successfully used password, moving on... Setting the root password ensures that nobody can log into the MariaDB root user without the proper authorisation. Set root password? [Y/n] You absolutely do want to have a root password set. You'll want to figure out what this should be and document it in a password manager somewhere so that you can pull it up if necessary. Start by hitting 'Enter' to accept the default \"Y\". This will bring up the password dialog: New password: Re-enter new password: Enter your chosen password and then confirm it by entering it again. If this is successful, you will get the following dialog: Password updated successfully! Reloading privilege tables.. ... Success! Next the dialog deals with the anonymous user: By default, a MariaDB installation has an anonymous user, allowing anyone to log into MariaDB without having to have a user account created for them. This is intended only for testing, and to make the installation go a bit smoother. You should remove them before moving into a production environment. Remove anonymous users? [Y/n] The answer here is \"Y\" so just hit 'Enter' to accept the default. The dialog proceeds to the section dealing with allowing the root user to login remotely: ... Success! Normally, root should only be allowed to connect from 'localhost'. This ensures that someone cannot guess at the root password from the network. Disallow root login remotely? [Y/n] root should only be needed locally on the machine. So accept this default as well by hitting 'Enter'. The dialog then moves on to the 'test' database that is automatically installed with mariadb-server : ... Success! By default, MariaDB comes with a database named 'test' that anyone can access. This is also intended only for testing, and should be removed before moving into a production environment. Remove test database and access to it? [Y/n] Again, the answer here is the default, so just hit 'Enter' to remove it. Finally, the dialog ask you if you want to reload the privileges: - Dropping test database... ... Success! - Removing privileges on test database... ... Success! Reloading the privilege tables will ensure that all changes made so far will take effect immediately. Reload privilege tables now? [Y/n] Again, simply hit 'Enter' to do this. If all goes well, you should receive this message: ... Success! Cleaning up... All done! If you've completed all of the above steps, your MariaDB installation should now be secure. Thanks for using MariaDB! MariaDB should now be ready to use.","title":"Securing mariadb-server"},{"location":"guides/database_mariadb-server/#conclusions","text":"A database server, such as mariadb-server , can be used for many purposes. Because of the popularity of the Wordpress CMS, it is often found on web servers. Before we run the database in production, however, it is a good idea to strengthen its security.","title":"Conclusions"},{"location":"guides/developer_start2/","text":"Download Rocky Devtools Install Rocky Devtools Download Source RPMs (rockyget) Building packages (rockybuild) Trobleshooting package builds Work in progress Rocky Devtools refers to a set of home grown scripts and utlities created by members of the Rocky Linux community to help with sourcing, creating, branding, patching and building software packages distributed with the Rocky Linux Operating system. Rocky devtools consists of rockyget , rockybuild , rockypatch , and rockyprep . At a low level Rocky Devtools is a wrapper for running some custom and tradtional programs that are used for various package management tasks. Rocky Devtools relies heavily on srpmproc , go , git , and rpmbuild . You'll need an existing modern RPM based Linux system to install and use Rocky devtools. Let's walk through a typical installation and usage scenario of the devtools. 1. Download Rocky Devtools \u00b6 Download the devtools zipped source from the following URL: https://github.com/rocky-linux/devtools/archive/refs/heads/main.zip Here we use the curl command: curl -OJL https://github.com/rocky-linux/devtools/archive/refs/heads/main.zip You should now have a zipped archive named devtools-main.zip 2. Install Rocky Devtools \u00b6 Locate and uncompress the devtools archive that you just downloaded. Here we'll use the unzip command line utility: unzip devtools-main.zip Change your working directory to the new devtool source directory that was just created: cd devtools-main Run make to configure and compile devtools: make Install devtools: sudo make install 3. Use Rocky Devtools (rockyget) to search for and download Source RPMs (SRPMs) \u00b6 Once installed, the main utility for finding and downloading SRPMs is the rockyget utility. Let's use rockyget to download the SRPM for the popular sed package: rockyget sed The first time rockyget is run, it will automatically create a directory structure that roughly mimics the repository structure of Rocky's build servers. For example the ~/rocky/rpms folder will be automaically created. For our current sed example, its sources will be stored under the following sample folder hierchy: ~rocky/rpms/sed/ \u2514\u2500\u2500 r8 \u251c\u2500\u2500 SOURCES \u2502 \u251c\u2500\u2500 sed-4.2.2-binary_copy_args.patch \u2502 \u251c\u2500\u2500 sed-4.5.tar.xz \u2502 \u251c\u2500\u2500 sedfaq.txt \u2502 \u251c\u2500\u2500 sed-fuse.patch \u2502 \u2514\u2500\u2500 sed-selinux.patch \u2514\u2500\u2500 SPECS \u2514\u2500\u2500 sed.spec TIP : \u00b6 Once you have the original sources, this might be a good time to look through the SPECs file ( ~rocky/rpms/sed/SPECS/specs.spec ) to look for potential debranding opportinites in the given package. Debranding might include replacing upstream artwork/logos and so on. TIP \u00b6 If you are looking for other Rocky packages to build and experiment with, you can browse the list of packages that are currently failing in the Rocky automated build environment here - https://kojidev.rockylinux.org/koji/builds?state=3&order=-build_id 4. Use Rocky Devtools (rockybuild) to build a new package for the Rocky OS \u00b6 Under the hood, rockybuild calls rpmbuild and mock utilities to build the source package in a chroot environment for the application specified on the command-line. It relies on the application sources and RPM SPEC file that was automatically downloaded via the rockyget command. Use rockybuild to build the sed utility: rockybuild sed The time needed to complete the build process/step depends on the size and complexity of the application you are trying to build. At the end of the rockybuild run, an output similar to the one here indicates that the build completed successfully. .......... + exit 0 Finish: rpmbuild sed-4.5-2.el8.src.rpm Finish: build phase for sed-4.5-2.el8.src.rpm INFO: Done(~/rocky/rpms/sed/r8/SRPMS/sed-4.5-2.el8.src.rpm) Config(baseos) 4 minutes 34 seconds INFO: Results and/or logs in: /home/centos/rocky/builds/sed/r8 ........ If all goes well you should end up with a Rocky ready SRPM file under the ~/rocky/builds/sed/r8 directory. ~/rocky/rpms/sed/r8/SRPMS/sed-4.5-2.el8.src.rpm 5. Debugging a failed package build \u00b6 The previous rockybuild process will generate some log files that can be used in debugging failed application builds. The results and/or logs of the build process are stored under the ~/rocky/builds/<PACKAGE NAME>/r8 . For example ~/rocky/builds/sed/r8 ~/rocky/builds/sed/r8 \u251c\u2500\u2500 build.log \u251c\u2500\u2500 hw_info.log \u251c\u2500\u2500 installed_pkgs.log \u251c\u2500\u2500 root.log \u251c\u2500\u2500 sed-4.5-2.el8_3.src.rpm \u251c\u2500\u2500 sed-4.5-2.el8_3.x86_64.rpm \u251c\u2500\u2500 sed-debuginfo-4.5-2.el8_3.x86_64.rpm \u251c\u2500\u2500 sed-debugsource-4.5-2.el8_3.x86_64.rpm \u2514\u2500\u2500 state.log The main files to search for clues for the causes any error(s) are the build.log and root.log. The build.log file should detail all build errors and the root.log file will contain information about the chroot environment setup and tear down processes. With everything else being equal, most of the build debugging/troubleshooting process can be performed with the contents of the build.log file.","title":"Developer start2"},{"location":"guides/developer_start2/#1-download-rocky-devtools","text":"Download the devtools zipped source from the following URL: https://github.com/rocky-linux/devtools/archive/refs/heads/main.zip Here we use the curl command: curl -OJL https://github.com/rocky-linux/devtools/archive/refs/heads/main.zip You should now have a zipped archive named devtools-main.zip","title":"1. Download Rocky Devtools"},{"location":"guides/developer_start2/#2-install-rocky-devtools","text":"Locate and uncompress the devtools archive that you just downloaded. Here we'll use the unzip command line utility: unzip devtools-main.zip Change your working directory to the new devtool source directory that was just created: cd devtools-main Run make to configure and compile devtools: make Install devtools: sudo make install","title":"2. Install Rocky Devtools"},{"location":"guides/developer_start2/#3-use-rocky-devtools-rockyget-to-search-for-and-download-source-rpms-srpms","text":"Once installed, the main utility for finding and downloading SRPMs is the rockyget utility. Let's use rockyget to download the SRPM for the popular sed package: rockyget sed The first time rockyget is run, it will automatically create a directory structure that roughly mimics the repository structure of Rocky's build servers. For example the ~/rocky/rpms folder will be automaically created. For our current sed example, its sources will be stored under the following sample folder hierchy: ~rocky/rpms/sed/ \u2514\u2500\u2500 r8 \u251c\u2500\u2500 SOURCES \u2502 \u251c\u2500\u2500 sed-4.2.2-binary_copy_args.patch \u2502 \u251c\u2500\u2500 sed-4.5.tar.xz \u2502 \u251c\u2500\u2500 sedfaq.txt \u2502 \u251c\u2500\u2500 sed-fuse.patch \u2502 \u2514\u2500\u2500 sed-selinux.patch \u2514\u2500\u2500 SPECS \u2514\u2500\u2500 sed.spec","title":"3. Use Rocky Devtools (rockyget) to search for and download Source RPMs (SRPMs)"},{"location":"guides/developer_start2/#tip","text":"Once you have the original sources, this might be a good time to look through the SPECs file ( ~rocky/rpms/sed/SPECS/specs.spec ) to look for potential debranding opportinites in the given package. Debranding might include replacing upstream artwork/logos and so on.","title":"TIP :"},{"location":"guides/developer_start2/#tip_1","text":"If you are looking for other Rocky packages to build and experiment with, you can browse the list of packages that are currently failing in the Rocky automated build environment here - https://kojidev.rockylinux.org/koji/builds?state=3&order=-build_id","title":"TIP"},{"location":"guides/developer_start2/#4-use-rocky-devtools-rockybuild-to-build-a-new-package-for-the-rocky-os","text":"Under the hood, rockybuild calls rpmbuild and mock utilities to build the source package in a chroot environment for the application specified on the command-line. It relies on the application sources and RPM SPEC file that was automatically downloaded via the rockyget command. Use rockybuild to build the sed utility: rockybuild sed The time needed to complete the build process/step depends on the size and complexity of the application you are trying to build. At the end of the rockybuild run, an output similar to the one here indicates that the build completed successfully. .......... + exit 0 Finish: rpmbuild sed-4.5-2.el8.src.rpm Finish: build phase for sed-4.5-2.el8.src.rpm INFO: Done(~/rocky/rpms/sed/r8/SRPMS/sed-4.5-2.el8.src.rpm) Config(baseos) 4 minutes 34 seconds INFO: Results and/or logs in: /home/centos/rocky/builds/sed/r8 ........ If all goes well you should end up with a Rocky ready SRPM file under the ~/rocky/builds/sed/r8 directory. ~/rocky/rpms/sed/r8/SRPMS/sed-4.5-2.el8.src.rpm","title":"4. Use Rocky Devtools (rockybuild) to build a new package for the Rocky OS"},{"location":"guides/developer_start2/#5-debugging-a-failed-package-build","text":"The previous rockybuild process will generate some log files that can be used in debugging failed application builds. The results and/or logs of the build process are stored under the ~/rocky/builds/<PACKAGE NAME>/r8 . For example ~/rocky/builds/sed/r8 ~/rocky/builds/sed/r8 \u251c\u2500\u2500 build.log \u251c\u2500\u2500 hw_info.log \u251c\u2500\u2500 installed_pkgs.log \u251c\u2500\u2500 root.log \u251c\u2500\u2500 sed-4.5-2.el8_3.src.rpm \u251c\u2500\u2500 sed-4.5-2.el8_3.x86_64.rpm \u251c\u2500\u2500 sed-debuginfo-4.5-2.el8_3.x86_64.rpm \u251c\u2500\u2500 sed-debugsource-4.5-2.el8_3.x86_64.rpm \u2514\u2500\u2500 state.log The main files to search for clues for the causes any error(s) are the build.log and root.log. The build.log file should detail all build errors and the root.log file will contain information about the chroot environment setup and tear down processes. With everything else being equal, most of the build debugging/troubleshooting process can be performed with the contents of the build.log file.","title":"5. Debugging a failed package build"},{"location":"guides/dokuwiki_server/","text":"DokuWiki Server \u00b6 Prerequisites And Assumptions \u00b6 A Rocky Linux instance installed on a server, container, or virtual machine. Comfort with modifying configuration files from the command line with an editor (our examples here will use vi , but you can substitute your favorite editor) Some knowledge about web applications and setup. Our example will use the Apache Sites Enabled for setup, so it is a good idea to review that routine if you plan on following along. We will be using \"wiki-doc.yourdomain.com\" as the domain name throughout this example. We will assume throughout this document that you are the root user or can get there with sudo . We are assuming a fresh install of the OS, however that is NOT a requirement. Introduction \u00b6 Documentation can take many forms in an organization. Having a repository that you can reference for that documentation is invaluable. A wiki (which means quick in Hawaiian), is a way to keep documentation, process notes, corporate knowledge bases, and even code examples, in a centralized location. IT professionals who maintain a wiki, even secretly, have a built-in insurance policy against forgetting an obscure routine. DokuWiki is a mature, fast, wiki that runs without a database, has built in security features, and is relatively easy to deploy. For more information on what DokuWiki can do, check out their web page . DokuWiki is just one of many wiki's available, though it's a pretty good one. One big pro is that DokuWiki is relatively lightweight and can run on a server that is already running other services, provided you have space and memory available. Installation \u00b6 Installing Dependencies \u00b6 The minimum PHP version for DokuWiki is now 7.2, which is exactly what Rocky Linux 8 comes with. We are specifying packages here that may already be installed: dnf install tar wget httpd php php-gd php-xml php-json php-mbstring You will see a list of additional dependencies that will be installed and this prompt: Is this ok [y/N]: Go ahead and answer with \"y\" and hit 'Enter' to install. Create Directories And Modify Configuration \u00b6 Apache Configuration \u00b6 If you have read through the Apache Sites Enabled procedure, you know that we need to create a few directories. We will start with the httpd configuration directory additions: mkdir -p /etc/httpd/{sites-available,sites-enabled} We need to edit the httpd.conf file: vi /etc/httpd/conf/httpd.conf And add this to the very bottom of the file: Include /etc/httpd/sites-enabled Create the site configuration file in sites-available: vi /etc/httpd/sites-available/com.yourdomain.wiki-doc That configuration file should look something like this: <VirtualHost *> ServerName wiki-doc.yourdomain.com DocumentRoot /var/www/sub-domains/com.yourdomain.wiki-doc/html <Directory ~ \"/var/www/sub-domains/com.yourdomain.wiki-doc/html/(bin/|conf/|data/|inc/)\"> <IfModule mod_authz_core.c> AllowOverride All Require all denied </IfModule> <IfModule !mod_authz_core.c> Order allow,deny Deny from all </IfModule> </Directory> ErrorLog /var/log/httpd/wiki-doc.yourdomain.com_error.log CustomLog /var/log/httpd/wiki-doc.yourdomain_access.log combined </VirtualHost> Note that the \"AllowOverride All\" above, allows the .htaccess (directory specific security) file to work. Go ahead an link the configuration file into sites-enabled, but don't start web services as yet: ln -s /etc/httpd/sites-available/com.yourdomain.wiki-doc /etc/httpd/sites-enabled/ Apache DocumentRoot \u00b6 We also need to create our DocumentRoot . To do this: mkdir -p /var/www/sub-domains/com.yourdomain.wiki-doc/html Installing DokuWiki \u00b6 In your server, change to the root directory. cd /root Now that we have our environment ready to go, let's get the latest stable version of DokuWiki. You can find this by going to the download page and on the left-hand side of the page under \"Version\" you will see \"Stable (Recommended) (direct link).\" Right-click on the \"(direct link)\" portion of this and copy the link address. In the console of your DokuWiki server, type \"wget\" and a space and then paste in your copied link in the terminal. You should get something like this: wget https://download.dokuwiki.org/src/dokuwiki/dokuwiki-stable.tgz Before we decompress the archive, take a look at the contents using tar ztf to see the contents of the archive: tar ztv dokuwiki-stable.tgz Notice the named dated directory ahead of all the other files that looks something like this? ... (more above) dokuwiki-2020-07-29/inc/lang/fr/resetpwd.txt dokuwiki-2020-07-29/inc/lang/fr/draft.txt dokuwiki-2020-07-29/inc/lang/fr/recent.txt ... (more below) We don't want that leading named directory when we decompress the archive, so we are going to use some options with tar to exclude it. The first option is the \"--strip-components=1\" which removes that leading directory. The second option is the \"-C\" option, and that tells tar where we want the archive to be decompressed to. So decompress the archive with this command: tar xzf dokuwiki-stable.tgz --strip-components=1 -C /var/www/sub-domains/com.yourdomain.wiki-doc/html/ Once we have executed this command, all of DokuWiki should be in our DocumentRoot . We need to make a copy of the .htaccess.dist file that came with DokuWiki and keep the old one there too, in case we need to revert to the original in the future. In the process, we will be changing the name of this file to simply .htaccess which is what apache will be looking for. To do this: cp /var/www/sub-domains/com.yourdomain.wiki-doc/html/.htaccess{.dist,} Now we need to change ownership of the new directory and its files to the apache user and group: chown -Rf apache.apache /var/www/sub-domains/com.yourdomain.wiki-doc/html Setting Up DNS Or /etc/hosts \u00b6 Before you'll be able to access the DokuWiki interface, you'll need to set name resolution for this site. For testing purposes, you can use your /etc/hosts file. In this example, let's assume that DokuWiki will be running on a private IPv4 address of 10.56.233.179. Let's also assume that you are modifying the /etc/hosts file on a Linux workstation. To do this, run: sudo vi /etc/hosts And then modify your hosts file to look something like this (note the IP address above in the below example): 127.0.0.1 localhost 127.0.1.1 myworkstation-home 10.56.233.179 wiki-doc.yourdomain.com wiki-doc # The following lines are desirable for IPv6 capable hosts ::1 ip6-localhost ip6-loopback fe00::0 ip6-localnet ff00::0 ip6-mcastprefix ff02::1 ip6-allnodes ff02::2 ip6-allrouters Once you have finished testing and are ready to take things live for everyone, you will need to add this host to a DNS server. You could do this by using a Private DNS Server , or a public-facing DNS server. Starting httpd \u00b6 Before we start httpd let's test to make sure that our configuration is OK: httpd -t You should get: Syntax OK If so, you should be ready to start httpd and then finish the setup. Let's start by enabling httpd to start on boot: systemctl enable httpd And then start it: systemctl start httpd Testing DokuWiki \u00b6 Now that our host name is set for testing and the web service has been started, the next step is to open up a web browser and type this in the address bar: http://wiki-doc/install.php OR http://wiki-doc.yourdomain.com/install.php Either should work if you set your hosts file as above. This will bring you to the setup screen so that you can finish the setup: In the \"Wiki Name\" field, type the name for our wiki. Example \"Technical Documentation\" In the \"Superuser\" field, type the administrative username. Example \"admin\" In the \"Real name\" field, type the real name for the administrative user. In the \"E-Mail\" field, type the email address of the administrative user. In the \"Password\" field, type the secure password for the administrative user. In the \"once again\" field, re-type that same password. In the \"Initial ACL Policy\" drop down, choose the option that works best for your environment. Choose the appropriate check box for the license you want to put your content under. Leave checked or uncheck the \"Once a month, send anonymous usage data to the DokuWiki developers\" checkbox Click the \"Save\" button Your wiki is now ready for you to add content. Securing DokuWiki \u00b6 Besides the ACL policy that you just created, consider: Your Firewall \u00b6 Before you call everything done, you need to think about security. First, you should be running a firewall on the server. We will assume that you are using iptables and have Enabled iptables , but if you want to use firewalld instead, simply modify your firewalld rules accordingly. Instead of everyone having access to the wiki, we are going to assume that anyone on the 10.0.0.0/8 network is on your private Local Area Network, and that those are the only people who need access to the site. A simple iptables firewall script for this is down below. Please note that you may need other rules for other services on this server, and that this example only takes into account the web services. First, modify or create the /etc/firewall.conf file: vi /etc/firewall.conf #IPTABLES=/usr/sbin/iptables # Unless specified, the defaults for OUTPUT is ACCEPT # The default for FORWARD and INPUT is DROP # echo \" clearing any existing rules and setting default policy..\" iptables -F INPUT iptables -P INPUT DROP # web ports iptables -A INPUT -p tcp -m tcp -s 10.0.0.0/8 --dport 80 -j ACCEPT iptables -A INPUT -p tcp -m tcp -s 10.0.0.0/8 --dport 443 -j ACCEPT iptables -A INPUT -i lo -j ACCEPT iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT iptables -A INPUT -p tcp -j REJECT --reject-with tcp-reset iptables -A INPUT -p udp -j REJECT --reject-with icmp-port-unreachable /usr/sbin/service iptables save Once the script is created, make sure it is executable: chmod +x /etc/firewall.conf Then execute the script: /etc/firewall.conf This will execute the rules and save them so that they will be reloaded on the next start of iptables or on boot. SSL \u00b6 For the best security, you should consider using an SSL so that all web traffic is encrypted. You can purchase an SSL from an SSL provider or use Let's Encrypt Conclusion \u00b6 Whether you need to document processes, company policies, program code, or something else, a wiki is a great way to get that done. DokuWiki is a product that is secure, flexible, easy to use, relatively easy to install and deploy, and is a stable project that has been around for many years.","title":"DokuWiki Server"},{"location":"guides/dokuwiki_server/#dokuwiki-server","text":"","title":"DokuWiki Server"},{"location":"guides/dokuwiki_server/#prerequisites-and-assumptions","text":"A Rocky Linux instance installed on a server, container, or virtual machine. Comfort with modifying configuration files from the command line with an editor (our examples here will use vi , but you can substitute your favorite editor) Some knowledge about web applications and setup. Our example will use the Apache Sites Enabled for setup, so it is a good idea to review that routine if you plan on following along. We will be using \"wiki-doc.yourdomain.com\" as the domain name throughout this example. We will assume throughout this document that you are the root user or can get there with sudo . We are assuming a fresh install of the OS, however that is NOT a requirement.","title":"Prerequisites And Assumptions"},{"location":"guides/dokuwiki_server/#introduction","text":"Documentation can take many forms in an organization. Having a repository that you can reference for that documentation is invaluable. A wiki (which means quick in Hawaiian), is a way to keep documentation, process notes, corporate knowledge bases, and even code examples, in a centralized location. IT professionals who maintain a wiki, even secretly, have a built-in insurance policy against forgetting an obscure routine. DokuWiki is a mature, fast, wiki that runs without a database, has built in security features, and is relatively easy to deploy. For more information on what DokuWiki can do, check out their web page . DokuWiki is just one of many wiki's available, though it's a pretty good one. One big pro is that DokuWiki is relatively lightweight and can run on a server that is already running other services, provided you have space and memory available.","title":"Introduction"},{"location":"guides/dokuwiki_server/#installation","text":"","title":"Installation"},{"location":"guides/dokuwiki_server/#installing-dependencies","text":"The minimum PHP version for DokuWiki is now 7.2, which is exactly what Rocky Linux 8 comes with. We are specifying packages here that may already be installed: dnf install tar wget httpd php php-gd php-xml php-json php-mbstring You will see a list of additional dependencies that will be installed and this prompt: Is this ok [y/N]: Go ahead and answer with \"y\" and hit 'Enter' to install.","title":"Installing Dependencies"},{"location":"guides/dokuwiki_server/#create-directories-and-modify-configuration","text":"","title":"Create Directories And Modify Configuration"},{"location":"guides/dokuwiki_server/#apache-configuration","text":"If you have read through the Apache Sites Enabled procedure, you know that we need to create a few directories. We will start with the httpd configuration directory additions: mkdir -p /etc/httpd/{sites-available,sites-enabled} We need to edit the httpd.conf file: vi /etc/httpd/conf/httpd.conf And add this to the very bottom of the file: Include /etc/httpd/sites-enabled Create the site configuration file in sites-available: vi /etc/httpd/sites-available/com.yourdomain.wiki-doc That configuration file should look something like this: <VirtualHost *> ServerName wiki-doc.yourdomain.com DocumentRoot /var/www/sub-domains/com.yourdomain.wiki-doc/html <Directory ~ \"/var/www/sub-domains/com.yourdomain.wiki-doc/html/(bin/|conf/|data/|inc/)\"> <IfModule mod_authz_core.c> AllowOverride All Require all denied </IfModule> <IfModule !mod_authz_core.c> Order allow,deny Deny from all </IfModule> </Directory> ErrorLog /var/log/httpd/wiki-doc.yourdomain.com_error.log CustomLog /var/log/httpd/wiki-doc.yourdomain_access.log combined </VirtualHost> Note that the \"AllowOverride All\" above, allows the .htaccess (directory specific security) file to work. Go ahead an link the configuration file into sites-enabled, but don't start web services as yet: ln -s /etc/httpd/sites-available/com.yourdomain.wiki-doc /etc/httpd/sites-enabled/","title":"Apache Configuration"},{"location":"guides/dokuwiki_server/#apache-documentroot","text":"We also need to create our DocumentRoot . To do this: mkdir -p /var/www/sub-domains/com.yourdomain.wiki-doc/html","title":"Apache DocumentRoot"},{"location":"guides/dokuwiki_server/#installing-dokuwiki","text":"In your server, change to the root directory. cd /root Now that we have our environment ready to go, let's get the latest stable version of DokuWiki. You can find this by going to the download page and on the left-hand side of the page under \"Version\" you will see \"Stable (Recommended) (direct link).\" Right-click on the \"(direct link)\" portion of this and copy the link address. In the console of your DokuWiki server, type \"wget\" and a space and then paste in your copied link in the terminal. You should get something like this: wget https://download.dokuwiki.org/src/dokuwiki/dokuwiki-stable.tgz Before we decompress the archive, take a look at the contents using tar ztf to see the contents of the archive: tar ztv dokuwiki-stable.tgz Notice the named dated directory ahead of all the other files that looks something like this? ... (more above) dokuwiki-2020-07-29/inc/lang/fr/resetpwd.txt dokuwiki-2020-07-29/inc/lang/fr/draft.txt dokuwiki-2020-07-29/inc/lang/fr/recent.txt ... (more below) We don't want that leading named directory when we decompress the archive, so we are going to use some options with tar to exclude it. The first option is the \"--strip-components=1\" which removes that leading directory. The second option is the \"-C\" option, and that tells tar where we want the archive to be decompressed to. So decompress the archive with this command: tar xzf dokuwiki-stable.tgz --strip-components=1 -C /var/www/sub-domains/com.yourdomain.wiki-doc/html/ Once we have executed this command, all of DokuWiki should be in our DocumentRoot . We need to make a copy of the .htaccess.dist file that came with DokuWiki and keep the old one there too, in case we need to revert to the original in the future. In the process, we will be changing the name of this file to simply .htaccess which is what apache will be looking for. To do this: cp /var/www/sub-domains/com.yourdomain.wiki-doc/html/.htaccess{.dist,} Now we need to change ownership of the new directory and its files to the apache user and group: chown -Rf apache.apache /var/www/sub-domains/com.yourdomain.wiki-doc/html","title":"Installing DokuWiki"},{"location":"guides/dokuwiki_server/#setting-up-dns-or-etchosts","text":"Before you'll be able to access the DokuWiki interface, you'll need to set name resolution for this site. For testing purposes, you can use your /etc/hosts file. In this example, let's assume that DokuWiki will be running on a private IPv4 address of 10.56.233.179. Let's also assume that you are modifying the /etc/hosts file on a Linux workstation. To do this, run: sudo vi /etc/hosts And then modify your hosts file to look something like this (note the IP address above in the below example): 127.0.0.1 localhost 127.0.1.1 myworkstation-home 10.56.233.179 wiki-doc.yourdomain.com wiki-doc # The following lines are desirable for IPv6 capable hosts ::1 ip6-localhost ip6-loopback fe00::0 ip6-localnet ff00::0 ip6-mcastprefix ff02::1 ip6-allnodes ff02::2 ip6-allrouters Once you have finished testing and are ready to take things live for everyone, you will need to add this host to a DNS server. You could do this by using a Private DNS Server , or a public-facing DNS server.","title":"Setting Up DNS Or /etc/hosts"},{"location":"guides/dokuwiki_server/#starting-httpd","text":"Before we start httpd let's test to make sure that our configuration is OK: httpd -t You should get: Syntax OK If so, you should be ready to start httpd and then finish the setup. Let's start by enabling httpd to start on boot: systemctl enable httpd And then start it: systemctl start httpd","title":"Starting httpd"},{"location":"guides/dokuwiki_server/#testing-dokuwiki","text":"Now that our host name is set for testing and the web service has been started, the next step is to open up a web browser and type this in the address bar: http://wiki-doc/install.php OR http://wiki-doc.yourdomain.com/install.php Either should work if you set your hosts file as above. This will bring you to the setup screen so that you can finish the setup: In the \"Wiki Name\" field, type the name for our wiki. Example \"Technical Documentation\" In the \"Superuser\" field, type the administrative username. Example \"admin\" In the \"Real name\" field, type the real name for the administrative user. In the \"E-Mail\" field, type the email address of the administrative user. In the \"Password\" field, type the secure password for the administrative user. In the \"once again\" field, re-type that same password. In the \"Initial ACL Policy\" drop down, choose the option that works best for your environment. Choose the appropriate check box for the license you want to put your content under. Leave checked or uncheck the \"Once a month, send anonymous usage data to the DokuWiki developers\" checkbox Click the \"Save\" button Your wiki is now ready for you to add content.","title":"Testing DokuWiki"},{"location":"guides/dokuwiki_server/#securing-dokuwiki","text":"Besides the ACL policy that you just created, consider:","title":"Securing DokuWiki"},{"location":"guides/dokuwiki_server/#your-firewall","text":"Before you call everything done, you need to think about security. First, you should be running a firewall on the server. We will assume that you are using iptables and have Enabled iptables , but if you want to use firewalld instead, simply modify your firewalld rules accordingly. Instead of everyone having access to the wiki, we are going to assume that anyone on the 10.0.0.0/8 network is on your private Local Area Network, and that those are the only people who need access to the site. A simple iptables firewall script for this is down below. Please note that you may need other rules for other services on this server, and that this example only takes into account the web services. First, modify or create the /etc/firewall.conf file: vi /etc/firewall.conf #IPTABLES=/usr/sbin/iptables # Unless specified, the defaults for OUTPUT is ACCEPT # The default for FORWARD and INPUT is DROP # echo \" clearing any existing rules and setting default policy..\" iptables -F INPUT iptables -P INPUT DROP # web ports iptables -A INPUT -p tcp -m tcp -s 10.0.0.0/8 --dport 80 -j ACCEPT iptables -A INPUT -p tcp -m tcp -s 10.0.0.0/8 --dport 443 -j ACCEPT iptables -A INPUT -i lo -j ACCEPT iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT iptables -A INPUT -p tcp -j REJECT --reject-with tcp-reset iptables -A INPUT -p udp -j REJECT --reject-with icmp-port-unreachable /usr/sbin/service iptables save Once the script is created, make sure it is executable: chmod +x /etc/firewall.conf Then execute the script: /etc/firewall.conf This will execute the rules and save them so that they will be reloaded on the next start of iptables or on boot.","title":"Your Firewall"},{"location":"guides/dokuwiki_server/#ssl","text":"For the best security, you should consider using an SSL so that all web traffic is encrypted. You can purchase an SSL from an SSL provider or use Let's Encrypt","title":"SSL"},{"location":"guides/dokuwiki_server/#conclusion","text":"Whether you need to document processes, company policies, program code, or something else, a wiki is a great way to get that done. DokuWiki is a product that is secure, flexible, easy to use, relatively easy to install and deploy, and is a stable project that has been around for many years.","title":"Conclusion"},{"location":"guides/enabling_iptables_firewall/","text":"Enabling iptables Firewall \u00b6 Prerequisites \u00b6 A burning, unquenchable desire to disable the default firewalld application, and enable iptables . Introduction \u00b6 firewalld is now the default firewall on Rocky Linux. firewalld is nothing more than a dynamic application of iptables using xml files, and it loads changes without flushing the rules. However, using straight iptables may be something that you are more comfortable with. If so, it is still possible to run iptables without firewalld by following this guide. What this guide will not tell you is how to write rules for iptables . It is assumed that if you want to get rid of firewalld , you must already know how to write rules for iptables . Disabling firewalld \u00b6 You can't really run the old iptables utilities alongside firewalld . They're just not compatible. The best way to get around this is to disable firewalld entirely (no need to unistall it unless you want to), and reinstall the iptables utilities. Disabling firewalld can be done using these commands: Stop firewalld : systemctl stop firewalld Disable firewalld so it won't start on boot: systemctl disable firewalld Mask the service so that it can't be found: systemctl mask firewalld Installing And Enabling iptables Services \u00b6 Next we need to install the old iptables services and utilities. This is done with the following: dnf install iptables-services iptables-utils This will install everything that is needed to run a straight iptables rule set. Now we need to enable the iptables service to make sure that it starts on boot: dnf enable iptables Conclusion \u00b6 You can return to using straight iptables if you prefer it over firewalld . You can return to using the default firewalld by simply reversing these changes.","title":"Enabling iptables Firewall"},{"location":"guides/enabling_iptables_firewall/#enabling-iptables-firewall","text":"","title":"Enabling iptables Firewall"},{"location":"guides/enabling_iptables_firewall/#prerequisites","text":"A burning, unquenchable desire to disable the default firewalld application, and enable iptables .","title":"Prerequisites"},{"location":"guides/enabling_iptables_firewall/#introduction","text":"firewalld is now the default firewall on Rocky Linux. firewalld is nothing more than a dynamic application of iptables using xml files, and it loads changes without flushing the rules. However, using straight iptables may be something that you are more comfortable with. If so, it is still possible to run iptables without firewalld by following this guide. What this guide will not tell you is how to write rules for iptables . It is assumed that if you want to get rid of firewalld , you must already know how to write rules for iptables .","title":"Introduction"},{"location":"guides/enabling_iptables_firewall/#disabling-firewalld","text":"You can't really run the old iptables utilities alongside firewalld . They're just not compatible. The best way to get around this is to disable firewalld entirely (no need to unistall it unless you want to), and reinstall the iptables utilities. Disabling firewalld can be done using these commands: Stop firewalld : systemctl stop firewalld Disable firewalld so it won't start on boot: systemctl disable firewalld Mask the service so that it can't be found: systemctl mask firewalld","title":"Disabling firewalld"},{"location":"guides/enabling_iptables_firewall/#installing-and-enabling-iptables-services","text":"Next we need to install the old iptables services and utilities. This is done with the following: dnf install iptables-services iptables-utils This will install everything that is needed to run a straight iptables rule set. Now we need to enable the iptables service to make sure that it starts on boot: dnf enable iptables","title":"Installing And Enabling iptables Services"},{"location":"guides/enabling_iptables_firewall/#conclusion","text":"You can return to using straight iptables if you prefer it over firewalld . You can return to using the default firewalld by simply reversing these changes.","title":"Conclusion"},{"location":"guides/generating_ssl_keys_lets_encrypt/","text":"Generating SSL Keys - Let's Encrypt \u00b6 Prerequisites \u00b6 Comfort with the command line Familiarity with securing web sites with SSL certificates is a plus Knowledge of command line text editors (this example uses vi ) An already running web server open to the world on port 80 (http) Familiarity with ssh (secure shell) and the ability to access your server with ssh Introduction \u00b6 One of the most popular ways to secure a web site, currently, is using Let's Encrypt SSL certificates, which are also free. These are actual certificates, not self-signed or snake oil, etc., so they are great for a low-budget security solution. This document will walk you through the process of installing and using Let's Encrypt certificates on a Rocky Linux web server. Assumptions \u00b6 All commands assume that you are either the root user or that you have used sudo to gain root access. Installation \u00b6 To do the next steps, use ssh to log into your server. If your server's fully qualified DNS name was www.myhost.com, then you would use: ssh -l root www.myhost.com Or, if you must access your server as an unprivileged user first. Use your username: ssh -l username www.myhost.com And then: sudo -s You will need your sudo user's credentials in this case to gain access to the system as root. Let's Encrypt uses a package called certbot which needs to be installed via a snap package. To install snapd on Rocky Linux, you will need to install the EPEL repository if you have not done so already: dnf install epel-release Besides snapd you may also need fuse and squashfuse depending on your system. We also need to make sure that mod_ssl is installed. To install them all use: dnf install snapd fuse squashfuse mod_ssl snapd requires a bunch of dependencies that will install along with it, so answer yes to the installation prompt. Once snapd and all of the dependencies are installed, enable the snapd service with: systemctl enable --now snapd.socket certbot requires classic snapd support, so we need to enable that with a symbolic link: ln -s /var/lib/snapd/snap /snap Before continuing on, we want to make sure that all of the snap packages are up to date. To do this use: snap install core; snap refresh core If there are any updates, they will install here. Just in case you got ahead of yourself and installed certbot from the RPM (which will not work, by the way), make sure that you remove it with: dnf remove certbot And finally, it's time to install certbot with: snap install --classic certbot This should install certbot . The final step is to put the certbot command in a path that Rocky Linux can find easily. This is done with another symbolic link: ln -s /snap/bin/certbot /usr/bin/certbot Getting The Let's Encrypt Certificate \u00b6 There are two ways to retrieve your Let's Encrypt certificate, either using the command to modify the http configuration file for you, or to just retrieve the certificate. If you are using the procedure for a multi-site setup suggested for one or more sites in the procedure Apache Web Server Multi-Site Setup , then you will only want to retrieve your certificate. We are assuming that you are using this procedure so we will only retrieve the certificate. If you are running a standalone web server using the default configuration, you can retrieve the certificate and modify the configuration file in one step using certbot --apache . To retrieve the certificate only, use this command: certbot certonly --apache This will generate a set of prompts that you will need to answer. The first is to give an email address for important information: Saving debug log to /var/log/letsencrypt/letsencrypt.log Plugins selected: Authenticator apache, Installer apache Enter email address (used for urgent renewal and security notices) (Enter 'c' to cancel): yourusername@youremaildomain.com The next asks you to read and accept the terms of the subscriber agreement. Once you have read the agreement answer 'Y' to continue: - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Please read the Terms of Service at https://letsencrypt.org/documents/LE-SA-v1.2-November-15-2017.pdf. You must agree in order to register with the ACME server. Do you agree? - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - (Y)es/(N)o: The next is a request to share your email with the Electronic Frontier Foundation. Answer 'Y' or 'N' as is your preference: - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Would you be willing, once your first certificate is successfully issued, to share your email address with the Electronic Frontier Foundation, a founding partner of the Let's Encrypt project and the non-profit organization that develops Certbot? We'd like to send you email about our work encrypting the web, EFF news, campaigns, and ways to support digital freedom. - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - (Y)es/(N)o: The next prompt asks you which domain you want the certificate for. It should display a domain in the listing based on your running web server. If so, enter the number next to the domain that you are getting the certificate for. In this case there is only one option ('1'): Which names would you like to activate HTTPS for? - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 1: yourdomain.com - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Select the appropriate numbers separated by commas and/or spaces, or leave input blank to select all options shown (Enter 'c' to cancel): If all goes well, you should receive the following message: Requesting a certificate for yourdomain.com Performing the following challenges: http-01 challenge for yourdomain.com Waiting for verification... Cleaning up challenges Subscribe to the EFF mailing list (email: yourusername@youremaildomain.com). IMPORTANT NOTES: - Congratulations! Your certificate and chain have been saved at: /etc/letsencrypt/live/yourdomain.com/fullchain.pem Your key file has been saved at: /etc/letsencrypt/live/yourdomain.com/privkey.pem Your certificate will expire on 2021-07-01. To obtain a new or tweaked version of this certificate in the future, simply run certbot again. To non-interactively renew *all* of your certificates, run \"certbot renew\" - If you like Certbot, please consider supporting our work by: Donating to ISRG / Let's Encrypt: https://letsencrypt.org/donate Donating to EFF: https://eff.org/donate-le The Site Configuration - https \u00b6 Applying the configuration file to our site is slightly different than if we were using a purchased SSL certificate from another provider. The certificate and chain file are included in a single PEM (Privacy Enhanced Mail) file. This is a common format for all certificate files now, so even though it has \"Mail\" in the reference, it is just a type of certificate file. To illustrate the configuration file, we will show it in it's entirety and then describe what is happening: <VirtualHost *:80> ServerName www.yourdomain.com ServerAdmin username@rockylinux.org Redirect / https://www.yourdomain.com/ </VirtualHost> <Virtual Host *:443> ServerName www.yourdomain.com ServerAdmin username@rockylinux.org DocumentRoot /var/www/sub-domains/com.yourdomain.www/html DirectoryIndex index.php index.htm index.html Alias /icons/ /var/www/icons/ # ScriptAlias /cgi-bin/ /var/www/sub-domains/com.yourdomain.www/cgi-bin/ CustomLog \"/var/log/httpd/com.yourdomain.www-access_log\" combined ErrorLog \"/var/log/httpd/com.yourdomain.www-error_log\" SSLEngine on SSLProtocol all -SSLv2 -SSLv3 -TLSv1 SSLHonorCipherOrder on SSLCipherSuite EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384 :EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS SSLCertificateFile /etc/letsencrypt/live/yourdomain.com/fullchain.pem SSLCertificateKeyFile /etc/letsencrypt/live/yourdomain.com/privkey.pem SSLCertificateChainFile /etc/letsencrypt/live/yourdomain.com/fullchain.pem <Directory /var/www/sub-domains/com.yourdomain.www/html> Options -ExecCGI -Indexes AllowOverride None Order deny,allow Deny from all Allow from all Satisfy all </Directory> </VirtualHost> Here's what's happening above. You may want to review the Apache Web Server Multi-Site Setup to see the differences in the application of an SSL purchased from another provider and the Let's Encrypt certificate: Even though port 80 (standard http) is listening, we are redirecting all traffic to port 443 (https) SSLEngine on - simply says to use SSL SSLProtocol all -SSLv2 -SSLv3 -TLSv1 - says to use all available protocols, except those that have been found to have vulnerabilities. You should research periodically which protocols are currently acceptable for use. SSLHonorCipherOrder on - this deals with the next line that regarding the cipher suites, and says to deal with them in the order that they are given. This is another area where you should review the cipher suites that you want to include periodically SSLCertificateFile - this is the PEM file, that contains the site certificate AND the intermediate certificate. We still need the 'SSLCertificateChainFile' line in our configuration, but it will simply specify the same PEM file again. SSLCertificateKeyFile - the PEM file for the private key, generated with the certbot request. SSLCertificateChainFile - the certificate from your certificate provider, often called the intermediate certificate, in this case exactly like the 'SSLCertificateFile' location above. Once you have made all of your changes, simply restart httpd and if it starts test your site to make sure you now have a valid certificate file showing. If so, you are ready to move on to the next step. Automating Let's Encrypt Certificate Renewal \u00b6 The beauty of installing certbot is that the Let's Encrypt certificate will be automatically renewed. There is no need to create a process to do this. We do need to test the renewal with: certbot renew --dry-run When you run this command, you'll get a nice output showing the renewal process: Saving debug log to /var/log/letsencrypt/letsencrypt.log - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Processing /etc/letsencrypt/renewal/yourdomain.com.conf - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Cert not due for renewal, but simulating renewal for dry run Plugins selected: Authenticator apache, Installer apache Account registered. Simulating renewal of an existing certificate for yourdomain.com Performing the following challenges: http-01 challenge for yourdomain.com Waiting for verification... Cleaning up challenges - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - new certificate deployed with reload of apache server; fullchain is /etc/letsencrypt/live/yourdomain.com/fullchain.pem - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Congratulations, all simulated renewals succeeded: /etc/letsencrypt/live/yourdomain.com/fullchain.pem (success) - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - The certbot documentation tells you in their step number 8, that the automatic renewal process could be in a couple of different spots, depending on your system. For a Rocky Linux install, you are going to find the process by using: systemctl list-timers Which gives you a list of processes, one of which will be for certbot : Sat 2021-04-03 07:12:00 UTC 14h left n/a n/a snap.certbot.renew.timer snap.certbot.renew.service Conclusions \u00b6 Let's Encrypt SSL certificates are yet another option for securing your web site with an SSL. Once installed, the system provides automatic renewal of certificates and will encrypt traffic to your web site. It should be noted that Let's Encrypt certificates are used for standard DV (Domain Validation) certificates. They cannot be used for OV (Organization Validation) or EV (Extended Validation) certificates.","title":"Generating SSL Keys - Let's Encrypt"},{"location":"guides/generating_ssl_keys_lets_encrypt/#generating-ssl-keys-lets-encrypt","text":"","title":"Generating SSL Keys - Let's Encrypt"},{"location":"guides/generating_ssl_keys_lets_encrypt/#prerequisites","text":"Comfort with the command line Familiarity with securing web sites with SSL certificates is a plus Knowledge of command line text editors (this example uses vi ) An already running web server open to the world on port 80 (http) Familiarity with ssh (secure shell) and the ability to access your server with ssh","title":"Prerequisites"},{"location":"guides/generating_ssl_keys_lets_encrypt/#introduction","text":"One of the most popular ways to secure a web site, currently, is using Let's Encrypt SSL certificates, which are also free. These are actual certificates, not self-signed or snake oil, etc., so they are great for a low-budget security solution. This document will walk you through the process of installing and using Let's Encrypt certificates on a Rocky Linux web server.","title":"Introduction"},{"location":"guides/generating_ssl_keys_lets_encrypt/#assumptions","text":"All commands assume that you are either the root user or that you have used sudo to gain root access.","title":"Assumptions"},{"location":"guides/generating_ssl_keys_lets_encrypt/#installation","text":"To do the next steps, use ssh to log into your server. If your server's fully qualified DNS name was www.myhost.com, then you would use: ssh -l root www.myhost.com Or, if you must access your server as an unprivileged user first. Use your username: ssh -l username www.myhost.com And then: sudo -s You will need your sudo user's credentials in this case to gain access to the system as root. Let's Encrypt uses a package called certbot which needs to be installed via a snap package. To install snapd on Rocky Linux, you will need to install the EPEL repository if you have not done so already: dnf install epel-release Besides snapd you may also need fuse and squashfuse depending on your system. We also need to make sure that mod_ssl is installed. To install them all use: dnf install snapd fuse squashfuse mod_ssl snapd requires a bunch of dependencies that will install along with it, so answer yes to the installation prompt. Once snapd and all of the dependencies are installed, enable the snapd service with: systemctl enable --now snapd.socket certbot requires classic snapd support, so we need to enable that with a symbolic link: ln -s /var/lib/snapd/snap /snap Before continuing on, we want to make sure that all of the snap packages are up to date. To do this use: snap install core; snap refresh core If there are any updates, they will install here. Just in case you got ahead of yourself and installed certbot from the RPM (which will not work, by the way), make sure that you remove it with: dnf remove certbot And finally, it's time to install certbot with: snap install --classic certbot This should install certbot . The final step is to put the certbot command in a path that Rocky Linux can find easily. This is done with another symbolic link: ln -s /snap/bin/certbot /usr/bin/certbot","title":"Installation"},{"location":"guides/generating_ssl_keys_lets_encrypt/#getting-the-lets-encrypt-certificate","text":"There are two ways to retrieve your Let's Encrypt certificate, either using the command to modify the http configuration file for you, or to just retrieve the certificate. If you are using the procedure for a multi-site setup suggested for one or more sites in the procedure Apache Web Server Multi-Site Setup , then you will only want to retrieve your certificate. We are assuming that you are using this procedure so we will only retrieve the certificate. If you are running a standalone web server using the default configuration, you can retrieve the certificate and modify the configuration file in one step using certbot --apache . To retrieve the certificate only, use this command: certbot certonly --apache This will generate a set of prompts that you will need to answer. The first is to give an email address for important information: Saving debug log to /var/log/letsencrypt/letsencrypt.log Plugins selected: Authenticator apache, Installer apache Enter email address (used for urgent renewal and security notices) (Enter 'c' to cancel): yourusername@youremaildomain.com The next asks you to read and accept the terms of the subscriber agreement. Once you have read the agreement answer 'Y' to continue: - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Please read the Terms of Service at https://letsencrypt.org/documents/LE-SA-v1.2-November-15-2017.pdf. You must agree in order to register with the ACME server. Do you agree? - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - (Y)es/(N)o: The next is a request to share your email with the Electronic Frontier Foundation. Answer 'Y' or 'N' as is your preference: - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Would you be willing, once your first certificate is successfully issued, to share your email address with the Electronic Frontier Foundation, a founding partner of the Let's Encrypt project and the non-profit organization that develops Certbot? We'd like to send you email about our work encrypting the web, EFF news, campaigns, and ways to support digital freedom. - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - (Y)es/(N)o: The next prompt asks you which domain you want the certificate for. It should display a domain in the listing based on your running web server. If so, enter the number next to the domain that you are getting the certificate for. In this case there is only one option ('1'): Which names would you like to activate HTTPS for? - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - 1: yourdomain.com - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Select the appropriate numbers separated by commas and/or spaces, or leave input blank to select all options shown (Enter 'c' to cancel): If all goes well, you should receive the following message: Requesting a certificate for yourdomain.com Performing the following challenges: http-01 challenge for yourdomain.com Waiting for verification... Cleaning up challenges Subscribe to the EFF mailing list (email: yourusername@youremaildomain.com). IMPORTANT NOTES: - Congratulations! Your certificate and chain have been saved at: /etc/letsencrypt/live/yourdomain.com/fullchain.pem Your key file has been saved at: /etc/letsencrypt/live/yourdomain.com/privkey.pem Your certificate will expire on 2021-07-01. To obtain a new or tweaked version of this certificate in the future, simply run certbot again. To non-interactively renew *all* of your certificates, run \"certbot renew\" - If you like Certbot, please consider supporting our work by: Donating to ISRG / Let's Encrypt: https://letsencrypt.org/donate Donating to EFF: https://eff.org/donate-le","title":"Getting The Let's Encrypt Certificate"},{"location":"guides/generating_ssl_keys_lets_encrypt/#the-site-configuration-https","text":"Applying the configuration file to our site is slightly different than if we were using a purchased SSL certificate from another provider. The certificate and chain file are included in a single PEM (Privacy Enhanced Mail) file. This is a common format for all certificate files now, so even though it has \"Mail\" in the reference, it is just a type of certificate file. To illustrate the configuration file, we will show it in it's entirety and then describe what is happening: <VirtualHost *:80> ServerName www.yourdomain.com ServerAdmin username@rockylinux.org Redirect / https://www.yourdomain.com/ </VirtualHost> <Virtual Host *:443> ServerName www.yourdomain.com ServerAdmin username@rockylinux.org DocumentRoot /var/www/sub-domains/com.yourdomain.www/html DirectoryIndex index.php index.htm index.html Alias /icons/ /var/www/icons/ # ScriptAlias /cgi-bin/ /var/www/sub-domains/com.yourdomain.www/cgi-bin/ CustomLog \"/var/log/httpd/com.yourdomain.www-access_log\" combined ErrorLog \"/var/log/httpd/com.yourdomain.www-error_log\" SSLEngine on SSLProtocol all -SSLv2 -SSLv3 -TLSv1 SSLHonorCipherOrder on SSLCipherSuite EECDH+ECDSA+AESGCM:EECDH+aRSA+AESGCM:EECDH+ECDSA+SHA384:EECDH+ECDSA+SHA256:EECDH+aRSA+SHA384 :EECDH+aRSA+SHA256:EECDH+aRSA+RC4:EECDH:EDH+aRSA:RC4:!aNULL:!eNULL:!LOW:!3DES:!MD5:!EXP:!PSK:!SRP:!DSS SSLCertificateFile /etc/letsencrypt/live/yourdomain.com/fullchain.pem SSLCertificateKeyFile /etc/letsencrypt/live/yourdomain.com/privkey.pem SSLCertificateChainFile /etc/letsencrypt/live/yourdomain.com/fullchain.pem <Directory /var/www/sub-domains/com.yourdomain.www/html> Options -ExecCGI -Indexes AllowOverride None Order deny,allow Deny from all Allow from all Satisfy all </Directory> </VirtualHost> Here's what's happening above. You may want to review the Apache Web Server Multi-Site Setup to see the differences in the application of an SSL purchased from another provider and the Let's Encrypt certificate: Even though port 80 (standard http) is listening, we are redirecting all traffic to port 443 (https) SSLEngine on - simply says to use SSL SSLProtocol all -SSLv2 -SSLv3 -TLSv1 - says to use all available protocols, except those that have been found to have vulnerabilities. You should research periodically which protocols are currently acceptable for use. SSLHonorCipherOrder on - this deals with the next line that regarding the cipher suites, and says to deal with them in the order that they are given. This is another area where you should review the cipher suites that you want to include periodically SSLCertificateFile - this is the PEM file, that contains the site certificate AND the intermediate certificate. We still need the 'SSLCertificateChainFile' line in our configuration, but it will simply specify the same PEM file again. SSLCertificateKeyFile - the PEM file for the private key, generated with the certbot request. SSLCertificateChainFile - the certificate from your certificate provider, often called the intermediate certificate, in this case exactly like the 'SSLCertificateFile' location above. Once you have made all of your changes, simply restart httpd and if it starts test your site to make sure you now have a valid certificate file showing. If so, you are ready to move on to the next step.","title":"The Site Configuration - https"},{"location":"guides/generating_ssl_keys_lets_encrypt/#automating-lets-encrypt-certificate-renewal","text":"The beauty of installing certbot is that the Let's Encrypt certificate will be automatically renewed. There is no need to create a process to do this. We do need to test the renewal with: certbot renew --dry-run When you run this command, you'll get a nice output showing the renewal process: Saving debug log to /var/log/letsencrypt/letsencrypt.log - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Processing /etc/letsencrypt/renewal/yourdomain.com.conf - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Cert not due for renewal, but simulating renewal for dry run Plugins selected: Authenticator apache, Installer apache Account registered. Simulating renewal of an existing certificate for yourdomain.com Performing the following challenges: http-01 challenge for yourdomain.com Waiting for verification... Cleaning up challenges - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - new certificate deployed with reload of apache server; fullchain is /etc/letsencrypt/live/yourdomain.com/fullchain.pem - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - Congratulations, all simulated renewals succeeded: /etc/letsencrypt/live/yourdomain.com/fullchain.pem (success) - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - The certbot documentation tells you in their step number 8, that the automatic renewal process could be in a couple of different spots, depending on your system. For a Rocky Linux install, you are going to find the process by using: systemctl list-timers Which gives you a list of processes, one of which will be for certbot : Sat 2021-04-03 07:12:00 UTC 14h left n/a n/a snap.certbot.renew.timer snap.certbot.renew.service","title":"Automating Let's Encrypt Certificate Renewal"},{"location":"guides/generating_ssl_keys_lets_encrypt/#conclusions","text":"Let's Encrypt SSL certificates are yet another option for securing your web site with an SSL. Once installed, the system provides automatic renewal of certificates and will encrypt traffic to your web site. It should be noted that Let's Encrypt certificates are used for standard DV (Domain Validation) certificates. They cannot be used for OV (Organization Validation) or EV (Extended Validation) certificates.","title":"Conclusions"},{"location":"guides/import_rocky_to_wsl_howto/","text":"Import Rocky Linux to WSL[2] with Virtualbox and Docker \u00b6 Prerequisites \u00b6 Linux PC running VirtualBox - VirtualBox will not run under windows 10 with WSL2, which is needed for later steps. You can also use a dual boot PC, or a live distribution, but make sure you have VirtualBox available. Windows 10 PC running WSL2 Internet access Introduction \u00b6 This guide shows the steps to create a tar image for a Docker container, and how to import that image into the Windows Subsystem for Linux (WSL). The steps outlined below are largely taken from Microsoft's Import any Linux distribution to use with WSL and from Docker's Create a base image , and adapted to the new distribution. Please note that you do not need Docker to accomplish this task. If you go to either of the original guides for reference, do not install Docker on your PC(s), unless you need it for other purposes. This guide assumes the user is familiar with VirtualBox, and knows how to perform tasks like installing the VirtualBoxAdditions, and mounting shared drives. It is also important to be familiar with the limitations of WSL, which will cause some functionality to break, work slowly, or work in unexpected ways. Depending on what you want to accomplish, the resulting distribution may or may not do what you want it to do. There are no guarantees. Install Steps \u00b6 On Linux PC with VirtualBox \u00b6 Download the minimal image from Rocky Linux . Boot and install Rocky Linux on a new VirtualBox VM. The default settings are fine. Install VirtualBoxAdditions on your VM. This will require installing additional packages (as shown in the suggested command): $ sudo yum install gcc make kernel-devel bzip2 binutils patch libgomp glibc-headers glibc-devel kernel-headers elfutils-libelf-devel tar Make a working directory, and copy files to be used for the tar image. $ mkdir wsl_tar $ cd wsl_tar $ cp -p /etc/yum.conf . $ cp -p /etc/yum.repos.d/Rocky-BaseOS.repo . Edit your copy of yum.conf and add this line to it (modify the path as needed): reposdir=/home/<your_username>/wsl_tar/ Download the script to create a base image from Docker GitHub. The script is called mkimage-yum.sh . Modify the script to create a tar file at the end, instead of starting Docker. Here are the suggested changes to the file: ## Change line 143 to simply create the tar file, without invoking Docker tar --numeric-owner -c -C \"$target\" . -f <path-to-the-new-tar-file> ## Comment out line 145 Execute the script using this command (modify the path as needed): $ sudo ./mkimage-yum.sh -y /home/<your_username>/wsl_tar/yum.conf baseos After the script finishes, your new tar file will be in the path you entered in the script above. Mount a shared drive with the host and move the tar file there. You could also move the file to a USB drive or folder accessible to the Windows 10 PC. After moving the file to an external drive or folder, you won't need the VM anymore. You can delete it or modify it for other purposes. On your Windows 10 PC \u00b6 Create a directory to hold the Rocky Linux filesystem. In a PowerShell prompt, import Rocky Linux (it's named rocky_rc here, but you can name it anything you like). wsl --import rocky_rc <Path to RockyLinuxDirectory> <Path to tar file from above> Verify Rocky Linux is installed with: wsl -l -v Launch Rocky Linux with wsl -d rocky_rc Set up Rocky Linux with the following bash commands (you'll need to be running as root). yum update yum install glibc-langpack-en -y yum reinstall passwd sudo cracklib-dicts -y newUsername=<your new username> adduser -G wheel $newUsername echo -e \"[user]\\ndefault=$newUsername\" >> /etc/wsl.conf passwd $newUsername Exit the bash prompt (Ctrl+D or exit). Back in a PowerShell prompt, shutdown all WSL running instances and start Rocky. wsl --shutdown wsl -d rocky_rc Test and enjoy! If you have Windows Terminal installed, the new WSL distro name will appear as an option on the pull-down menu, which is quite handy to launch it in the future. You can then customize it with colors, fonts, etc. Even though you need WSL2 in order to perform the steps above, you can use the distro as WSL 1 or 2, by converting it with PowerShell commands.","title":"Import Rocky Linux to WSL[2] with Virtualbox and Docker"},{"location":"guides/import_rocky_to_wsl_howto/#import-rocky-linux-to-wsl2-with-virtualbox-and-docker","text":"","title":"Import Rocky Linux to WSL[2] with Virtualbox and Docker"},{"location":"guides/import_rocky_to_wsl_howto/#prerequisites","text":"Linux PC running VirtualBox - VirtualBox will not run under windows 10 with WSL2, which is needed for later steps. You can also use a dual boot PC, or a live distribution, but make sure you have VirtualBox available. Windows 10 PC running WSL2 Internet access","title":"Prerequisites"},{"location":"guides/import_rocky_to_wsl_howto/#introduction","text":"This guide shows the steps to create a tar image for a Docker container, and how to import that image into the Windows Subsystem for Linux (WSL). The steps outlined below are largely taken from Microsoft's Import any Linux distribution to use with WSL and from Docker's Create a base image , and adapted to the new distribution. Please note that you do not need Docker to accomplish this task. If you go to either of the original guides for reference, do not install Docker on your PC(s), unless you need it for other purposes. This guide assumes the user is familiar with VirtualBox, and knows how to perform tasks like installing the VirtualBoxAdditions, and mounting shared drives. It is also important to be familiar with the limitations of WSL, which will cause some functionality to break, work slowly, or work in unexpected ways. Depending on what you want to accomplish, the resulting distribution may or may not do what you want it to do. There are no guarantees.","title":"Introduction"},{"location":"guides/import_rocky_to_wsl_howto/#install-steps","text":"","title":"Install Steps"},{"location":"guides/import_rocky_to_wsl_howto/#on-linux-pc-with-virtualbox","text":"Download the minimal image from Rocky Linux . Boot and install Rocky Linux on a new VirtualBox VM. The default settings are fine. Install VirtualBoxAdditions on your VM. This will require installing additional packages (as shown in the suggested command): $ sudo yum install gcc make kernel-devel bzip2 binutils patch libgomp glibc-headers glibc-devel kernel-headers elfutils-libelf-devel tar Make a working directory, and copy files to be used for the tar image. $ mkdir wsl_tar $ cd wsl_tar $ cp -p /etc/yum.conf . $ cp -p /etc/yum.repos.d/Rocky-BaseOS.repo . Edit your copy of yum.conf and add this line to it (modify the path as needed): reposdir=/home/<your_username>/wsl_tar/ Download the script to create a base image from Docker GitHub. The script is called mkimage-yum.sh . Modify the script to create a tar file at the end, instead of starting Docker. Here are the suggested changes to the file: ## Change line 143 to simply create the tar file, without invoking Docker tar --numeric-owner -c -C \"$target\" . -f <path-to-the-new-tar-file> ## Comment out line 145 Execute the script using this command (modify the path as needed): $ sudo ./mkimage-yum.sh -y /home/<your_username>/wsl_tar/yum.conf baseos After the script finishes, your new tar file will be in the path you entered in the script above. Mount a shared drive with the host and move the tar file there. You could also move the file to a USB drive or folder accessible to the Windows 10 PC. After moving the file to an external drive or folder, you won't need the VM anymore. You can delete it or modify it for other purposes.","title":"On Linux PC with VirtualBox"},{"location":"guides/import_rocky_to_wsl_howto/#on-your-windows-10-pc","text":"Create a directory to hold the Rocky Linux filesystem. In a PowerShell prompt, import Rocky Linux (it's named rocky_rc here, but you can name it anything you like). wsl --import rocky_rc <Path to RockyLinuxDirectory> <Path to tar file from above> Verify Rocky Linux is installed with: wsl -l -v Launch Rocky Linux with wsl -d rocky_rc Set up Rocky Linux with the following bash commands (you'll need to be running as root). yum update yum install glibc-langpack-en -y yum reinstall passwd sudo cracklib-dicts -y newUsername=<your new username> adduser -G wheel $newUsername echo -e \"[user]\\ndefault=$newUsername\" >> /etc/wsl.conf passwd $newUsername Exit the bash prompt (Ctrl+D or exit). Back in a PowerShell prompt, shutdown all WSL running instances and start Rocky. wsl --shutdown wsl -d rocky_rc Test and enjoy! If you have Windows Terminal installed, the new WSL distro name will appear as an option on the pull-down menu, which is quite handy to launch it in the future. You can then customize it with colors, fonts, etc. Even though you need WSL2 in order to perform the steps above, you can use the distro as WSL 1 or 2, by converting it with PowerShell commands.","title":"On your Windows 10 PC"},{"location":"guides/mirroring_lsyncd/","text":"Mirroring Solution - lsycnd \u00b6 Prerequisites \u00b6 This is everything you'll need to understand and follow along with this guide: A machine running Rocky Linux A comfort level with modifying configuration files from the command-line Knowledge of how to use a command line editor (we use vi here, but you could use your favorite editor) You will need root access, and ideally be signed in as the root user in your terminal Public and Private SSH key pairs The EPEL repositories from Fedora You will need to be familair with inotify , an event monitor interface Optional: familiarity with tail Introduction \u00b6 If you're looking for a way to synchronize files and folders between computers automatically, lsyncd is a pretty great option. The only downside for beginners? You have to configure everything via the command line, and text files. Even so, it's a program worth learning for any sysadmin. The best description of lsyncd , comes from its own man page. Slightly paraphrased, lsyncd is a light-weight live mirror solution that is comparatively easy to install. It doesn't require new filesystems or blockdevices, and does not hamper local filesystem performance. In short, it mirrors files. lsyncd watches a local directory trees event monitor interface (inotify). It aggregates and combines events for a few seconds, and then spawns one (or more) process(es) to synchronize the changes. By default this is rsync. For the purposes of this guide, we will call the system with the original files the \"master\", and the one that we are synchronizing to will be the \"target\". It is actually possible to completely mirror a server using lsyncd by very carefully specifying directories and files that you want to synchronize. It's pretty sweet! For remote syncing, you will also want to set up Rocky Linux SSH Public Private Key Pairs . The examples here use SSH (port 22). Installing lsycnd \u00b6 There are actually two ways to install lsyncd. We will include them both here, but the preferred method is to install from source. It's relatively easy to do this and there are few dependencies required. The RPM tends to lag behind the source packages by a little. That said, we want to give you both options and let you choose. Installing lsycnd - RPM Method \u00b6 Installing the RPM version is relatively easy. The only thing you will need to install first is the EPEL software repository from Fedora. This can be done with a single command: dnf install https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm To install lsyncd, then, we just need to install it, and any missing dependencies will be installed along with it: dnf install lsyncd That's it! Installing lsycnd - Source Method \u00b6 Installing from source is not as bad is it sounds. Just follow this guide and you will be up and running in no time! Install Dependencies \u00b6 We will need some dependencies: a few that are required by lsyncd itself, and a few that are required to build packages from source. Use this command on your Rocky Linux machine to make sure you have the dependencies you need. If you are going to be building from source, it's a good idea to have all of the development tools installed: dnf install groupinstall 'Development Tools' And here are the dependencies we need for lsyncd itself, and its build process: dnf install lua lua-libs lua-devel cmake unzip wget rsync Download lsycnd And Build It \u00b6 Next we need the source code: wget https://github.com/axkibe/lsyncd/archive/master.zip Now unzip the master.zip file: unzip master.zip This will create a directory called \"lsyncd-master\". We need to change to this directory and create a directory called build: cd lsyncd-master And then: mkdir build Now change directories again so that you are in the build directory: cd build Now execute these commands: cmake .. make make install When done, you should have the lsyncd binary installed and ready for use in /usr/local/bin lsycnd Systemd Service \u00b6 Neither install method will create a systemd service for starting lsyncd on a reboot. We want to be able to do just that, because if you are mirroring files, you don't want the mirror to be offline because you forgot to manually start a service. That's very embarrassing for any sysadmin! Creating the systemd service is not terribly difficult, though, and will save you a lot of time in the long run. Create The lsyncd Service File \u00b6 This file can be created anywhere, even in the root directory of your server. Once it is created, we can easily move it the right location. vi /root/lsyncd.service The contents of this file should be: [Unit] Description=Live Syncing (Mirror) Daemon After=network.target [Service] Restart=always Type=simple Nice=19 ExecStart=/usr/local/bin/lsyncd -nodaemon -pidfile /run/lsyncd.pid /etc/lsyncd.conf ExecReload=/bin/kill -HUP $MAINPID PIDFile=/run/lsyncd.pid [Install] WantedBy=multi-user.target Now let's install the file you just made to the correct location: install -Dm0644 /root/lsyncd.service /usr/lib/systemd/system/lsyncd.service Finally, reload the systemctl daemon so that systemd will \"see\" the new service file: systemctl daemon-reload lsycnd Configuration \u00b6 Whichever method you choose for installing lsyncd, you will need a configuration file: /etc/lsyncd.conf . The next section will tell you how to build a simple configuration file, and test it. Sample Configuration For Testing \u00b6 Here's an example of a simple configuration file that synchronizes /home to another machine. Our target machine is going to be a local IP address: 192.168.1.40 settings { logfile = \"/var/log/lsyncd.log\", statusFile = \"/var/log/lsyncd-status.log\", statusInterval = 20 maxProcesses = 1 } sync { default.rsyncssh, source=\"/home\", host=\"root@192.168.1.40\", excludeFrom=\"/etc/lsyncd.exclude\", targetdir=\"/home\", rsync = { archive = true, compress = false, whole_file = false }, ssh = { port = 22 } } Breaking down this file a bit: The \"logfile\" and \"statusFile\" will be automatically created when the service starts. The \"statusInterval\" is the number of seconds to wait before writing to the statusFile. \"maxProcesses\" is the number of processes lsyncd is allowed to spawn. Honestly, unless you are running this on a super busy machine, 1 process is enough. In the sync section \"default.rsyncssh\" says to use rsync over ssh The \"source=\" is the directory path we are syncing from. The \"host=\" is our target machine that we are syncing to. The \"excludeFrom=\" tells lsyncd where the eclusions file is. It must exist, but can be empty. The \"targetdir=\" is the target directory we are sending files to. In most cases this will be equal to the source, but not always. Then we have the \"rsync =\" section, and these are the options that we are running rsync with. Finally we have the \"ssh =\" section, and this specifies the SSH port that is listening on the target machine. If you are adding more than one directory to sync, then you need to repeat the entire \"sync\" section including all the opening and closing brackets for each directory. The lsyncd.exclude File \u00b6 As noted earlier, the \"excludeFrom\" file must exist, so let's create that now: touch /etc/lsyncd.exclude If we were syncing the /etc folder on our machine, there would be a number of files and/or directories that we should leave out. Each excluded file or directory is simply listed in the file, one per line, like this: /etc/hostname /etc/hosts /etc/networks /etc/fstab Test And Turn Up \u00b6 Now that everything else is set up, we can test it all. For starters, lets make sure our systemd lsyncd.service will start: systemctl start lsyncd If no errors appear after executing this command, check the status of the service, just to make sure: systemctl status lsyncd If it shows the service running, use tail to see the ends of the two log files, and make sure everything show up OK: tail /var/log/lsyncd.log And then: tail /var/log/lsyncd-status.log Assuming that this all looks correct, navigate to the /home/[user] directory, where [user] is a user on the machine and crate a new file there with touch . touch /home/[user]/testfile Now go to the target machine and see if the file shows up. If so, everything is working as it should. Set the lsyncd.service to start on boot with: systemctl enable lsyncd And you should be ready to go. Remember To Be Careful \u00b6 Anytime you are synchronizing a set of files or directories to another machine, think carefully about the effect it will have on the target machine. If you go back to The lsyncd.exclude File in our example above, can you imagine what might happen if /etc/fstab is synchronized? For newbies, fstab is the file that is used to configure storage drives on any Linux machine. The disks and labels are almost certainly different. The next time the target machine was rebooted it would likely fail to boot entirely. Conclusions And References \u00b6 lsycnd is a powerful tool for directory synchronization between machines. As you've seen, it's not hard to install, and it's easy to maintain going forward. Can't ask for more than that. You can find out more about lsyncd by going to The Official Site","title":"Mirroring Solution - lsycnd"},{"location":"guides/mirroring_lsyncd/#mirroring-solution-lsycnd","text":"","title":"Mirroring Solution - lsycnd"},{"location":"guides/mirroring_lsyncd/#prerequisites","text":"This is everything you'll need to understand and follow along with this guide: A machine running Rocky Linux A comfort level with modifying configuration files from the command-line Knowledge of how to use a command line editor (we use vi here, but you could use your favorite editor) You will need root access, and ideally be signed in as the root user in your terminal Public and Private SSH key pairs The EPEL repositories from Fedora You will need to be familair with inotify , an event monitor interface Optional: familiarity with tail","title":"Prerequisites"},{"location":"guides/mirroring_lsyncd/#introduction","text":"If you're looking for a way to synchronize files and folders between computers automatically, lsyncd is a pretty great option. The only downside for beginners? You have to configure everything via the command line, and text files. Even so, it's a program worth learning for any sysadmin. The best description of lsyncd , comes from its own man page. Slightly paraphrased, lsyncd is a light-weight live mirror solution that is comparatively easy to install. It doesn't require new filesystems or blockdevices, and does not hamper local filesystem performance. In short, it mirrors files. lsyncd watches a local directory trees event monitor interface (inotify). It aggregates and combines events for a few seconds, and then spawns one (or more) process(es) to synchronize the changes. By default this is rsync. For the purposes of this guide, we will call the system with the original files the \"master\", and the one that we are synchronizing to will be the \"target\". It is actually possible to completely mirror a server using lsyncd by very carefully specifying directories and files that you want to synchronize. It's pretty sweet! For remote syncing, you will also want to set up Rocky Linux SSH Public Private Key Pairs . The examples here use SSH (port 22).","title":"Introduction"},{"location":"guides/mirroring_lsyncd/#installing-lsycnd","text":"There are actually two ways to install lsyncd. We will include them both here, but the preferred method is to install from source. It's relatively easy to do this and there are few dependencies required. The RPM tends to lag behind the source packages by a little. That said, we want to give you both options and let you choose.","title":"Installing lsycnd"},{"location":"guides/mirroring_lsyncd/#installing-lsycnd-rpm-method","text":"Installing the RPM version is relatively easy. The only thing you will need to install first is the EPEL software repository from Fedora. This can be done with a single command: dnf install https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm To install lsyncd, then, we just need to install it, and any missing dependencies will be installed along with it: dnf install lsyncd That's it!","title":"Installing lsycnd - RPM Method"},{"location":"guides/mirroring_lsyncd/#installing-lsycnd-source-method","text":"Installing from source is not as bad is it sounds. Just follow this guide and you will be up and running in no time!","title":"Installing lsycnd - Source Method"},{"location":"guides/mirroring_lsyncd/#install-dependencies","text":"We will need some dependencies: a few that are required by lsyncd itself, and a few that are required to build packages from source. Use this command on your Rocky Linux machine to make sure you have the dependencies you need. If you are going to be building from source, it's a good idea to have all of the development tools installed: dnf install groupinstall 'Development Tools' And here are the dependencies we need for lsyncd itself, and its build process: dnf install lua lua-libs lua-devel cmake unzip wget rsync","title":"Install Dependencies"},{"location":"guides/mirroring_lsyncd/#download-lsycnd-and-build-it","text":"Next we need the source code: wget https://github.com/axkibe/lsyncd/archive/master.zip Now unzip the master.zip file: unzip master.zip This will create a directory called \"lsyncd-master\". We need to change to this directory and create a directory called build: cd lsyncd-master And then: mkdir build Now change directories again so that you are in the build directory: cd build Now execute these commands: cmake .. make make install When done, you should have the lsyncd binary installed and ready for use in /usr/local/bin","title":"Download lsycnd And Build It"},{"location":"guides/mirroring_lsyncd/#lsycnd-systemd-service","text":"Neither install method will create a systemd service for starting lsyncd on a reboot. We want to be able to do just that, because if you are mirroring files, you don't want the mirror to be offline because you forgot to manually start a service. That's very embarrassing for any sysadmin! Creating the systemd service is not terribly difficult, though, and will save you a lot of time in the long run.","title":"lsycnd Systemd Service"},{"location":"guides/mirroring_lsyncd/#create-the-lsyncd-service-file","text":"This file can be created anywhere, even in the root directory of your server. Once it is created, we can easily move it the right location. vi /root/lsyncd.service The contents of this file should be: [Unit] Description=Live Syncing (Mirror) Daemon After=network.target [Service] Restart=always Type=simple Nice=19 ExecStart=/usr/local/bin/lsyncd -nodaemon -pidfile /run/lsyncd.pid /etc/lsyncd.conf ExecReload=/bin/kill -HUP $MAINPID PIDFile=/run/lsyncd.pid [Install] WantedBy=multi-user.target Now let's install the file you just made to the correct location: install -Dm0644 /root/lsyncd.service /usr/lib/systemd/system/lsyncd.service Finally, reload the systemctl daemon so that systemd will \"see\" the new service file: systemctl daemon-reload","title":"Create The lsyncd Service File"},{"location":"guides/mirroring_lsyncd/#lsycnd-configuration","text":"Whichever method you choose for installing lsyncd, you will need a configuration file: /etc/lsyncd.conf . The next section will tell you how to build a simple configuration file, and test it.","title":"lsycnd Configuration"},{"location":"guides/mirroring_lsyncd/#sample-configuration-for-testing","text":"Here's an example of a simple configuration file that synchronizes /home to another machine. Our target machine is going to be a local IP address: 192.168.1.40 settings { logfile = \"/var/log/lsyncd.log\", statusFile = \"/var/log/lsyncd-status.log\", statusInterval = 20 maxProcesses = 1 } sync { default.rsyncssh, source=\"/home\", host=\"root@192.168.1.40\", excludeFrom=\"/etc/lsyncd.exclude\", targetdir=\"/home\", rsync = { archive = true, compress = false, whole_file = false }, ssh = { port = 22 } } Breaking down this file a bit: The \"logfile\" and \"statusFile\" will be automatically created when the service starts. The \"statusInterval\" is the number of seconds to wait before writing to the statusFile. \"maxProcesses\" is the number of processes lsyncd is allowed to spawn. Honestly, unless you are running this on a super busy machine, 1 process is enough. In the sync section \"default.rsyncssh\" says to use rsync over ssh The \"source=\" is the directory path we are syncing from. The \"host=\" is our target machine that we are syncing to. The \"excludeFrom=\" tells lsyncd where the eclusions file is. It must exist, but can be empty. The \"targetdir=\" is the target directory we are sending files to. In most cases this will be equal to the source, but not always. Then we have the \"rsync =\" section, and these are the options that we are running rsync with. Finally we have the \"ssh =\" section, and this specifies the SSH port that is listening on the target machine. If you are adding more than one directory to sync, then you need to repeat the entire \"sync\" section including all the opening and closing brackets for each directory.","title":"Sample Configuration For Testing"},{"location":"guides/mirroring_lsyncd/#the-lsyncdexclude-file","text":"As noted earlier, the \"excludeFrom\" file must exist, so let's create that now: touch /etc/lsyncd.exclude If we were syncing the /etc folder on our machine, there would be a number of files and/or directories that we should leave out. Each excluded file or directory is simply listed in the file, one per line, like this: /etc/hostname /etc/hosts /etc/networks /etc/fstab","title":"The lsyncd.exclude File"},{"location":"guides/mirroring_lsyncd/#test-and-turn-up","text":"Now that everything else is set up, we can test it all. For starters, lets make sure our systemd lsyncd.service will start: systemctl start lsyncd If no errors appear after executing this command, check the status of the service, just to make sure: systemctl status lsyncd If it shows the service running, use tail to see the ends of the two log files, and make sure everything show up OK: tail /var/log/lsyncd.log And then: tail /var/log/lsyncd-status.log Assuming that this all looks correct, navigate to the /home/[user] directory, where [user] is a user on the machine and crate a new file there with touch . touch /home/[user]/testfile Now go to the target machine and see if the file shows up. If so, everything is working as it should. Set the lsyncd.service to start on boot with: systemctl enable lsyncd And you should be ready to go.","title":"Test And Turn Up"},{"location":"guides/mirroring_lsyncd/#remember-to-be-careful","text":"Anytime you are synchronizing a set of files or directories to another machine, think carefully about the effect it will have on the target machine. If you go back to The lsyncd.exclude File in our example above, can you imagine what might happen if /etc/fstab is synchronized? For newbies, fstab is the file that is used to configure storage drives on any Linux machine. The disks and labels are almost certainly different. The next time the target machine was rebooted it would likely fail to boot entirely.","title":"Remember To Be Careful"},{"location":"guides/mirroring_lsyncd/#conclusions-and-references","text":"lsycnd is a powerful tool for directory synchronization between machines. As you've seen, it's not hard to install, and it's easy to maintain going forward. Can't ask for more than that. You can find out more about lsyncd by going to The Official Site","title":"Conclusions And References"},{"location":"guides/package_build_troubleshooting/","text":"First get Familiar with the Mock build tool: \u00b6 Once you get through that, the biggest and most relevant technical/intro page for our package debugging effort is this: https://wiki.rockylinux.org/en/team/development/Mock_Build_Howto We are using the \u201cmock\u201d program to perform our builds, just like the real Rocky infrastructure will. You should install it and get very used to it. Please use this guide to get started, and explain a bit about what we hope to achieve and why we have to build all these packages in a specific order. Please read those carefully, and maybe dip your toe in the water by feeding your mock an SRPM or 2 and compiling some things. Mock is really great, as it\u2019s an easy-to-call program that constructs an entire system inside a chroot to perform the build, then cleans it up afterwards. If you\u2019d like a reference for Mock config files to look at or play with, there are some published here (that correspond with the \u201cBuild Passes\u201d being done to test package builds): https://rocky.lowend.ninja/RockyDevel/mock_configs/ Once you\u2019re familiar with Mock (and especially digging through its output logs), we have a list of failing packages that we need to investigate and come up with explanations and/or fixes for. Intro - What needs to be done \u00b6 The area we need help the most right now, and the easiest way to contribute, is to help troubleshoot failing package builds. We\u2019re rebuilding CentOS 8.3 as \u201cpractice\u201d, so we can figure out any issues that crop up with our official Rocky build ahead of time. We are documenting any errors we find in the packages and how to fix them (to make it build). This documentation will help our release engineering team when it comes time to do official builds. Helping with the debug effort: \u00b6 Once you are familiar with Mock, and especially with debugging its output, you can begin looking at failing packages. Some of this information is also on the Mock HowTo page linked above. Find a failing package on the newest build pass failures page (currently Build Pass 10: https://wiki.rockylinux.org/en/team/development/Build_Order/Build_Pass_10_Failure) Make sure the package hasn\u2019t already been looked at and/or fixed: https://wiki.rockylinux.org/en/team/development/Package_Error_Tracking Let other debuggers know what you\u2019re working on! We don\u2019t want to duplicate effort. Hop on chat.rockylinux.org (#dev/packaging channel) and let us know! Set your mock program up with the most recent configs that we are using (linked above). You can use it to attempt the build in the same way as we do (with external dependencies, extra repos, etc.) Investigate the error(s): You can use your own mock, as well as the log files from when the build failed, located here: https://rocky.lowend.ninja/RockyDevel/MOCK_RAW/ Figure out what\u2019s going on, and how to fix it. It may take the form of special mock settings, or a patch added to the program + specfile. Report your findings to the #Dev/Packaging channel, and someone will record them on the Wiki Package_Error_Tracking page linked above. The idea is to shrink the Build Failures, and grow the Package_Error_Tracking page. If necessary, we will commit build fixes to our patch repo for the different packages located here: https://git.rockylinux.org/staging/patch.","title":"Package build troubleshooting"},{"location":"guides/package_build_troubleshooting/#first-get-familiar-with-the-mock-build-tool","text":"Once you get through that, the biggest and most relevant technical/intro page for our package debugging effort is this: https://wiki.rockylinux.org/en/team/development/Mock_Build_Howto We are using the \u201cmock\u201d program to perform our builds, just like the real Rocky infrastructure will. You should install it and get very used to it. Please use this guide to get started, and explain a bit about what we hope to achieve and why we have to build all these packages in a specific order. Please read those carefully, and maybe dip your toe in the water by feeding your mock an SRPM or 2 and compiling some things. Mock is really great, as it\u2019s an easy-to-call program that constructs an entire system inside a chroot to perform the build, then cleans it up afterwards. If you\u2019d like a reference for Mock config files to look at or play with, there are some published here (that correspond with the \u201cBuild Passes\u201d being done to test package builds): https://rocky.lowend.ninja/RockyDevel/mock_configs/ Once you\u2019re familiar with Mock (and especially digging through its output logs), we have a list of failing packages that we need to investigate and come up with explanations and/or fixes for.","title":"First get Familiar with the Mock build tool:"},{"location":"guides/package_build_troubleshooting/#intro-what-needs-to-be-done","text":"The area we need help the most right now, and the easiest way to contribute, is to help troubleshoot failing package builds. We\u2019re rebuilding CentOS 8.3 as \u201cpractice\u201d, so we can figure out any issues that crop up with our official Rocky build ahead of time. We are documenting any errors we find in the packages and how to fix them (to make it build). This documentation will help our release engineering team when it comes time to do official builds.","title":"Intro - What needs to be done"},{"location":"guides/package_build_troubleshooting/#helping-with-the-debug-effort","text":"Once you are familiar with Mock, and especially with debugging its output, you can begin looking at failing packages. Some of this information is also on the Mock HowTo page linked above. Find a failing package on the newest build pass failures page (currently Build Pass 10: https://wiki.rockylinux.org/en/team/development/Build_Order/Build_Pass_10_Failure) Make sure the package hasn\u2019t already been looked at and/or fixed: https://wiki.rockylinux.org/en/team/development/Package_Error_Tracking Let other debuggers know what you\u2019re working on! We don\u2019t want to duplicate effort. Hop on chat.rockylinux.org (#dev/packaging channel) and let us know! Set your mock program up with the most recent configs that we are using (linked above). You can use it to attempt the build in the same way as we do (with external dependencies, extra repos, etc.) Investigate the error(s): You can use your own mock, as well as the log files from when the build failed, located here: https://rocky.lowend.ninja/RockyDevel/MOCK_RAW/ Figure out what\u2019s going on, and how to fix it. It may take the form of special mock settings, or a patch added to the program + specfile. Report your findings to the #Dev/Packaging channel, and someone will record them on the Wiki Package_Error_Tracking page linked above. The idea is to shrink the Build Failures, and grow the Package_Error_Tracking page. If necessary, we will commit build fixes to our patch repo for the different packages located here: https://git.rockylinux.org/staging/patch.","title":"Helping with the debug effort:"},{"location":"guides/package_debranding/","text":"This explains how to debrand a package for the Rocky Linux distribution. General Instructions First, identify the files in the package that need to be changed. They could be text files, image files, or others. You can identify the file(s) by digging into git.centos.org/rpms/PACKAGE/ Develop replacements for these files, but with Rocky branding placed instead. Diff/patch files may be needed as well for certain types of text, depends on the content being replaced. Replacement files go under https://git.rockylinux.org/patch/PACKAGE/ROCKY/_supporting/ Config file (specifying how to apply the patches) goes in https://git.rockylinux.org/patch/PACKAGE/ROCKY/CFG/*.cfg Note: Use spaces, not tabs. When srpmproc goes to import the package to Rocky, it will see the work done in https://git.rockylinux.org/patch/PACKAGE , and apply the stored debranding patches by reading the config file(s) under ROCKY/CFG/*.cfg from https://wiki.rockylinux.org/en/team/development/debranding/how-to","title":"Rocky package debranding How-To "},{"location":"guides/package_dev_start/","text":"Rocky Devtools refers to a set of home grown scripts and utlities created by members of the Rocky Linux community to help with sourcing, creating, branding, patching and building software packages distributed with the Rocky Linux Operating system. Rocky devtools consists of rockyget , rockybuild , rockypatch , and rockyprep . At a low level Rocky Devtools is a wrapper for running some custom and tradtional programs that are used for various package management tasks. Rocky Devtools relies heavily on srpmproc , go , git , and rpmbuild . You'll need an existing modern RPM based Linux system to install and use Rocky devtools. Let's walk through a typical installation and usage scenario of the devtools. 1. Download Rocky Devtools \u00b6 Download the devtools zipped source from the following URL: https://github.com/rocky-linux/devtools/archive/refs/heads/main.zip Here we use the curl command: curl -OJL https://github.com/rocky-linux/devtools/archive/refs/heads/main.zip You should now have a zipped archive named devtools-main.zip 2. Install Rocky Devtools \u00b6 Locate and uncompress the devtools archive that you just downloaded. Here we'll use the unzip command line utility: unzip devtools-main.zip Change your working directory to the new devtool source directory that was just created: cd devtools-main Run make to configure and compile devtools: make Install devtools: sudo make install 3. Use Rocky Devtools (rockyget) to search for and download Source RPMs (SRPMs) \u00b6 Once installed, the main utility for finding and downloading SRPMs is the rockyget utility. Let's use rockyget to download the SRPM for the popular sed package: rockyget sed The first time rockyget is run, it will automatically create a directory structure that roughly mimics the repository structure of Rocky's build servers. For example the ~/rocky/rpms folder will be automaically created. For our current sed example, its sources will be stored under the following sample folder hierchy: ~rocky/rpms/sed/ \u2514\u2500\u2500 r8 \u251c\u2500\u2500 SOURCES \u2502 \u251c\u2500\u2500 sed-4.2.2-binary_copy_args.patch \u2502 \u251c\u2500\u2500 sed-4.5.tar.xz \u2502 \u251c\u2500\u2500 sedfaq.txt \u2502 \u251c\u2500\u2500 sed-fuse.patch \u2502 \u2514\u2500\u2500 sed-selinux.patch \u2514\u2500\u2500 SPECS \u2514\u2500\u2500 sed.spec TIP : \u00b6 Once you have the original sources, this might be a good time to look through the SPECs file ( ~rocky/rpms/sed/SPECS/specs.spec ) to look for potential debranding opportinites in the given package. Debranding might include replacing upstream artwork/logos and so on. TIP \u00b6 If you are looking for other Rocky packages to build and experiment with, you can browse the list of packages that are currently failing in the Rocky automated build environment here - https://kojidev.rockylinux.org/koji/builds?state=3&order=-build_id 4. Use Rocky Devtools (rockybuild) to build a new package for the Rocky OS \u00b6 Under the hood, rockybuild calls rpmbuild and mock utilities to build the source package in a chroot environment for the application specified on the command-line. It relies on the application sources and RPM SPEC file that was automatically downloaded via the rockyget command. Use rockybuild to build the sed utility: rockybuild sed The time needed to complete the build process/step depends on the size and complexity of the application you are trying to build. At the end of the rockybuild run, an output similar to the one here indicates that the build completed successfully. .......... + exit 0 Finish: rpmbuild sed-4.5-2.el8.src.rpm Finish: build phase for sed-4.5-2.el8.src.rpm INFO: Done(~/rocky/rpms/sed/r8/SRPMS/sed-4.5-2.el8.src.rpm) Config(baseos) 4 minutes 34 seconds INFO: Results and/or logs in: /home/centos/rocky/builds/sed/r8 ........ If all goes well you should end up with a Rocky ready SRPM file under the ~/rocky/builds/sed/r8 directory. ~/rocky/rpms/sed/r8/SRPMS/sed-4.5-2.el8.src.rpm 5. Debugging a failed package build \u00b6 The previous rockybuild process will generate some log files that can be used in debugging failed application builds. The results and/or logs of the build process are stored under the ~/rocky/builds/<PACKAGE NAME>/r8 . For example ~/rocky/builds/sed/r8 ~/rocky/builds/sed/r8 \u251c\u2500\u2500 build.log \u251c\u2500\u2500 hw_info.log \u251c\u2500\u2500 installed_pkgs.log \u251c\u2500\u2500 root.log \u251c\u2500\u2500 sed-4.5-2.el8_3.src.rpm \u251c\u2500\u2500 sed-4.5-2.el8_3.x86_64.rpm \u251c\u2500\u2500 sed-debuginfo-4.5-2.el8_3.x86_64.rpm \u251c\u2500\u2500 sed-debugsource-4.5-2.el8_3.x86_64.rpm \u2514\u2500\u2500 state.log The main files to search for clues for the causes any error(s) are the build.log and root.log. The build.log file should detail all build errors and the root.log file will contain information about the chroot environment setup and tear down processes. With everything else being equal, most of the build debugging/troubleshooting process can be performed with the contents of the build.log file.","title":"Rocky Linux Devtools (Packaging and developer starter guide)"},{"location":"guides/package_dev_start/#1-download-rocky-devtools","text":"Download the devtools zipped source from the following URL: https://github.com/rocky-linux/devtools/archive/refs/heads/main.zip Here we use the curl command: curl -OJL https://github.com/rocky-linux/devtools/archive/refs/heads/main.zip You should now have a zipped archive named devtools-main.zip","title":"1. Download Rocky Devtools"},{"location":"guides/package_dev_start/#2-install-rocky-devtools","text":"Locate and uncompress the devtools archive that you just downloaded. Here we'll use the unzip command line utility: unzip devtools-main.zip Change your working directory to the new devtool source directory that was just created: cd devtools-main Run make to configure and compile devtools: make Install devtools: sudo make install","title":"2. Install Rocky Devtools"},{"location":"guides/package_dev_start/#3-use-rocky-devtools-rockyget-to-search-for-and-download-source-rpms-srpms","text":"Once installed, the main utility for finding and downloading SRPMs is the rockyget utility. Let's use rockyget to download the SRPM for the popular sed package: rockyget sed The first time rockyget is run, it will automatically create a directory structure that roughly mimics the repository structure of Rocky's build servers. For example the ~/rocky/rpms folder will be automaically created. For our current sed example, its sources will be stored under the following sample folder hierchy: ~rocky/rpms/sed/ \u2514\u2500\u2500 r8 \u251c\u2500\u2500 SOURCES \u2502 \u251c\u2500\u2500 sed-4.2.2-binary_copy_args.patch \u2502 \u251c\u2500\u2500 sed-4.5.tar.xz \u2502 \u251c\u2500\u2500 sedfaq.txt \u2502 \u251c\u2500\u2500 sed-fuse.patch \u2502 \u2514\u2500\u2500 sed-selinux.patch \u2514\u2500\u2500 SPECS \u2514\u2500\u2500 sed.spec","title":"3. Use Rocky Devtools (rockyget) to search for and download Source RPMs (SRPMs)"},{"location":"guides/package_dev_start/#tip","text":"Once you have the original sources, this might be a good time to look through the SPECs file ( ~rocky/rpms/sed/SPECS/specs.spec ) to look for potential debranding opportinites in the given package. Debranding might include replacing upstream artwork/logos and so on.","title":"TIP :"},{"location":"guides/package_dev_start/#tip_1","text":"If you are looking for other Rocky packages to build and experiment with, you can browse the list of packages that are currently failing in the Rocky automated build environment here - https://kojidev.rockylinux.org/koji/builds?state=3&order=-build_id","title":"TIP"},{"location":"guides/package_dev_start/#4-use-rocky-devtools-rockybuild-to-build-a-new-package-for-the-rocky-os","text":"Under the hood, rockybuild calls rpmbuild and mock utilities to build the source package in a chroot environment for the application specified on the command-line. It relies on the application sources and RPM SPEC file that was automatically downloaded via the rockyget command. Use rockybuild to build the sed utility: rockybuild sed The time needed to complete the build process/step depends on the size and complexity of the application you are trying to build. At the end of the rockybuild run, an output similar to the one here indicates that the build completed successfully. .......... + exit 0 Finish: rpmbuild sed-4.5-2.el8.src.rpm Finish: build phase for sed-4.5-2.el8.src.rpm INFO: Done(~/rocky/rpms/sed/r8/SRPMS/sed-4.5-2.el8.src.rpm) Config(baseos) 4 minutes 34 seconds INFO: Results and/or logs in: /home/centos/rocky/builds/sed/r8 ........ If all goes well you should end up with a Rocky ready SRPM file under the ~/rocky/builds/sed/r8 directory. ~/rocky/rpms/sed/r8/SRPMS/sed-4.5-2.el8.src.rpm","title":"4. Use Rocky Devtools (rockybuild) to build a new package for the Rocky OS"},{"location":"guides/package_dev_start/#5-debugging-a-failed-package-build","text":"The previous rockybuild process will generate some log files that can be used in debugging failed application builds. The results and/or logs of the build process are stored under the ~/rocky/builds/<PACKAGE NAME>/r8 . For example ~/rocky/builds/sed/r8 ~/rocky/builds/sed/r8 \u251c\u2500\u2500 build.log \u251c\u2500\u2500 hw_info.log \u251c\u2500\u2500 installed_pkgs.log \u251c\u2500\u2500 root.log \u251c\u2500\u2500 sed-4.5-2.el8_3.src.rpm \u251c\u2500\u2500 sed-4.5-2.el8_3.x86_64.rpm \u251c\u2500\u2500 sed-debuginfo-4.5-2.el8_3.x86_64.rpm \u251c\u2500\u2500 sed-debugsource-4.5-2.el8_3.x86_64.rpm \u2514\u2500\u2500 state.log The main files to search for clues for the causes any error(s) are the build.log and root.log. The build.log file should detail all build errors and the root.log file will contain information about the chroot environment setup and tear down processes. With everything else being equal, most of the build debugging/troubleshooting process can be performed with the contents of the build.log file.","title":"5. Debugging a failed package build"},{"location":"guides/package_signing/","text":"RPMs produced by us should be cryptographically signed with a Rocky Linux key, which guarantees to users that the package was indeed built by the Rocky Linux project. The package will also need to be put through some testing - preferably automated. The nature of the testing is yet to be determined, but we\u2019ll want to do some sanity checks at the bare minimum before unleashing it on the world. (Is this package installable? Did we accidentally miss any files? Does it cause dnf/yum dependency conflicts? etc.)","title":"Package signing and testing"},{"location":"guides/postfix_reporting/","text":"Using postfix For Server Process Reporting \u00b6 Prerequisites \u00b6 Complete comfort operating from the command line on a Rocky Linux server Familiarity with an editor of your choice (this document uses the vi editor, but you can substitute in your favorite editor) An understanding of DNS (the Domain Name System) and host names The ability to assign variables in a bash script Knowledge of what the tail , more , grep , and date commands do Introduction \u00b6 Many Rocky Linux server administrators write scripts to perform specific tasks, like backups or file synchronization, and many of these scripts generate logs that have useful and sometimes very important information. Just having the logs, though, is not enough. If a process fails and logs that failure, but the busy administrator does not review the log, then a catastrophe could be in the making. This document shows you how to use the postfix MTA (mail transfer agent) to grab log details from a particular process, and send them to you via email. It also touches on date formats in logs, and helps you identify which format you need to use in the reporting procedure. Keep in mind, though, that this is just the tip of the iceberg as far as what can be done with reporting via postfix. Please note, too, that it is always a good security move to limit running processes to only those that you will need all the time. This document shows you how to enable postfix only for the reporting you need it to do, and then shut it down again. Postfix Defined \u00b6 postfix is a server daemon used for sending email. It is more secure and simpler than sendmail, another MTA that was the default go-to MTA for years. It can be used as part of a full-featured mail server. Installing postfix \u00b6 Aside from postfix, we will need mailx for testing our ability to send emails. To install both, and any dependencies required, enter the following on the Rocky Linux server command line: dnf install postfix mailx Testing And Configuring Postfix \u00b6 Testing Mail First \u00b6 Before we configure postfix, we need to find out how mail will look when it leaves the server, because we will probably want to change this. To do this, start postfix: systemctl start postfix Then test it using mail command that is installed with mailx: mail -s \"Testing from server\" myname@mydomain.com This will bring up a blank line. Simply type your testing message in here: testing from the server Now hit enter, and enter a single period: . The system will respond with: EOT Our purpose for doing this is to check to see how our mail looks to the outside world, which we can get a feel for from the maillog that goes active with the starting of postfix. Use this command to see the output of the log file: tail /var/log/maillog You should see something like this, although the log file may have different domains for the email address, etc: Mar 4 16:51:40 hedgehogct postfix/postfix-script[735]: starting the Postfix mail system Mar 4 16:51:40 hedgehogct postfix/master[737]: daemon started -- version 3.3.1, configuration /etc/postfix Mar 4 16:52:04 hedgehogct postfix/pickup[738]: C9D42EC0ADD: uid=0 from=<root> Mar 4 16:52:04 hedgehogct postfix/cleanup[743]: C9D42EC0ADD: message-id=<20210304165204.C9D42EC0ADD@somehost.localdomain> Mar 4 16:52:04 hedgehogct postfix/qmgr[739]: C9D42EC0ADD: from=<root@somehost.localdomain>, size=457, nrcpt=1 (queue active) Mar 4 16:52:05 hedgehogct postfix/smtp[745]: connect to gmail-smtp-in.l.google.com[2607:f8b0:4001:c03::1a]:25: Network is unreachable Mar 4 16:52:06 hedgehogct postfix/smtp[745]: C9D42EC0ADD: to=<myname@mydomain.com>, relay=gmail-smtp-in.l.google.com[172.217.212.26] :25, delay=1.4, delays=0.02/0.02/0.99/0.32, dsn=2.0.0, status=sent (250 2.0.0 OK 1614876726 z8si17418573ilq.142 - gsmtp) Mar 4 16:52:06 hedgehogct postfix/qmgr[739]: C9D42EC0ADD: removed The \"somehost.localdomain\" shows us that we need to make some changes, so stop the postfix daemon first: systemctl stop postfix Configuring Postfix \u00b6 Since we aren't setting up a complete, fully functional mail server, the configuration options that we will be using are not as extensive. The first thing we need to do is to modify the main.cf file (literally the main configuration file for postfix), so let's make a backup first: cp /etc/postifix/main.cf /etc/postfix/main.cf.bak Then edit it: vi /etc/postfix/main.cf In our example, our server name is going to be \"bruno\" and our domain name is going to be \"ourdomain.com\". Find the line in the file: #myhostname = host.domain.tld You can either remove the remark (#) or you can add a new line under this line. Based on our example, the line would read: myhostname = bruno.ourdomain.com Next, find the line for the domain name: #mydomain = domain.tld Either remove the remark and change it, or add a new line: mydomain = ourdomain.com Finally, go to the bottom of the file and add this line: smtp_generic_maps = hash:/etc/postfix/generic Save your changes (in vi, that will be Shift : wq! ) and exit the file. Before we continue editing the generic file, we need to see how email will look. Specifically, we want to create the \"generic\" file that we referenced in the main.cf file above: vi /etc/postfix/generic This file tells postfix how any email coming from this server should look. Remember our test email and the log file? This is where we fix all of that: root@somehost.localdomain root@bruno.ourdomain.com @somehost.localdomain root@bruno.ourdomain.com Now we need to tell postfix to use all of our changes. This is done with the postmap command: postmap /etc/postfix/generic Now start postfix and test your email again using the same procedure as above. You should now see that all of the \"localdomain\" instances have been changed to your actual domain. The date Command And A Variable Called today \u00b6 Not every application will use the same logging format for the date. This means that you may have to get creative with any script you write for reporting by date. Let's say that you want to look at your system log as an example and pull everything that has to do with dbus-daemon for today's date, and email it to yourself. (It's probably not the greatest example, but it will give you an idea of how we would do this.) We need to use a a variable in our script that we will call \"today\" and we want it to relate to output from the \"date\" command and format it in a specific way, so that we can get the data we need from our system log (in /var/log/messages ). To start with, let's do some investigative work. First, enter the date command in the command line: date This should give you the default system date output, which could be something like this: Thu Mar 4 18:52:28 UTC 2021 Now let's check our system log and see how it records information. To do this, we will use the \"more\" and \"grep\" commands: more /var/log/messages | grep dbus-daemon Which should give you something like this: Mar 4 18:23:53 hedgehogct dbus-daemon[60]: [system] Successfully activated service 'org.freedesktop.nm_dispatcher' Mar 4 18:50:41 hedgehogct dbus-daemon[60]: [system] Activating via systemd: service name='org.freedesktop.nm_dispatcher' unit='dbus-org.freedesktop.nm-dispatcher.service' requested by ':1.1' (uid=0 pid=61 comm=\"/usr/sbin/NetworkManager --no-daemon \" label=\"unconfined\") Mar 4 18:50:41 hedgehogct dbus-daemon[60]: [system] Successfully activated service 'org.freedesktop.nm_dispatcher The date and log outputs need to be exactly the same in our script, so let's look at how to format the date using a variable called \"today\". First, let's look at what we need to do with the date to get the same output as the system log. You can reference the Linux man page or type man date on the command line to pull up the date manual page to get the information you need. What you will find is that in order to format the date the same way that /var/log/messages has it, we need to use the %b and %e format strings, with %b being the 3 character month and %e being the space-padded day. The Script \u00b6 For our bash script, we can see that we are going to use the date command and a variable called \"today\". (Keep in mind that \"today\" is arbitrary. You could call this variable \"late_for_dinner\" if you wanted!). We will call our script in this example, test.sh and place it in /usr/local/sbin : vi /usr/local/sbin/test.sh Let's start with, well, the beginning of our script. Note that even though the comment in our file says we are sending these messages to email, for now, we are just sending them to a standard log output so that we can verify that they are correct. Also, in our first attempt, we are grabbing all of the messages for the current date, not just the dbus-daemon messages. We will deal with that shortly. Another thing to be aware of is that the grep command will return the filename in the output, which we don't want in this case, so we have added the \"-h\" option to grep to remove the prefix of the filename. In addition, once the variable \"today\" is set, we need to look for the entire variable as a string, so we need it all in quotes: #!/bin/bash # set the date string to match /var/log/messages today=`date +\"%b %e\"` # grab the dbus-daemon messages and send them to email grep -h \"$today\" /var/log/messages That's it for now, so save your changes and then make the script executable: chmod +x /usr/local/sbin/test.sh And then let's test it: /usr/local/sbin/test.sh If all works correctly, you should get a long list of all of the messages in /var/log/messages from today, including but not limited to the dbus-daemon messages. If so, then the next step is to limit the messages to the dbus-daemon messages. So let's modify our script again: vi /usr/local/sbin/test.sh #!/bin/bash # set the date string to match /var/log/messages today=`date +\"%b %e\"` # grab the dbus-daemon messages and send them to email grep -h \"$today\" /var/log/messages | grep dbus-daemon Running the script again, should get you only the dbus-daemon messages and only the ones that occurred today (whenever you're following this guide). There's one final step, however. Remember, we need to get this emailed to the administrator for review. So the final thing we need to do is pipe the entire thing to our email: vi /usr/local/sbin/test.sh And modify the script: #!/bin/bash # set the date string to match /var/log/messages today=`date +\"%b %e\"` # grab the dbus-daemon messages and send them to email grep -h \"$today\" /var/log/messages | grep dbus-daemon | mail -s \"dbus-daemon messages for today\" myname@mydomain.com Run the script again, and you should now have an email from the server with the dbus-daemon message. You can now use a crontab to schedule this to run at a specific time. Conclusion \u00b6 Using postfix can help you keep track of process logs that you want to monitor. You can use it along with bash scripting to gain a firm grasp of your system processes and be informed if there is trouble.","title":"Using postfix For Server Process Reporting"},{"location":"guides/postfix_reporting/#using-postfix-for-server-process-reporting","text":"","title":"Using postfix For Server Process Reporting"},{"location":"guides/postfix_reporting/#prerequisites","text":"Complete comfort operating from the command line on a Rocky Linux server Familiarity with an editor of your choice (this document uses the vi editor, but you can substitute in your favorite editor) An understanding of DNS (the Domain Name System) and host names The ability to assign variables in a bash script Knowledge of what the tail , more , grep , and date commands do","title":"Prerequisites"},{"location":"guides/postfix_reporting/#introduction","text":"Many Rocky Linux server administrators write scripts to perform specific tasks, like backups or file synchronization, and many of these scripts generate logs that have useful and sometimes very important information. Just having the logs, though, is not enough. If a process fails and logs that failure, but the busy administrator does not review the log, then a catastrophe could be in the making. This document shows you how to use the postfix MTA (mail transfer agent) to grab log details from a particular process, and send them to you via email. It also touches on date formats in logs, and helps you identify which format you need to use in the reporting procedure. Keep in mind, though, that this is just the tip of the iceberg as far as what can be done with reporting via postfix. Please note, too, that it is always a good security move to limit running processes to only those that you will need all the time. This document shows you how to enable postfix only for the reporting you need it to do, and then shut it down again.","title":"Introduction"},{"location":"guides/postfix_reporting/#postfix-defined","text":"postfix is a server daemon used for sending email. It is more secure and simpler than sendmail, another MTA that was the default go-to MTA for years. It can be used as part of a full-featured mail server.","title":"Postfix Defined"},{"location":"guides/postfix_reporting/#installing-postfix","text":"Aside from postfix, we will need mailx for testing our ability to send emails. To install both, and any dependencies required, enter the following on the Rocky Linux server command line: dnf install postfix mailx","title":"Installing postfix"},{"location":"guides/postfix_reporting/#testing-and-configuring-postfix","text":"","title":"Testing And Configuring Postfix"},{"location":"guides/postfix_reporting/#testing-mail-first","text":"Before we configure postfix, we need to find out how mail will look when it leaves the server, because we will probably want to change this. To do this, start postfix: systemctl start postfix Then test it using mail command that is installed with mailx: mail -s \"Testing from server\" myname@mydomain.com This will bring up a blank line. Simply type your testing message in here: testing from the server Now hit enter, and enter a single period: . The system will respond with: EOT Our purpose for doing this is to check to see how our mail looks to the outside world, which we can get a feel for from the maillog that goes active with the starting of postfix. Use this command to see the output of the log file: tail /var/log/maillog You should see something like this, although the log file may have different domains for the email address, etc: Mar 4 16:51:40 hedgehogct postfix/postfix-script[735]: starting the Postfix mail system Mar 4 16:51:40 hedgehogct postfix/master[737]: daemon started -- version 3.3.1, configuration /etc/postfix Mar 4 16:52:04 hedgehogct postfix/pickup[738]: C9D42EC0ADD: uid=0 from=<root> Mar 4 16:52:04 hedgehogct postfix/cleanup[743]: C9D42EC0ADD: message-id=<20210304165204.C9D42EC0ADD@somehost.localdomain> Mar 4 16:52:04 hedgehogct postfix/qmgr[739]: C9D42EC0ADD: from=<root@somehost.localdomain>, size=457, nrcpt=1 (queue active) Mar 4 16:52:05 hedgehogct postfix/smtp[745]: connect to gmail-smtp-in.l.google.com[2607:f8b0:4001:c03::1a]:25: Network is unreachable Mar 4 16:52:06 hedgehogct postfix/smtp[745]: C9D42EC0ADD: to=<myname@mydomain.com>, relay=gmail-smtp-in.l.google.com[172.217.212.26] :25, delay=1.4, delays=0.02/0.02/0.99/0.32, dsn=2.0.0, status=sent (250 2.0.0 OK 1614876726 z8si17418573ilq.142 - gsmtp) Mar 4 16:52:06 hedgehogct postfix/qmgr[739]: C9D42EC0ADD: removed The \"somehost.localdomain\" shows us that we need to make some changes, so stop the postfix daemon first: systemctl stop postfix","title":"Testing Mail First"},{"location":"guides/postfix_reporting/#configuring-postfix","text":"Since we aren't setting up a complete, fully functional mail server, the configuration options that we will be using are not as extensive. The first thing we need to do is to modify the main.cf file (literally the main configuration file for postfix), so let's make a backup first: cp /etc/postifix/main.cf /etc/postfix/main.cf.bak Then edit it: vi /etc/postfix/main.cf In our example, our server name is going to be \"bruno\" and our domain name is going to be \"ourdomain.com\". Find the line in the file: #myhostname = host.domain.tld You can either remove the remark (#) or you can add a new line under this line. Based on our example, the line would read: myhostname = bruno.ourdomain.com Next, find the line for the domain name: #mydomain = domain.tld Either remove the remark and change it, or add a new line: mydomain = ourdomain.com Finally, go to the bottom of the file and add this line: smtp_generic_maps = hash:/etc/postfix/generic Save your changes (in vi, that will be Shift : wq! ) and exit the file. Before we continue editing the generic file, we need to see how email will look. Specifically, we want to create the \"generic\" file that we referenced in the main.cf file above: vi /etc/postfix/generic This file tells postfix how any email coming from this server should look. Remember our test email and the log file? This is where we fix all of that: root@somehost.localdomain root@bruno.ourdomain.com @somehost.localdomain root@bruno.ourdomain.com Now we need to tell postfix to use all of our changes. This is done with the postmap command: postmap /etc/postfix/generic Now start postfix and test your email again using the same procedure as above. You should now see that all of the \"localdomain\" instances have been changed to your actual domain.","title":"Configuring Postfix"},{"location":"guides/postfix_reporting/#the-date-command-and-a-variable-called-today","text":"Not every application will use the same logging format for the date. This means that you may have to get creative with any script you write for reporting by date. Let's say that you want to look at your system log as an example and pull everything that has to do with dbus-daemon for today's date, and email it to yourself. (It's probably not the greatest example, but it will give you an idea of how we would do this.) We need to use a a variable in our script that we will call \"today\" and we want it to relate to output from the \"date\" command and format it in a specific way, so that we can get the data we need from our system log (in /var/log/messages ). To start with, let's do some investigative work. First, enter the date command in the command line: date This should give you the default system date output, which could be something like this: Thu Mar 4 18:52:28 UTC 2021 Now let's check our system log and see how it records information. To do this, we will use the \"more\" and \"grep\" commands: more /var/log/messages | grep dbus-daemon Which should give you something like this: Mar 4 18:23:53 hedgehogct dbus-daemon[60]: [system] Successfully activated service 'org.freedesktop.nm_dispatcher' Mar 4 18:50:41 hedgehogct dbus-daemon[60]: [system] Activating via systemd: service name='org.freedesktop.nm_dispatcher' unit='dbus-org.freedesktop.nm-dispatcher.service' requested by ':1.1' (uid=0 pid=61 comm=\"/usr/sbin/NetworkManager --no-daemon \" label=\"unconfined\") Mar 4 18:50:41 hedgehogct dbus-daemon[60]: [system] Successfully activated service 'org.freedesktop.nm_dispatcher The date and log outputs need to be exactly the same in our script, so let's look at how to format the date using a variable called \"today\". First, let's look at what we need to do with the date to get the same output as the system log. You can reference the Linux man page or type man date on the command line to pull up the date manual page to get the information you need. What you will find is that in order to format the date the same way that /var/log/messages has it, we need to use the %b and %e format strings, with %b being the 3 character month and %e being the space-padded day.","title":"The date Command And A Variable Called today"},{"location":"guides/postfix_reporting/#the-script","text":"For our bash script, we can see that we are going to use the date command and a variable called \"today\". (Keep in mind that \"today\" is arbitrary. You could call this variable \"late_for_dinner\" if you wanted!). We will call our script in this example, test.sh and place it in /usr/local/sbin : vi /usr/local/sbin/test.sh Let's start with, well, the beginning of our script. Note that even though the comment in our file says we are sending these messages to email, for now, we are just sending them to a standard log output so that we can verify that they are correct. Also, in our first attempt, we are grabbing all of the messages for the current date, not just the dbus-daemon messages. We will deal with that shortly. Another thing to be aware of is that the grep command will return the filename in the output, which we don't want in this case, so we have added the \"-h\" option to grep to remove the prefix of the filename. In addition, once the variable \"today\" is set, we need to look for the entire variable as a string, so we need it all in quotes: #!/bin/bash # set the date string to match /var/log/messages today=`date +\"%b %e\"` # grab the dbus-daemon messages and send them to email grep -h \"$today\" /var/log/messages That's it for now, so save your changes and then make the script executable: chmod +x /usr/local/sbin/test.sh And then let's test it: /usr/local/sbin/test.sh If all works correctly, you should get a long list of all of the messages in /var/log/messages from today, including but not limited to the dbus-daemon messages. If so, then the next step is to limit the messages to the dbus-daemon messages. So let's modify our script again: vi /usr/local/sbin/test.sh #!/bin/bash # set the date string to match /var/log/messages today=`date +\"%b %e\"` # grab the dbus-daemon messages and send them to email grep -h \"$today\" /var/log/messages | grep dbus-daemon Running the script again, should get you only the dbus-daemon messages and only the ones that occurred today (whenever you're following this guide). There's one final step, however. Remember, we need to get this emailed to the administrator for review. So the final thing we need to do is pipe the entire thing to our email: vi /usr/local/sbin/test.sh And modify the script: #!/bin/bash # set the date string to match /var/log/messages today=`date +\"%b %e\"` # grab the dbus-daemon messages and send them to email grep -h \"$today\" /var/log/messages | grep dbus-daemon | mail -s \"dbus-daemon messages for today\" myname@mydomain.com Run the script again, and you should now have an email from the server with the dbus-daemon message. You can now use a crontab to schedule this to run at a specific time.","title":"The Script"},{"location":"guides/postfix_reporting/#conclusion","text":"Using postfix can help you keep track of process logs that you want to monitor. You can use it along with bash scripting to gain a firm grasp of your system processes and be informed if there is trouble.","title":"Conclusion"},{"location":"guides/private_dns_server_using_bind/","text":"Private DNS Server Using Bind \u00b6 Prerequisites And Assumptions \u00b6 A server running Rocky Linux Several internal servers that need to be accessed only locally, but not over the Internet Several workstations that need access to these same servers that exist on the same network A healthy comfort level with entering commands from command line Able to use a command line editor (we are using vi in this example) Able to use either firewalld or iptables for creating firewall rules (we are using iptables here. If you would like to use iptables as well, use the Enabling Iptables Firewall procedure ) Introduction \u00b6 External, or public, DNS servers are used on the Internet to map host names to IP addresses and, in the case of PTR (known as \"pointer\" or \"reverse\") records, to map the IP to the host name. This is an essential part of the Internet. It makes your mail server, web server, FTP server, or many other servers and services work as expected no matter where you are. On a private network, particularly one that is being used for developing multiple systems, you can use your Rocky Linux workstation's /etc/hosts file to map a name to an IP address. This will work for your workstation, but not for any other machine on your network. If you want to make things universally applied, then the best method is to take some time out and create a local, private DNS server to handle this for all of your machines. If you were creating production-level public DNS servers and resolvers, then this author would probably recommend the more robust PowerDNS authoritative and recursive DNS, which is easily installed on Rocky Linux servers. However, that is simply overkill for a local network that won't be exposing its DNS servers to the outside world. That is why we have chosen bind for this example. The DNS Server Components Explained \u00b6 As stated, DNS separates services into authoritative and recursive servers. These services are now recommended to be separate from each other on separate hardware or containers. The authoritative server is the storage area for all IP addresses and host names, and the recursive server is used to lookup addresses and host names. In the case of our private DNS server, both the authoritative and the recursive server services will run together. Installing And Enabling Bind \u00b6 The first step is to install packages. In the case of bind we need to execute the following command: dnf install bind bind-utils The service daemon for bind is called named , and we need to enable this to start on boot: systemctl enable named And then we need to start it: systemctl start named Configuration \u00b6 Before we make any changes to the configuration file, we want to make a backup copy of the original working named.conf file: cp /etc/named.conf /etc/named.conf.orig That will help us in the future if we completely muck up the configuration file. It is always a good idea to make a backup copy before making a bunch of changes. These changes require us to edit the named.conf file, to do this, we are using vi , but you can substitute your favorite command line editor: vi /etc/named.conf First thing we want to do is turn off listening on the localhost, this is done by remarking out with a \"#\" sign, these two lines in the \"options\" section. What this does is to effectively shutdown any connection to the outside world. This is helpful, particularly when we go to add this DNS to our workstations, because we want these DNS server to only respond when the IP address requesting the service is local, and simply not respond at all if the service that is being looked up is on the Internet. This way, the other configured DNS servers will take over nearly immediately to look up the Internet based services: options { # listen-on port 53 { 127.0.0.1; }; # listen-on-v6 port 53 { ::1; }; If you are not using IPv6, then it's a good idea to turn off IPv6 in bind . This has to be handled in two places. The first place is in the named.conf file that we are already in. If you are using IPv6, then you can (and should!) skip adding this line. Again, this can just be added anywhere in the \"options\" section: filter-aaaa-on-v4 yes; Finally, skip down to the bottom of the named.conf file and add a section for your network. Our example is using ourdomain, so sub in what you want to call your lan hosts: # primary forwward and reverse zones //forward zone zone \"ourdomain.lan\" IN { type master; file \"ourdomain.lan.db\"; allow-update { none; }; allow-query {any; }; }; //reverse zone zone \"1.168.192.in-addr.arpa\" IN { type master; file \"ourdomain.lan.rev\"; allow-update { none; }; allow-query { any; }; }; Now save your changes (for vi , SHIFT:wq! ) If you are turning off IPv6 for bind as noted above, then you will need to make a change to one more file: vi /etc/sysconfig/named And then add this to the bottom of the file: OPTIONS=\"-4\" Now save those changes (again, for vi , SHIFT:wq! ) Next, we need to create two files in /var/named. These files are the ones that you will edit if you add machines to your network that you want to include in the DNS. The first is the forward file to map our IP address to the hostname. Again, we are using \"ourdomain\" as our example here. Note that the IP of our local DNS here is 192.168.1.136. The hosts are added at the bottom of this file. vi /var/named/ourdomain.lan.db The file will look something like this when you are done: $TTL 86400 @ IN SOA dns-primary.ourdomain.lan. admin.ourdomain.lan. ( 2019061800 ;Serial 3600 ;Refresh 1800 ;Retry 604800 ;Expire 86400 ;Minimum TTL ) ;Name Server Information @ IN NS dns-primary.ourdomain.lan. ;IP for Name Server dns-primary IN A 192.168.1.136 ;A Record for IP address to Hostname wiki IN A 192.168.1.13 www IN A 192.168.1.14 devel IN A 192.168.1.15 Add as many hosts as you need to the bottom of the file along with their IP addresses and then save your changes. Next, we need a reverse file to map our hostname to the IP address, In this case, the only part of the IP that you need is the last octet (in an IPv4 address each number separated by a comma, is an octet) of the host and then the PTR and hostname. vi /var/named/ourdomain.lan.rev And the file should look something like this when you are done.: $TTL 86400 @ IN SOA dns-primary.ourdomain.lan. admin.ourdomain.lan. ( 2019061800 ;Serial 3600 ;Refresh 1800 ;Retry 604800 ;Expire 86400 ;Minimum TTL ) ;Name Server Information @ IN NS dns-primary.ourdomain.lan. ;Reverse lookup for Name Server 100 IN PTR dns-primary.ourdomain.lan. ;PTR Record IP address to HostName 13 IN PTR wiki.ourdomain.lan. 14 IN PTR www.ourdomain.lan. 15 IN PTR devel.ourdomain.lan. Add all of the hostnames that appear in the forward file and then save your changes. What All Of This Means \u00b6 Now that we have all of this added in and are preparing to restart our bind DNS server, let's just explore some of the terminology that is used in these two files. Just making things work isn't good enough if you don't know what each term means, right? TTL appears in both files and it stands for \"Time To Live.\" TTL tells the DNS server how long to keep its cache in place before requesting a fresh copy. In this case, the TTL is the default setting for all records unless a specific record TTL is set. The default here is 86400 seconds or 24 hours. IN stands for Internet. In this case, we aren't actually using the Internet, so think of this as the Intranet. SOA stands for \"Start Of Authority\" or what the primary DNS server is for the domain. NS stands for \"name server\" Serial is the value used by the DNS server to verify that the contents of the zone file are up-to-date. Refresh specifies how often a slave DNS server should do a zone transfer from the master. Retry specifies the length of time in seconds to wait before trying again on a failed zone transfer. Expire specifies how long a slave server should wait to answer a query when the master is unreachable. A Is the host address or forward record and is only in the forward file (above). PTR Is the pointer record better known as the \"reverse\" and is only in our reverse file (above). Testing Configurations \u00b6 Once we have gotten all of our files created, we need to make sure that the configuration files and zones are in good working order before we start the bind service again. Check the main configuration: named-checkconf This should return an empty result if everything is OK. Then check the forward zone: named-checkzone ourdomain.lan /var/named/ourdomain.lan.db This should return something like this if all is well: zone ourdomain.lan/IN: loaded serial 2019061800 OK And finally check the reverse zone: named-checkzone 192.168.1.136 /var/named/ourdomain.lan.rev Which should return something like this if all is well: zone 192.168.1.136/IN: loaded serial 2019061800 OK Assuming that everything looks good, go ahead and restart bind : systemctl restart named Testing Machines \u00b6 You need to add the DNS server (in our example 192.168.1.136) to each machine that you want to have access to the servers that you added to your new local DNS. We are only going to show you an example of how to do this on a Rocky Linux workstation, but there are similar methods for other Linux distributions, as well as Windows and Mac machines. Keep in mind that you will want to just add the DNS server in the list, as you will still need Internet access, which will require your currently assigned DNS servers. These might be assigned via DHCP (Dynamic Host Configuration Protocol) or statically assigned. On a Rocky Linux workstation where the enabled network interface is eth0, you would use: vi /etc/sysconfig/network-scripts/ifcfg-eth0 If your enabled network interface is different, you will need to substitute that interface name. The configuration file that you open will look something like this for a statically assigned IP (not DHCP as mentioned above). In the example below, our machine's IP address is 192.168.1.151: DEVICE=eth0 BOOTPROTO=none IPADDR=192.168.1.151 PREFIX=24 GATEWAY=192.168.1.1 DNS1=8.8.8.8 DNS2=8.8.4.4 ONBOOT=yes HOSTNAME=tender-kiwi TYPE=Ethernet MTU= We want to substitute in our new DNS server for the primary (DNS1) and then move each of the other DNS servers down one so that it like this: DEVICE=eth0 BOOTPROTO=none IPADDR=192.168.1.151 PREFIX=24 GATEWAY=192.168.1.1 DNS1=192.168.1.136 DNS2=8.8.8.8 DNS3=8.8.4.4 ONBOOT=yes HOSTNAME=tender-kiwi TYPE=Ethernet MTU= Once you've made the change, either restart the machine or restart networking with: systemctl restart network Now you should be able to get to anything in the ourdomain.lan domain from your workstation, plus still be able to resovle and get to Internet addresses. Adding The Firewall Rule \u00b6 You have two choices for adding the firewall rules for DNS. You can either use the default firewalld or you can use iptables which is what we are using here. If you want to use firewalld , then we are assuming you will know how to translate this rule into firewalld syntax. The firewall rules are applied to the new private DNS server. First, create a file in /etc called \"firewall.conf\" that will contain the following rules. This is a bare minimum rule set, and you may need to tweak this for your environment: #!/bin/sh # #IPTABLES=/usr/sbin/iptables # Unless specified, the defaults for OUTPUT is ACCEPT # The default for FORWARD and INPUT is DROP # echo \" clearing any existing rules and setting default policy..\" iptables -F INPUT iptables -P INPUT DROP iptables -A INPUT -p tcp -m tcp -s 192.168.1.0/24 --dport 22 -j ACCEPT # dns rules iptables -A INPUT -p udp -m udp -s 192.168.1.0/24 --dport 53 -j ACCEPT iptables -A INPUT -i lo -j ACCEPT iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT iptables -A INPUT -p tcp -j REJECT --reject-with tcp-reset iptables -A INPUT -p udp -j REJECT --reject-with icmp-port-unreachable /usr/sbin/service iptables save Let's evaluate the rules above: The first \"iptables\" line flushes the rules that are currently loaded (-F). Next, we are setting a default policy for the INPUT chain of DROP. This means, if the traffic is not explicitly allowed here, it is dropped. Next, we have an SSH rule for our local network, so that we can get into the DNS server remotely. Then we have our DNS allow rule, only for our local network. Note that DNS uses the UDP protocol (User Datagram Protocol). Next we allow INPUT from the local interface. Then if you have established a connection for something else, we are allowing related packets in as well. And finally we reject everything else. The last line tells iptables to save the rules so that when the machine restarts, the rules will load as well. Once our firewall.conf file is created, we need to make it executable: chmod +x /etc/firewall.conf Then run it: /etc/firewall.conf And this is what you should get in return. If you get something else, take a look at your script for errors: clearing any existing rules and setting default policy.. iptables: Saving firewall rules to /etc/sysconfig/iptables:[ OK ] Conclusions \u00b6 While using /etc/hosts on an individual workstation will get you access to a machine on your internal network, you can only use it on that one machine. By adding a private DNS server using bind , you can add hosts to the DNS and as long as the workstations have access to that private DNS server, they will be able to get to these local servers. If you don't need machines to resolve on the Internet, but do need local access from several machines to local servers, then consider using a private DNS server instead.","title":"Private DNS Server Using Bind"},{"location":"guides/private_dns_server_using_bind/#private-dns-server-using-bind","text":"","title":"Private DNS Server Using Bind"},{"location":"guides/private_dns_server_using_bind/#prerequisites-and-assumptions","text":"A server running Rocky Linux Several internal servers that need to be accessed only locally, but not over the Internet Several workstations that need access to these same servers that exist on the same network A healthy comfort level with entering commands from command line Able to use a command line editor (we are using vi in this example) Able to use either firewalld or iptables for creating firewall rules (we are using iptables here. If you would like to use iptables as well, use the Enabling Iptables Firewall procedure )","title":"Prerequisites And Assumptions"},{"location":"guides/private_dns_server_using_bind/#introduction","text":"External, or public, DNS servers are used on the Internet to map host names to IP addresses and, in the case of PTR (known as \"pointer\" or \"reverse\") records, to map the IP to the host name. This is an essential part of the Internet. It makes your mail server, web server, FTP server, or many other servers and services work as expected no matter where you are. On a private network, particularly one that is being used for developing multiple systems, you can use your Rocky Linux workstation's /etc/hosts file to map a name to an IP address. This will work for your workstation, but not for any other machine on your network. If you want to make things universally applied, then the best method is to take some time out and create a local, private DNS server to handle this for all of your machines. If you were creating production-level public DNS servers and resolvers, then this author would probably recommend the more robust PowerDNS authoritative and recursive DNS, which is easily installed on Rocky Linux servers. However, that is simply overkill for a local network that won't be exposing its DNS servers to the outside world. That is why we have chosen bind for this example.","title":"Introduction"},{"location":"guides/private_dns_server_using_bind/#the-dns-server-components-explained","text":"As stated, DNS separates services into authoritative and recursive servers. These services are now recommended to be separate from each other on separate hardware or containers. The authoritative server is the storage area for all IP addresses and host names, and the recursive server is used to lookup addresses and host names. In the case of our private DNS server, both the authoritative and the recursive server services will run together.","title":"The DNS Server Components Explained"},{"location":"guides/private_dns_server_using_bind/#installing-and-enabling-bind","text":"The first step is to install packages. In the case of bind we need to execute the following command: dnf install bind bind-utils The service daemon for bind is called named , and we need to enable this to start on boot: systemctl enable named And then we need to start it: systemctl start named","title":"Installing And Enabling Bind"},{"location":"guides/private_dns_server_using_bind/#configuration","text":"Before we make any changes to the configuration file, we want to make a backup copy of the original working named.conf file: cp /etc/named.conf /etc/named.conf.orig That will help us in the future if we completely muck up the configuration file. It is always a good idea to make a backup copy before making a bunch of changes. These changes require us to edit the named.conf file, to do this, we are using vi , but you can substitute your favorite command line editor: vi /etc/named.conf First thing we want to do is turn off listening on the localhost, this is done by remarking out with a \"#\" sign, these two lines in the \"options\" section. What this does is to effectively shutdown any connection to the outside world. This is helpful, particularly when we go to add this DNS to our workstations, because we want these DNS server to only respond when the IP address requesting the service is local, and simply not respond at all if the service that is being looked up is on the Internet. This way, the other configured DNS servers will take over nearly immediately to look up the Internet based services: options { # listen-on port 53 { 127.0.0.1; }; # listen-on-v6 port 53 { ::1; }; If you are not using IPv6, then it's a good idea to turn off IPv6 in bind . This has to be handled in two places. The first place is in the named.conf file that we are already in. If you are using IPv6, then you can (and should!) skip adding this line. Again, this can just be added anywhere in the \"options\" section: filter-aaaa-on-v4 yes; Finally, skip down to the bottom of the named.conf file and add a section for your network. Our example is using ourdomain, so sub in what you want to call your lan hosts: # primary forwward and reverse zones //forward zone zone \"ourdomain.lan\" IN { type master; file \"ourdomain.lan.db\"; allow-update { none; }; allow-query {any; }; }; //reverse zone zone \"1.168.192.in-addr.arpa\" IN { type master; file \"ourdomain.lan.rev\"; allow-update { none; }; allow-query { any; }; }; Now save your changes (for vi , SHIFT:wq! ) If you are turning off IPv6 for bind as noted above, then you will need to make a change to one more file: vi /etc/sysconfig/named And then add this to the bottom of the file: OPTIONS=\"-4\" Now save those changes (again, for vi , SHIFT:wq! ) Next, we need to create two files in /var/named. These files are the ones that you will edit if you add machines to your network that you want to include in the DNS. The first is the forward file to map our IP address to the hostname. Again, we are using \"ourdomain\" as our example here. Note that the IP of our local DNS here is 192.168.1.136. The hosts are added at the bottom of this file. vi /var/named/ourdomain.lan.db The file will look something like this when you are done: $TTL 86400 @ IN SOA dns-primary.ourdomain.lan. admin.ourdomain.lan. ( 2019061800 ;Serial 3600 ;Refresh 1800 ;Retry 604800 ;Expire 86400 ;Minimum TTL ) ;Name Server Information @ IN NS dns-primary.ourdomain.lan. ;IP for Name Server dns-primary IN A 192.168.1.136 ;A Record for IP address to Hostname wiki IN A 192.168.1.13 www IN A 192.168.1.14 devel IN A 192.168.1.15 Add as many hosts as you need to the bottom of the file along with their IP addresses and then save your changes. Next, we need a reverse file to map our hostname to the IP address, In this case, the only part of the IP that you need is the last octet (in an IPv4 address each number separated by a comma, is an octet) of the host and then the PTR and hostname. vi /var/named/ourdomain.lan.rev And the file should look something like this when you are done.: $TTL 86400 @ IN SOA dns-primary.ourdomain.lan. admin.ourdomain.lan. ( 2019061800 ;Serial 3600 ;Refresh 1800 ;Retry 604800 ;Expire 86400 ;Minimum TTL ) ;Name Server Information @ IN NS dns-primary.ourdomain.lan. ;Reverse lookup for Name Server 100 IN PTR dns-primary.ourdomain.lan. ;PTR Record IP address to HostName 13 IN PTR wiki.ourdomain.lan. 14 IN PTR www.ourdomain.lan. 15 IN PTR devel.ourdomain.lan. Add all of the hostnames that appear in the forward file and then save your changes.","title":"Configuration"},{"location":"guides/private_dns_server_using_bind/#what-all-of-this-means","text":"Now that we have all of this added in and are preparing to restart our bind DNS server, let's just explore some of the terminology that is used in these two files. Just making things work isn't good enough if you don't know what each term means, right? TTL appears in both files and it stands for \"Time To Live.\" TTL tells the DNS server how long to keep its cache in place before requesting a fresh copy. In this case, the TTL is the default setting for all records unless a specific record TTL is set. The default here is 86400 seconds or 24 hours. IN stands for Internet. In this case, we aren't actually using the Internet, so think of this as the Intranet. SOA stands for \"Start Of Authority\" or what the primary DNS server is for the domain. NS stands for \"name server\" Serial is the value used by the DNS server to verify that the contents of the zone file are up-to-date. Refresh specifies how often a slave DNS server should do a zone transfer from the master. Retry specifies the length of time in seconds to wait before trying again on a failed zone transfer. Expire specifies how long a slave server should wait to answer a query when the master is unreachable. A Is the host address or forward record and is only in the forward file (above). PTR Is the pointer record better known as the \"reverse\" and is only in our reverse file (above).","title":"What All Of This Means"},{"location":"guides/private_dns_server_using_bind/#testing-configurations","text":"Once we have gotten all of our files created, we need to make sure that the configuration files and zones are in good working order before we start the bind service again. Check the main configuration: named-checkconf This should return an empty result if everything is OK. Then check the forward zone: named-checkzone ourdomain.lan /var/named/ourdomain.lan.db This should return something like this if all is well: zone ourdomain.lan/IN: loaded serial 2019061800 OK And finally check the reverse zone: named-checkzone 192.168.1.136 /var/named/ourdomain.lan.rev Which should return something like this if all is well: zone 192.168.1.136/IN: loaded serial 2019061800 OK Assuming that everything looks good, go ahead and restart bind : systemctl restart named","title":"Testing Configurations"},{"location":"guides/private_dns_server_using_bind/#testing-machines","text":"You need to add the DNS server (in our example 192.168.1.136) to each machine that you want to have access to the servers that you added to your new local DNS. We are only going to show you an example of how to do this on a Rocky Linux workstation, but there are similar methods for other Linux distributions, as well as Windows and Mac machines. Keep in mind that you will want to just add the DNS server in the list, as you will still need Internet access, which will require your currently assigned DNS servers. These might be assigned via DHCP (Dynamic Host Configuration Protocol) or statically assigned. On a Rocky Linux workstation where the enabled network interface is eth0, you would use: vi /etc/sysconfig/network-scripts/ifcfg-eth0 If your enabled network interface is different, you will need to substitute that interface name. The configuration file that you open will look something like this for a statically assigned IP (not DHCP as mentioned above). In the example below, our machine's IP address is 192.168.1.151: DEVICE=eth0 BOOTPROTO=none IPADDR=192.168.1.151 PREFIX=24 GATEWAY=192.168.1.1 DNS1=8.8.8.8 DNS2=8.8.4.4 ONBOOT=yes HOSTNAME=tender-kiwi TYPE=Ethernet MTU= We want to substitute in our new DNS server for the primary (DNS1) and then move each of the other DNS servers down one so that it like this: DEVICE=eth0 BOOTPROTO=none IPADDR=192.168.1.151 PREFIX=24 GATEWAY=192.168.1.1 DNS1=192.168.1.136 DNS2=8.8.8.8 DNS3=8.8.4.4 ONBOOT=yes HOSTNAME=tender-kiwi TYPE=Ethernet MTU= Once you've made the change, either restart the machine or restart networking with: systemctl restart network Now you should be able to get to anything in the ourdomain.lan domain from your workstation, plus still be able to resovle and get to Internet addresses.","title":"Testing Machines"},{"location":"guides/private_dns_server_using_bind/#adding-the-firewall-rule","text":"You have two choices for adding the firewall rules for DNS. You can either use the default firewalld or you can use iptables which is what we are using here. If you want to use firewalld , then we are assuming you will know how to translate this rule into firewalld syntax. The firewall rules are applied to the new private DNS server. First, create a file in /etc called \"firewall.conf\" that will contain the following rules. This is a bare minimum rule set, and you may need to tweak this for your environment: #!/bin/sh # #IPTABLES=/usr/sbin/iptables # Unless specified, the defaults for OUTPUT is ACCEPT # The default for FORWARD and INPUT is DROP # echo \" clearing any existing rules and setting default policy..\" iptables -F INPUT iptables -P INPUT DROP iptables -A INPUT -p tcp -m tcp -s 192.168.1.0/24 --dport 22 -j ACCEPT # dns rules iptables -A INPUT -p udp -m udp -s 192.168.1.0/24 --dport 53 -j ACCEPT iptables -A INPUT -i lo -j ACCEPT iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT iptables -A INPUT -p tcp -j REJECT --reject-with tcp-reset iptables -A INPUT -p udp -j REJECT --reject-with icmp-port-unreachable /usr/sbin/service iptables save Let's evaluate the rules above: The first \"iptables\" line flushes the rules that are currently loaded (-F). Next, we are setting a default policy for the INPUT chain of DROP. This means, if the traffic is not explicitly allowed here, it is dropped. Next, we have an SSH rule for our local network, so that we can get into the DNS server remotely. Then we have our DNS allow rule, only for our local network. Note that DNS uses the UDP protocol (User Datagram Protocol). Next we allow INPUT from the local interface. Then if you have established a connection for something else, we are allowing related packets in as well. And finally we reject everything else. The last line tells iptables to save the rules so that when the machine restarts, the rules will load as well. Once our firewall.conf file is created, we need to make it executable: chmod +x /etc/firewall.conf Then run it: /etc/firewall.conf And this is what you should get in return. If you get something else, take a look at your script for errors: clearing any existing rules and setting default policy.. iptables: Saving firewall rules to /etc/sysconfig/iptables:[ OK ]","title":"Adding The Firewall Rule"},{"location":"guides/private_dns_server_using_bind/#conclusions","text":"While using /etc/hosts on an individual workstation will get you access to a machine on your internal network, you can only use it on that one machine. By adding a private DNS server using bind , you can add hosts to the DNS and as long as the workstations have access to that private DNS server, they will be able to get to these local servers. If you don't need machines to resolve on the Internet, but do need local access from several machines to local servers, then consider using a private DNS server instead.","title":"Conclusions"},{"location":"guides/rocky-8-installation/","text":"Installing Rocky Linux \u00b6 This guide walks-through the detailed steps to install a 64-bit version of the rocky Linux distribution on a stand-alone system. We will be performing a server class install in this chapter using an operating system installer image downloaded from the rocky project website. We will tackle the installation and customizations steps in the following sections. OS installation prerequisites \u00b6 First, you need to download the ISO for Rocky that we will be installing. The latest ISO image for the version of Rocky that we will be using for this installation can be downloaded from here: https://www.rockylinux.org/download/ To download the ISO directly from the command line, type: $ wget https://download.rockylinux.org/pub/rocky/8.3/isos/x86_64/Rocky-8.3-x86_64-minimal.iso Rocky ISOs are named following this convention: Rocky-<MAJOR#>.<MINOR#>.<ARCH>-<VARIANT>.iso For example Rocky-8.3-x86_64-minimal.iso Note: Rocky project web page has a listing of several mirrors located all over the world. Whenever possible, you should choose the mirror geographically closest to you. The list of official mirrors can be found at https://# Verifying the installer ISO \u00b6 If you've downloaded the Rocky ISO(s) on an existing Linux distribution, you can use the sha256sum utility to verify that file(s) you downloaded are not corrupted in anyway. We'll show an example of how to verify the sha256sum of Rocky-8.3-x86_64-minimal.iso . First download the file that contains the official checksums for the avaiable ISOs. While still in the folder that contains the downloaded Rocky ISO, type: wget http://download.rockylinux.org/pub/rocky/8.3/isos/x86_64/CHECKSUM Use the sha256sum utility to verify the sha256sum -c CHECKSUM --ignore-missing Rocky-8.3-x86_64-minimal.iso The output should include: Rocky-8.3-x86_64-minimal.iso: OK TIP: Before starting the installation proper, the system\u2019s Unified Extensible Firmware Interface (UEFI) or Basic Input/Output System (BIOS) should be preconfigured to boot from the correct medium. The Installation \u00b6 Let\u2019s begin the installation process. Insert and boot off the installation medium (optical disk, USB flash drive, and so on). Once booted, you'll be presented with a welcome splash screen. If you do not press any key, the prompt will begin a countdown, after which the installation process will start by booting the highlighted Test This Media & Install Rocky Linux 8 ... option. You can also press enter to start the process immediately. A quick media verification step will take place. This media verification step can save you the trouble of starting the installation only to find out halfway through that the installer will abort because of bad installation media. After the media check runs to completion, and the media is successfully verified to be usable, the installer will automatically continue to the next screen. Select the language you want to use to perform the installation in this screen. For this example, we select English (United States). Then click the Continue button. Warning: :warning: You'll next see warning screen. The screen will warn you that you are installing pre-release software and that you should NOT use the operating system in a production environment. If you okay with this, click I want to proceed to continue Installation Summary \u00b6 The Installation Summary screen is an all-in-one area where you make the important decisions about the operating system to be installed. The screen is roughly divided into the following sections: \u2022 Localization (Keyboard, Language Support, and Time & Date) \u2022 Software (Installation Source and Software Selection) \u2022 System (Installation Destination and Network & Hostname) We delve into each of these sections next and make changes where necessary. Localization Section \u00b6 This section is used for customizing items related to the locale of the system. This includes \u2013 Keyboard, Language Support, Time and Date. Keyboard \u00b6 On our demo system in this guide, we accept the default value (English US) and make no changes. However if you need to make any changes here, from the Installation Summary screen, click the Keyboard option to specify the keyboard layout of the system. You can add additional keyboard layouts if you need to in the ensuing screen and specify their order. Click Done when you are done. Language Support \u00b6 The Language Support option on the Installation Summary screen enables you to specify support for additional languages that you may need on the finished system. We accept the default value (English \u2013 United States) and make no change. Click Done. Time & Date \u00b6 Click the Time & Date option on the main Installation Summary screen to bring up another screen that will allow you to select the time zone in which the machine is located. Scroll through the list of regions and cities and select the area closest to you. Depending on your installation source, the Network Time option could be set to ON or OFF by default. Accept the default ON setting; this allows the system to automatically set the correct time using the Network Time Protocol (NTP). Click Done after making any changes. Software Section \u00b6 Under the Software section of the Installation Summary screen, you can select the installation source as well as additional packages (applications) that get installed. Installation Source \u00b6 Since we are performing our installation using a full Rocky 8 image, you will notice that Local Media is automatically specified under the Installation Source section of the main Installation Summary screen. We'll accept the preset defaults. Software Selection \u00b6 Clicking the Software Selection option on the main Installation Summary screen presents you with the section of the installation where you can pick the exact software packages that get installed on the system. The software selection area is divided into the Base Environment (Server, Minimal Install, Custom Operating System) and Additional software for Selected Environment area. Selecting a Base Environment on the left side presents a variety of related additional software that can be installed for the given environment on the right side. Select the Minimal Install (Basic functionality) option instead. Click Done at the top of the screen. \u200b System Section \u00b6 The System section of the Installation Summary screen is used for customizing and making changes to the underlying hardware of the target system. This is where you create your hard drive partitions or volumes, specify the file system to be used, and specify the network configuration. Installation Destination \u00b6 From the Installation Summary screen, click the Installation Destination option. This takes you to the corresponding task area. You will see a screen displaying all the candidate disk drives that you have available on the target system. If you have only one disk drive on the system, as on our sample system, you will see the drive listed under Local Standard Disks with a check mark beside it. Clicking the disk icon will toggle on or off the disk selection check mark. We want it selected/checked here. Under the Storage Configuration Options section, select the Automatic radio button. Then click Done at the top of the screen. Once the installer determines that you have a usable disk, you will be returned to the installation summary screen. Network & Hostname \u00b6 The final task of the installation procedure deals with network configuration, where you can configure or tweak network-related settings for the system. NOTE: After you click on the Network & Hostname option, all correctly detected network interface hardware (such as Ethernet, wireless network cards, and so on) will be listed in the left pane of the network configuration screen.Depending on the Linux distribution and the specific hardware setup, Ethernet devices in Linux have names similar to eth0, eth1, ens3, ens4, em1, em2, p1p1, enp0s3, and so on. \u2003 For each interface, you can either configure it using DHCP or manually set the IP address. If you choose to configure manually, be sure to have all the pertinent information ready, such as the IP address, netmask, and so on. Clicking the Network & Hostname button in the main Installation Summary screen opens the corresponding configuration screen. Among other things, you have the option to configure the hostname of the system (the name defaults to localhost.localdomain). Note that you can easily change this name later on after the OS has been installed. For now, accept the default value supplied for the hostname. The next important configuration task is related to the network interfaces on the system. First, verify that an Ethernet card (or any network card) is listed in the left pane. Click any of the detected network devices in the left pane to select it. The configurable properties of the selected network adapter will appear in the right pane of the screen. On our sample server, we have four Ethernet devices (ens3, ens4, ens5 and ens6), all of which are in a connected state. The type, name, quantity, and state of the network devices on your system may vary from the ones on our sample system. Make sure the switch of the device you want to configure is flipped to the ON position in the right pane. We'll accept all the defaults in this section. Click Done to return to the main Installation Summary screen. CAUTION: Pay attention to the IP address of the server in this section of this installer. If you don\u2019t have physical or easy console access to the system, this information will come in handy later on when you need to connect to the server to continue working on it. The Installation \u00b6 Once you are satisfied with your choices for the various installation tasks, the next phase of the installation process will begin the installation proper. User Settings Section \u00b6 This section can be used for creating a password for the root user account and also for creating new administrative or non-administrative accounts. Set the Root Password \u00b6 Click the Root Password field under User Settings to launch the Root Password task screen. In the Root Password text box, set a strong password for the root user. This user is the most privileged account on the system. Therefore, if you choose to use it or enable it - it is crucial that you protect this account with a very good password. Enter the same password again in the Confirm text box. Click Done. \u200b Create a User Account \u00b6 Next click the User Creation field under User Settings to launch the Create User task screen. This task area allows you to create a privileged or non-privileged (non-administrative) user account on the system. Creating and using a non-privileged account for day-to-day tasks on a system is a good system administration practice. We\u2019ll create a regular user that can invoke superuser (administrator) powers when needed. Complete the fields in the Create User screen with the following information and then click Done: Full name rockstar Username rockstar Make this user administrator Checked Require a password to use this account Checked Password 04302021 Confirm password 04302021 Start the Installation \u00b6 Once you are satisfied with your choices for the various installation tasks, click the Begin Installation button on the main Installation Summary screen. The installation will begin, and the installer will show the progress of the installation. NOTE: If you develop cold feet after you click the Begin Installation button, you can still safely back out of the installation without any loss of data (or self-esteem). To quit the installer, simply reset your system either by clicking the Quit button, pressing ctrl-alt-del on the keyboard, or pushing the reset or power switch. When the installation begins, various tasks will begin running in the background, such as partitioning the disk, formatting the partitions or LVM volumes, checking for and resolving software dependencies, writing the operating system to the disk, and so on. \u200b Complete the Installation \u00b6 After you\u2019ve completed any of the mandatory subtasks and the installer has run its course, you'll be presented with a final installation progress screen with a complete message. Finally, complete the entire procedure by clicking the Reboot System button. The system will reboot itself. \u200b Log In \u00b6 The system is now set up and ready for use. You will see the adorable Rocky Linux console. To log onto the system, type rockstar at the login prompt and press enter. At the Password prompt, type 04302021 (rockstar\u2019s password) and press enter. We'll run the whoami command after login.","title":"Installing Rocky Linux"},{"location":"guides/rocky-8-installation/#installing-rocky-linux","text":"This guide walks-through the detailed steps to install a 64-bit version of the rocky Linux distribution on a stand-alone system. We will be performing a server class install in this chapter using an operating system installer image downloaded from the rocky project website. We will tackle the installation and customizations steps in the following sections.","title":"Installing Rocky Linux"},{"location":"guides/rocky-8-installation/#os-installation-prerequisites","text":"First, you need to download the ISO for Rocky that we will be installing. The latest ISO image for the version of Rocky that we will be using for this installation can be downloaded from here: https://www.rockylinux.org/download/ To download the ISO directly from the command line, type: $ wget https://download.rockylinux.org/pub/rocky/8.3/isos/x86_64/Rocky-8.3-x86_64-minimal.iso Rocky ISOs are named following this convention: Rocky-<MAJOR#>.<MINOR#>.<ARCH>-<VARIANT>.iso For example Rocky-8.3-x86_64-minimal.iso Note: Rocky project web page has a listing of several mirrors located all over the world. Whenever possible, you should choose the mirror geographically closest to you. The list of official mirrors can be found at https://#","title":"OS installation prerequisites"},{"location":"guides/rocky-8-installation/#verifying-the-installer-iso","text":"If you've downloaded the Rocky ISO(s) on an existing Linux distribution, you can use the sha256sum utility to verify that file(s) you downloaded are not corrupted in anyway. We'll show an example of how to verify the sha256sum of Rocky-8.3-x86_64-minimal.iso . First download the file that contains the official checksums for the avaiable ISOs. While still in the folder that contains the downloaded Rocky ISO, type: wget http://download.rockylinux.org/pub/rocky/8.3/isos/x86_64/CHECKSUM Use the sha256sum utility to verify the sha256sum -c CHECKSUM --ignore-missing Rocky-8.3-x86_64-minimal.iso The output should include: Rocky-8.3-x86_64-minimal.iso: OK TIP: Before starting the installation proper, the system\u2019s Unified Extensible Firmware Interface (UEFI) or Basic Input/Output System (BIOS) should be preconfigured to boot from the correct medium.","title":"Verifying the installer ISO"},{"location":"guides/rocky-8-installation/#the-installation","text":"Let\u2019s begin the installation process. Insert and boot off the installation medium (optical disk, USB flash drive, and so on). Once booted, you'll be presented with a welcome splash screen. If you do not press any key, the prompt will begin a countdown, after which the installation process will start by booting the highlighted Test This Media & Install Rocky Linux 8 ... option. You can also press enter to start the process immediately. A quick media verification step will take place. This media verification step can save you the trouble of starting the installation only to find out halfway through that the installer will abort because of bad installation media. After the media check runs to completion, and the media is successfully verified to be usable, the installer will automatically continue to the next screen. Select the language you want to use to perform the installation in this screen. For this example, we select English (United States). Then click the Continue button. Warning: :warning: You'll next see warning screen. The screen will warn you that you are installing pre-release software and that you should NOT use the operating system in a production environment. If you okay with this, click I want to proceed to continue","title":"The Installation"},{"location":"guides/rocky-8-installation/#installation-summary","text":"The Installation Summary screen is an all-in-one area where you make the important decisions about the operating system to be installed. The screen is roughly divided into the following sections: \u2022 Localization (Keyboard, Language Support, and Time & Date) \u2022 Software (Installation Source and Software Selection) \u2022 System (Installation Destination and Network & Hostname) We delve into each of these sections next and make changes where necessary.","title":"Installation Summary"},{"location":"guides/rocky-8-installation/#localization-section","text":"This section is used for customizing items related to the locale of the system. This includes \u2013 Keyboard, Language Support, Time and Date.","title":"Localization Section"},{"location":"guides/rocky-8-installation/#keyboard","text":"On our demo system in this guide, we accept the default value (English US) and make no changes. However if you need to make any changes here, from the Installation Summary screen, click the Keyboard option to specify the keyboard layout of the system. You can add additional keyboard layouts if you need to in the ensuing screen and specify their order. Click Done when you are done.","title":"Keyboard"},{"location":"guides/rocky-8-installation/#language-support","text":"The Language Support option on the Installation Summary screen enables you to specify support for additional languages that you may need on the finished system. We accept the default value (English \u2013 United States) and make no change. Click Done.","title":"Language Support"},{"location":"guides/rocky-8-installation/#time-date","text":"Click the Time & Date option on the main Installation Summary screen to bring up another screen that will allow you to select the time zone in which the machine is located. Scroll through the list of regions and cities and select the area closest to you. Depending on your installation source, the Network Time option could be set to ON or OFF by default. Accept the default ON setting; this allows the system to automatically set the correct time using the Network Time Protocol (NTP). Click Done after making any changes.","title":"Time &amp; Date"},{"location":"guides/rocky-8-installation/#software-section","text":"Under the Software section of the Installation Summary screen, you can select the installation source as well as additional packages (applications) that get installed.","title":"Software Section"},{"location":"guides/rocky-8-installation/#installation-source","text":"Since we are performing our installation using a full Rocky 8 image, you will notice that Local Media is automatically specified under the Installation Source section of the main Installation Summary screen. We'll accept the preset defaults.","title":"Installation Source"},{"location":"guides/rocky-8-installation/#software-selection","text":"Clicking the Software Selection option on the main Installation Summary screen presents you with the section of the installation where you can pick the exact software packages that get installed on the system. The software selection area is divided into the Base Environment (Server, Minimal Install, Custom Operating System) and Additional software for Selected Environment area. Selecting a Base Environment on the left side presents a variety of related additional software that can be installed for the given environment on the right side. Select the Minimal Install (Basic functionality) option instead. Click Done at the top of the screen. \u200b","title":"Software Selection"},{"location":"guides/rocky-8-installation/#system-section","text":"The System section of the Installation Summary screen is used for customizing and making changes to the underlying hardware of the target system. This is where you create your hard drive partitions or volumes, specify the file system to be used, and specify the network configuration.","title":"System Section"},{"location":"guides/rocky-8-installation/#installation-destination","text":"From the Installation Summary screen, click the Installation Destination option. This takes you to the corresponding task area. You will see a screen displaying all the candidate disk drives that you have available on the target system. If you have only one disk drive on the system, as on our sample system, you will see the drive listed under Local Standard Disks with a check mark beside it. Clicking the disk icon will toggle on or off the disk selection check mark. We want it selected/checked here. Under the Storage Configuration Options section, select the Automatic radio button. Then click Done at the top of the screen. Once the installer determines that you have a usable disk, you will be returned to the installation summary screen.","title":"Installation Destination"},{"location":"guides/rocky-8-installation/#network-hostname","text":"The final task of the installation procedure deals with network configuration, where you can configure or tweak network-related settings for the system. NOTE: After you click on the Network & Hostname option, all correctly detected network interface hardware (such as Ethernet, wireless network cards, and so on) will be listed in the left pane of the network configuration screen.Depending on the Linux distribution and the specific hardware setup, Ethernet devices in Linux have names similar to eth0, eth1, ens3, ens4, em1, em2, p1p1, enp0s3, and so on. \u2003 For each interface, you can either configure it using DHCP or manually set the IP address. If you choose to configure manually, be sure to have all the pertinent information ready, such as the IP address, netmask, and so on. Clicking the Network & Hostname button in the main Installation Summary screen opens the corresponding configuration screen. Among other things, you have the option to configure the hostname of the system (the name defaults to localhost.localdomain). Note that you can easily change this name later on after the OS has been installed. For now, accept the default value supplied for the hostname. The next important configuration task is related to the network interfaces on the system. First, verify that an Ethernet card (or any network card) is listed in the left pane. Click any of the detected network devices in the left pane to select it. The configurable properties of the selected network adapter will appear in the right pane of the screen. On our sample server, we have four Ethernet devices (ens3, ens4, ens5 and ens6), all of which are in a connected state. The type, name, quantity, and state of the network devices on your system may vary from the ones on our sample system. Make sure the switch of the device you want to configure is flipped to the ON position in the right pane. We'll accept all the defaults in this section. Click Done to return to the main Installation Summary screen. CAUTION: Pay attention to the IP address of the server in this section of this installer. If you don\u2019t have physical or easy console access to the system, this information will come in handy later on when you need to connect to the server to continue working on it.","title":"Network &amp; Hostname"},{"location":"guides/rocky-8-installation/#the-installation_1","text":"Once you are satisfied with your choices for the various installation tasks, the next phase of the installation process will begin the installation proper.","title":"The Installation"},{"location":"guides/rocky-8-installation/#user-settings-section","text":"This section can be used for creating a password for the root user account and also for creating new administrative or non-administrative accounts.","title":"User Settings Section"},{"location":"guides/rocky-8-installation/#set-the-root-password","text":"Click the Root Password field under User Settings to launch the Root Password task screen. In the Root Password text box, set a strong password for the root user. This user is the most privileged account on the system. Therefore, if you choose to use it or enable it - it is crucial that you protect this account with a very good password. Enter the same password again in the Confirm text box. Click Done. \u200b","title":"Set the Root Password"},{"location":"guides/rocky-8-installation/#create-a-user-account","text":"Next click the User Creation field under User Settings to launch the Create User task screen. This task area allows you to create a privileged or non-privileged (non-administrative) user account on the system. Creating and using a non-privileged account for day-to-day tasks on a system is a good system administration practice. We\u2019ll create a regular user that can invoke superuser (administrator) powers when needed. Complete the fields in the Create User screen with the following information and then click Done: Full name rockstar Username rockstar Make this user administrator Checked Require a password to use this account Checked Password 04302021 Confirm password 04302021","title":"Create a User Account"},{"location":"guides/rocky-8-installation/#start-the-installation","text":"Once you are satisfied with your choices for the various installation tasks, click the Begin Installation button on the main Installation Summary screen. The installation will begin, and the installer will show the progress of the installation. NOTE: If you develop cold feet after you click the Begin Installation button, you can still safely back out of the installation without any loss of data (or self-esteem). To quit the installer, simply reset your system either by clicking the Quit button, pressing ctrl-alt-del on the keyboard, or pushing the reset or power switch. When the installation begins, various tasks will begin running in the background, such as partitioning the disk, formatting the partitions or LVM volumes, checking for and resolving software dependencies, writing the operating system to the disk, and so on. \u200b","title":"Start the Installation"},{"location":"guides/rocky-8-installation/#complete-the-installation","text":"After you\u2019ve completed any of the mandatory subtasks and the installer has run its course, you'll be presented with a final installation progress screen with a complete message. Finally, complete the entire procedure by clicking the Reboot System button. The system will reboot itself. \u200b","title":"Complete the Installation"},{"location":"guides/rocky-8-installation/#log-in","text":"The system is now set up and ready for use. You will see the adorable Rocky Linux console. To log onto the system, type rockstar at the login prompt and press enter. At the Password prompt, type 04302021 (rockstar\u2019s password) and press enter. We'll run the whoami command after login.","title":"Log In"},{"location":"guides/rocky_to_wsl_howto/","text":"Import Rocky Linux to WSL with WSL and rinse \u00b6 Prerequisites \u00b6 A Windows 10 PC with WSL 2 enabled. (*see note below). Ubuntu, or any debian-based distribution, installed and running on WSL. This guide was tested using Ubuntu 20.04 LTS from the Microsoft store. Introduction \u00b6 This guide is for Windows users who would like to run Rocky Linux (RL) in the Windows Subsystem for Linux (WSL). It assumes the reader is familiar with the command line and has WSL enabled and running in their Windows 10 PC. The process uses rinse , a perl script for creating images of distributions that use the package manager YUM. Please keep in mind that WSL has significant limitations and quirks, and the resulting distribution may or may not work as you expect it. It may be too slow, or be unpredictable for some applications. With computers, as with life, there are no guarantees. Steps \u00b6 Launch your Ubuntu distribution in WSL, update the package manager and install rinse $ sudo apt-get update $ sudo apt-get install rinse rinse is not aware of RL, so we need to modify its configuration to add the package repositories and so on. Copy the CentOS 8 packages file and prepare it for RL $ sudo cp -p /etc/rinse/centos-8.packages /etc/rinse/rocky-8.packages Edit the new file and change all the entries for 'centos' to 'rocky'. Next, add the following lines to it. The order in the file is not important, the entries can be added anywhere. Here you can also add any other packages that you may want to have in your image (servers, utilities like which , etc) glibc-langpack-en libmodulemd libzstd passwd sudo cracklib-dicts openssh-clients Edit the rinse config file at /etc/rinse/rinse.conf and add the following lines, which are the entry for RL mirrors. As of this writing, we have a direct download, but this will be changed to a mirror as soon as available. # Rocky Linux 8 [rocky-8] mirror.amd64 = http://dl.rockylinux.org/pub/rocky/8/BaseOS/x86_64/os/Packages/ Copy the post-install script for CentOS so it can be modified for RL $ sudo cp -pR /usr/lib/rinse/centos-8 /usr/lib/rinse/rocky-8 Edit /usr/lib/rinse/rocky-8/post-install.sh and add the following lines at line 14. This is needed to make sure TLS/SSL works as expected for YUM and dnf . echo \" Extracting CA certs...\" $CH /usr/bin/update-ca-trust Edit the rinse script at /usr/sbin/rinse , and at line 1248 remove the text --extract-over-symlinks . This option was deprecated in the program called and breaks the script. Don't close the file yet. On the same file, go to line 1249 and replace 'centos' for 'rocky'. Save and close the file. Make a directory to hold the new RL filesystem (any name is fine). $ mkdir rocky_rc Execute rinse with the following command $ sudo rinse --arch amd64 --directory ./rocky_rc --distribution rocky-8 After the script completes downloading and extracting all the packages, you will have a full Rocky Linux file system in the directory you created. Now it's time to package it to pass it to Windows for importing into a new WSL distro. Use this command, creating the tar file in a Windows folder (starting with /mnt/c/ or similar to have it readily available for the next step). $ sudo tar --numeric-owner -c -C ./rocky_rc . -f <path to new tar file> Close your WSL session with Ctrl+D or by typing exit . Open a PowerShell prompt (does not need to be admin), and create a folder to hold your new RL distro. Import the tar file with this command: wsl --import rocky_rc <path to folder from step 13> <path to tar file> In the PowerShell prompt, launch your new distro with: wsl -d rocky_rc You are now root in your new RL distro. Run these commands to finish setting everything up: yum update yum reinstall passwd sudo cracklib-dicts -y newUsername=<your new username> adduser -G wheel $newUsername echo -e \"[user]\\ndefault=$newUsername\" >> /etc/wsl.conf passwd $newUsername Exit the bash prompt (Ctrl+D or type exit ). Back in PowerShell, shutdown WSL and relaunch your new distro. wsl --shutdown wsl -d rocky_rc Test and enjoy! Cleanup \u00b6 All the downloaded packages are still stored in the debian distro you used at the beginning of the process. You can remove the files from /var/cache/rinse , and you can also delete all the files from the rocky_rc directory. Next time you want to create a new, updated or modified image, simply make your changes and run the commands from step 10 on. Known issues \u00b6 There are some quirky things that result from extracting packages, rather than installing them. Running yum reinstall in some packages fixes the issues, as is the case for passwd . The rinse script simply extracts the packages and does not execute post-install commands (although it is capable of doing so). Please leave comments for other users if you run into problems and know how to fix them, so that others can benefit from your experience. Notes \u00b6 Most of the rinse script runs under WSL 1, but the very last part, where dnf is invoked, runs into memory issues and corrupts the rpm database. This ruins the distro, and repair attempts fail, even uder WSL. If you know how to get dnf to work under WSL 1, please let us know, but there are lots of BDB issues related to WSL 1 on different forums on the web. WSL 2 solved those issues with the native Linux kernel.","title":"Import Rocky Linux to WSL with WSL and rinse"},{"location":"guides/rocky_to_wsl_howto/#import-rocky-linux-to-wsl-with-wsl-and-rinse","text":"","title":"Import Rocky Linux to WSL with WSL and rinse"},{"location":"guides/rocky_to_wsl_howto/#prerequisites","text":"A Windows 10 PC with WSL 2 enabled. (*see note below). Ubuntu, or any debian-based distribution, installed and running on WSL. This guide was tested using Ubuntu 20.04 LTS from the Microsoft store.","title":"Prerequisites"},{"location":"guides/rocky_to_wsl_howto/#introduction","text":"This guide is for Windows users who would like to run Rocky Linux (RL) in the Windows Subsystem for Linux (WSL). It assumes the reader is familiar with the command line and has WSL enabled and running in their Windows 10 PC. The process uses rinse , a perl script for creating images of distributions that use the package manager YUM. Please keep in mind that WSL has significant limitations and quirks, and the resulting distribution may or may not work as you expect it. It may be too slow, or be unpredictable for some applications. With computers, as with life, there are no guarantees.","title":"Introduction"},{"location":"guides/rocky_to_wsl_howto/#steps","text":"Launch your Ubuntu distribution in WSL, update the package manager and install rinse $ sudo apt-get update $ sudo apt-get install rinse rinse is not aware of RL, so we need to modify its configuration to add the package repositories and so on. Copy the CentOS 8 packages file and prepare it for RL $ sudo cp -p /etc/rinse/centos-8.packages /etc/rinse/rocky-8.packages Edit the new file and change all the entries for 'centos' to 'rocky'. Next, add the following lines to it. The order in the file is not important, the entries can be added anywhere. Here you can also add any other packages that you may want to have in your image (servers, utilities like which , etc) glibc-langpack-en libmodulemd libzstd passwd sudo cracklib-dicts openssh-clients Edit the rinse config file at /etc/rinse/rinse.conf and add the following lines, which are the entry for RL mirrors. As of this writing, we have a direct download, but this will be changed to a mirror as soon as available. # Rocky Linux 8 [rocky-8] mirror.amd64 = http://dl.rockylinux.org/pub/rocky/8/BaseOS/x86_64/os/Packages/ Copy the post-install script for CentOS so it can be modified for RL $ sudo cp -pR /usr/lib/rinse/centos-8 /usr/lib/rinse/rocky-8 Edit /usr/lib/rinse/rocky-8/post-install.sh and add the following lines at line 14. This is needed to make sure TLS/SSL works as expected for YUM and dnf . echo \" Extracting CA certs...\" $CH /usr/bin/update-ca-trust Edit the rinse script at /usr/sbin/rinse , and at line 1248 remove the text --extract-over-symlinks . This option was deprecated in the program called and breaks the script. Don't close the file yet. On the same file, go to line 1249 and replace 'centos' for 'rocky'. Save and close the file. Make a directory to hold the new RL filesystem (any name is fine). $ mkdir rocky_rc Execute rinse with the following command $ sudo rinse --arch amd64 --directory ./rocky_rc --distribution rocky-8 After the script completes downloading and extracting all the packages, you will have a full Rocky Linux file system in the directory you created. Now it's time to package it to pass it to Windows for importing into a new WSL distro. Use this command, creating the tar file in a Windows folder (starting with /mnt/c/ or similar to have it readily available for the next step). $ sudo tar --numeric-owner -c -C ./rocky_rc . -f <path to new tar file> Close your WSL session with Ctrl+D or by typing exit . Open a PowerShell prompt (does not need to be admin), and create a folder to hold your new RL distro. Import the tar file with this command: wsl --import rocky_rc <path to folder from step 13> <path to tar file> In the PowerShell prompt, launch your new distro with: wsl -d rocky_rc You are now root in your new RL distro. Run these commands to finish setting everything up: yum update yum reinstall passwd sudo cracklib-dicts -y newUsername=<your new username> adduser -G wheel $newUsername echo -e \"[user]\\ndefault=$newUsername\" >> /etc/wsl.conf passwd $newUsername Exit the bash prompt (Ctrl+D or type exit ). Back in PowerShell, shutdown WSL and relaunch your new distro. wsl --shutdown wsl -d rocky_rc Test and enjoy!","title":"Steps"},{"location":"guides/rocky_to_wsl_howto/#cleanup","text":"All the downloaded packages are still stored in the debian distro you used at the beginning of the process. You can remove the files from /var/cache/rinse , and you can also delete all the files from the rocky_rc directory. Next time you want to create a new, updated or modified image, simply make your changes and run the commands from step 10 on.","title":"Cleanup"},{"location":"guides/rocky_to_wsl_howto/#known-issues","text":"There are some quirky things that result from extracting packages, rather than installing them. Running yum reinstall in some packages fixes the issues, as is the case for passwd . The rinse script simply extracts the packages and does not execute post-install commands (although it is capable of doing so). Please leave comments for other users if you run into problems and know how to fix them, so that others can benefit from your experience.","title":"Known issues"},{"location":"guides/rocky_to_wsl_howto/#notes","text":"Most of the rinse script runs under WSL 1, but the very last part, where dnf is invoked, runs into memory issues and corrupts the rpm database. This ruins the distro, and repair attempts fail, even uder WSL. If you know how to get dnf to work under WSL 1, please let us know, but there are lots of BDB issues related to WSL 1 on different forums on the web. WSL 2 solved those issues with the native Linux kernel.","title":"Notes"},{"location":"guides/rsnapshot_backup/","text":"Backup Solution - Rsnapshot \u00b6 Prerequisites \u00b6 Know how to install additional repositories and snapshots from the command-line Know about mounting filesystems external of your machine (external Hard Drive, remote filesystem, etc.) Know how to use an editor (vi is used here, but you can use your favorite editor) Know a little BASH scripting Know how to modify the crontab for the root user Knowledge of SSH public and private keys (only if you plan to run remote backups from another server) Introduction \u00b6 rsnapshot is a very powerful backup utility that can be installed on any Linux-based machine. It can either back up a machine locally, or you can back up multiple machines, say servers for instance, from a single machine. rsnapshot uses rsync and is written entirely in perl with no library dependencies, so there are no weird requirements to installing it. In the case of Rocky Linux, you should be able to install rsnapshot simply by installing the EPEL software repository. This documentation covers the installation of rsnapshot on Rocky Linux only. Installing Rsnapshot \u00b6 All commands shown here are from the command-line on your server or workstation unless otherwise noted. Installing The EPEL repository \u00b6 We need the EPEL software repo from Fedora to install rsnapshot. To install the repository, just use this command, if you haven't already: sudo dnf install https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm The repository should now be active. Install the Rsnapshot Package \u00b6 Next, install rsnapshot itself: sudo dnf install rsnapshot If there are any missing dependencies, those will show up and you simply need to answer the prompt to continue. For example: dnf install rsnapshot Last metadata expiration check: 0:00:16 ago on Mon Feb 22 00:12:45 2021. Dependencies resolved. ======================================================================================================================================== Package Architecture Version Repository Size ======================================================================================================================================== Installing: rsnapshot noarch 1.4.3-1.el8 epel 121 k Installing dependencies: perl-Lchown x86_64 1.01-14.el8 epel 18 k rsync x86_64 3.1.3-9.el8 baseos 404 k Transaction Summary ======================================================================================================================================== Install 3 Packages Total download size: 543 k Installed size: 1.2 M Is this ok [y/N]: y Mounting A Drive or Filesystem For Backup \u00b6 In this step, we show how to mount a hard drive, such as an external USB hard drive, that will be used to back up your system. This particular step is only necessary if you are backing up a single machine or server, as seen in our first example below. Plug in the USB drive. Type dmesg | grep sd which should show you the drive should show you the drive you want to use. In this case, it'll be called sda1 . Example: EXT4-fs (sda1): mounting ext2 file system using the ext4 subsystem . Unfortunately (or fortunately depending on your opinion) most modern Linux desktop operating systems automount the drive if they can. This means that, depending on various factors, rsnapshot might lose track of the hard drive. We want the drive to \"mount\" or make its files available in the same place every time. To do that, take the drive information revealed in the dmesg command above and type mount | grep sda1 , which should show something like this: /dev/sda1 on /media/username/8ea89e5e-9291-45c1-961d-99c346a2628a Type sudo umount /dev/sda1 to unmount your external hard drive. Next, create a new mount point for the backup: sudo mkdir /mnt/backup Now mount the drive to your backup folder location: sudo mount /dev/sda1 /mnt/backup Now type mount | grep sda1 again, and you should see something like this: /dev/sda1 on /mnt/backup type ext2 (rw,relatime) Next create a directory that must exist for the backup to continue on the mounted drive. We are using a folder called \"storage\" for this example: sudo mkdir /mnt/backup/storage Note that for a single machine, you will have to either repeat the umount and mount steps each time the drive is plugged in again, or each time the system reboots, or automate these commands with a script. We recommend automation. Automation is the sysadmin way. Configuring rsnapshot \u00b6 This is the most important step. It's easy to make a mistake when making changes to the configuration file. The rsnapshot configuration requires tabs for any separation between elements, and a warning to that effect is at the very top of the configuration file. A space character will cause the entire configuration\u2014and your backup\u2014to fail. For instance, near the top of the configuration file is a section for the # SNAPSHOT ROOT DIRECTORY # . If you were adding this in from scratch, you would type snapshot_root then TAB and then type /whatever_the_path_to_the_snapshot_root_will_be/ The best thing is that the default configuration that comes with rsnapshot only needs minor changes to make it work for a backup of a local machine. It's always a good idea, though, to make a backup copy of the configuration file before you start editing: cp /etc/rsnapshot.conf /etc/rsnapshot.conf.bak Basic Machine or Single Server Backup \u00b6 In this case, rsnapshot is going to be run locally to back up a particular machine. In this example, we'll break down the configuration file, and show you exactly what you need to change. You will need to use vi (or edit with your favorite editor) to open the /etc/rsnapshot.conf file. The first thing to change is the snapshot_root setting which by default has this value: snapshot_root /.snapshots/ We need to change this to our mount point that we created above plus the addition of \"storage\". snapshot_root /mnt/backup/storage/ We also want to tell the backup NOT to run if the drive is not mounted. To do this, remove the \"#\" sign (also called a remark, pound sign, number sign, hash symbol, etc.) next to no_create_root so that it looks like this: no_create_root 1 Next go down to the section titled # EXTERNAL PROGRAM DEPENDENCIES # and remove the comment (again, the \"#\" sign) from this line: #cmd_cp /usr/bin/cp So that it now reads: cmd_cp /usr/bin/cp While we do not need cmd_ssh for this particular configuration, we will need it for our other option below and it doesn't hurt to have it enabled. So find the line that says: #cmd_ssh /usr/bin/ssh And remove the \"#\" sign so that it looks like this: cmd_ssh /usr/bin/ssh Next we need to skip down to the section titled # BACKUP LEVELS / INTERVALS # This has been changed from earlier versions of rsnapshot from hourly, daily, monthly, yearly to alpha, beta, gamma, delta . Which is a bit confusing. What you need to do is add a remark to any interval that you won't be using. In the configuration, delta is already remarked out. For this example, we aren't going to be running any other increments other than a nightly backup, so just add a remark to alpha and gamma so that the configuration looks like this when you are done: #retain alpha 6 retain beta 7 #retain gamma 4 #retain delta 3 Now skip down to the logfile line, which by default should read: #logfile /var/log/rsnapshot And remove the remark so that it is enabled: logfile /var/log/rsnapshot Finally, skip down to the ### BACKUP POINTS / SCRIPTS ### section and add any directories that you want to add in the # LOCALHOST section, remember to use TAB rather than SPACE between elements! For now write your changes ( SHIFT :wq! for vi) and exit the configuration file. Checking The Configuration \u00b6 We want to make sure that we didn't add spaces or any other glaring errors to our configuration file while we were editing it. To do this, we run rsnapshot against our configuration with the configtest option: rsnapshot configtest will show Syntax OK if there are no errors in the configuration. You should get into the habit of running configtest against a particular configuration. The reason for that will be more evident when we get into the Multiple Machine or Multiple Server Backups section. To run configtest against a particular configuration file, run it with the -c option to specify the configuration: rsnapshot -c /etc/rsnapshot.conf configtest Running The Backup The First Time \u00b6 Everything has checked out, so it's time to go ahead and run the backup for the first time. You can run this in test mode first if you like, so that you can see what the backup script is going to do. Again, to do this you don't necessarily have to specify the configuration in this case, but you should get into the habit of doing so: rsnapshot -c /etc/rsnapshot.conf -t beta Which should return something like this, showing you what will happen when the backup is actually run: echo 1441 > /var/run/rsnapshot.pid mkdir -m 0755 -p /mnt/backup/storage/beta.0/ /usr/bin/rsync -a --delete --numeric-ids --relative --delete-excluded \\ /home/ /mnt/backup/storage/beta.0/localhost/ mkdir -m 0755 -p /mnt/backup/storage/beta.0/ /usr/bin/rsync -a --delete --numeric-ids --relative --delete-excluded /etc/ \\ /mnt/backup/storage/beta.0/localhost/ mkdir -m 0755 -p /mnt/backup/storage/beta.0/ /usr/bin/rsync -a --delete --numeric-ids --relative --delete-excluded \\ /usr/local/ /mnt/backup/storage/beta.0/localhost/ touch /mnt/backup/storage/beta.0/ Once you are satisfied with the test, go ahead and run it manually the first time without the test: rsnapshot -c /etc/rsnapshot.conf beta When the backup finishes, navigate to /mnt/backup and take a look at the directory structure that was created there. There will be a storage/beta.0/localhost directory, followed by the directories that you specified to backup. Further Explanation \u00b6 Each time the backup is run, it will create a new beta increment, 0-6, or 7 days worth of backups. The newest backup will always be beta.0 where as yesterday's backup will always be beta.1. The size of each of these backups will appear to take up the same amount (or more) of disk space, but this is because of rsnapshot's use of hard links. To restore files from yesterday's backup, you would simply copy them back from beta.1's directory structure. Each backup is only an incremental backup from the previous run, BUT, because of the use of hard links, each backup directory, contains the file, or the hard-link to the file in whichever directory it actually was backed up in. So to restore files, you don't have to pick and choose which directory or increment to restore them from, just what time stamp the backup should have. It's a great system and uses far less disk space than many other backup solutions. Setting The Backup To Run Automatically \u00b6 Once everything has been tested and we know that things will work without issue, the next step is to set up the crontab for the root user, so that all of this can be done automatically every day: sudo crontab -e If you haven't run this before, choose vim.basic as your editor or your own editor preference when the Select an editor line comes up. We are going to set our backup to automatically run at 11 PM, so we will add this to the crontab: ## Running the backup at 11 PM 00 23 * * * /usr/bin/rsnapshot -c /etc/rsnapshot.conf beta` Multiple Machine or Multiple Server Backups \u00b6 Doing backups of multiple machines from a machine with a RAID array or large storage capacity, either on premises or from across the Internet works very well. If running these backups from across the Internet, you need to make sure that both locations have adequate bandwidth for the backups to occur. You can use rsnapshot to synchronize an on-site server with an off-site backup array or backup server to improve data redundancy. Assumptions \u00b6 We are assuming that you are running rsnapshot from a machine remotely, on-premise. This exact configuration can be duplicated, as indicated above, remotely off-premise as well. In this case, you will want to install rsnapshot on the machine that is doing all of the backups. We are also assuming That the servers you will be backing up to, have a firewall rule that allows the remote machine to SSH into it That each server that you will be backing up has a recent version of rsync installed. For Rocky Linux servers, run dnf install rsync to update your system's version of rsync. That you've either connected to the machine as the root user, or that you have run sudo -s to switch to the root user. SSH Public / Private Keys \u00b6 For the server that will be running the backups, we need to generate an SSH key-pair for use during the backups. For our example, we will be creating RSA keys. If you already have a set of keys generated, you can skip this step. You can find out by doing an ls -al .ssh and looking for an id_rsa and id_rsa.pub key pair. If none exists use the following link to set up your keys and the servers that you want to access: SSH Public Private Key Pairs Rsnapshot Configuration \u00b6 The configuration file needs to be just like the one we created for the Basic Machine or Single Server Backup above, except that we want to change some of the options. The snapshot root can be reverted back to the default like so: snapshot_root /.snapshots/ And this line: no_create_root 1 ... can be commented out again: #no_create_root 1 The other difference here is that each machine will have its very own configuration. Once you get used to this, you'll simply copy one of your existing configuration files over to a new name and then modify it to fit any additional machines that you want to backup. For now, we want to modify the configuration file just like we did above, and then save it. Then copy that file as a template for our first server: cp /etc/rsnapshot.conf /etc/rsnapshot_web.conf We want to modify the new configuration file and create the log and lockfile with the machine's name: logfile /var/log/rsnapshot_web.log lockfile /var/run/rsnapshot_web.pid Next, we want to modify rsnapshot_web.conf so that it includes the directories we want to back up. The only thing that is different here is the target. Here's an example of the web.ourdomain.com configuration: ### BACKUP POINTS / SCRIPTS ### backup root@web.ourourdomain.com:/etc/ web.ourourdomain.com/ backup root@web.ourourdomain.com:/var/www/ web.ourourdomain.com/ backup root@web.ourdomain.com:/usr/local/ web.ourdomain.com/ backup root@web.ourdomain.com:/home/ web.ourdomain.com/ backup root@web.ourdomain.com:/root/ web.ourdomain.com/ Checking The Configuration and Running The Initial Backup \u00b6 Just like before, we can now check the configuration to make sure it is syntactically correct: rsnapshot -c /etc/rsnapshot_web.conf configtest And just like before, we are looking for the Syntax OK message. If all is well, we can execute the backup manually: /usr/bin/rsnapshot -c /etc/rsnapshot_web.conf beta Assuming that everything works alright, we can then create the configuration files for the mail server (rsnapshot_mail.conf) and portal server (rsnapshot_portal.conf), test them, and do a trial backup. Automating The Backup \u00b6 Automating backups for the multiple machine/server version is slightly different. We want to create a bash script to call the backups in order. When one finishes the next will start. This script will look something like this and be stored in /usr/local/sbin: vi /usr/local/sbin/backup_all With the content: #!/bin/bash # script to run rsnapshot backups in succession /usr/bin/rsnapshot -c /etc/rsnapshot_web.conf beta /usr/bin/rsnapshot -c /etc/rsnapshot_mail.conf beta /usr/bin/rsnapshot -c /etc/rsnapshot_portal.conf beta Then we make the script executabe: chmod +x /usr/local/sbin/backup_all Then create the crontab for root to run the backup script: chrontab -e And add this line: ## Running the backup at 11 PM 00 23 * * * /usr/local/sbin/backup_all Reporting The Backup Status \u00b6 To make sure that everything is backing up according to plan, you might want to send the backup log files to your email. If your are running multiple machine backups using rsnapshot, each log file will have its own name, which you can then send to your email for review by Using postfix For Server Process Reporting procedure. Conclusions and Other Resources \u00b6 Getting the setup right with rsnapshot is a little daunting at first, but can save you loads of time backing up your machines or servers. rsnapshot is very powerful, very fast, and very economical on disk space usage. You can find more information on Rsnapshot, by visiting rsnapshot.org","title":"Backup Solution - Rsnapshot"},{"location":"guides/rsnapshot_backup/#backup-solution-rsnapshot","text":"","title":"Backup Solution - Rsnapshot"},{"location":"guides/rsnapshot_backup/#prerequisites","text":"Know how to install additional repositories and snapshots from the command-line Know about mounting filesystems external of your machine (external Hard Drive, remote filesystem, etc.) Know how to use an editor (vi is used here, but you can use your favorite editor) Know a little BASH scripting Know how to modify the crontab for the root user Knowledge of SSH public and private keys (only if you plan to run remote backups from another server)","title":"Prerequisites"},{"location":"guides/rsnapshot_backup/#introduction","text":"rsnapshot is a very powerful backup utility that can be installed on any Linux-based machine. It can either back up a machine locally, or you can back up multiple machines, say servers for instance, from a single machine. rsnapshot uses rsync and is written entirely in perl with no library dependencies, so there are no weird requirements to installing it. In the case of Rocky Linux, you should be able to install rsnapshot simply by installing the EPEL software repository. This documentation covers the installation of rsnapshot on Rocky Linux only.","title":"Introduction"},{"location":"guides/rsnapshot_backup/#installing-rsnapshot","text":"All commands shown here are from the command-line on your server or workstation unless otherwise noted.","title":"Installing Rsnapshot"},{"location":"guides/rsnapshot_backup/#installing-the-epel-repository","text":"We need the EPEL software repo from Fedora to install rsnapshot. To install the repository, just use this command, if you haven't already: sudo dnf install https://dl.fedoraproject.org/pub/epel/epel-release-latest-8.noarch.rpm The repository should now be active.","title":"Installing The EPEL repository"},{"location":"guides/rsnapshot_backup/#install-the-rsnapshot-package","text":"Next, install rsnapshot itself: sudo dnf install rsnapshot If there are any missing dependencies, those will show up and you simply need to answer the prompt to continue. For example: dnf install rsnapshot Last metadata expiration check: 0:00:16 ago on Mon Feb 22 00:12:45 2021. Dependencies resolved. ======================================================================================================================================== Package Architecture Version Repository Size ======================================================================================================================================== Installing: rsnapshot noarch 1.4.3-1.el8 epel 121 k Installing dependencies: perl-Lchown x86_64 1.01-14.el8 epel 18 k rsync x86_64 3.1.3-9.el8 baseos 404 k Transaction Summary ======================================================================================================================================== Install 3 Packages Total download size: 543 k Installed size: 1.2 M Is this ok [y/N]: y","title":"Install the Rsnapshot Package"},{"location":"guides/rsnapshot_backup/#mounting-a-drive-or-filesystem-for-backup","text":"In this step, we show how to mount a hard drive, such as an external USB hard drive, that will be used to back up your system. This particular step is only necessary if you are backing up a single machine or server, as seen in our first example below. Plug in the USB drive. Type dmesg | grep sd which should show you the drive should show you the drive you want to use. In this case, it'll be called sda1 . Example: EXT4-fs (sda1): mounting ext2 file system using the ext4 subsystem . Unfortunately (or fortunately depending on your opinion) most modern Linux desktop operating systems automount the drive if they can. This means that, depending on various factors, rsnapshot might lose track of the hard drive. We want the drive to \"mount\" or make its files available in the same place every time. To do that, take the drive information revealed in the dmesg command above and type mount | grep sda1 , which should show something like this: /dev/sda1 on /media/username/8ea89e5e-9291-45c1-961d-99c346a2628a Type sudo umount /dev/sda1 to unmount your external hard drive. Next, create a new mount point for the backup: sudo mkdir /mnt/backup Now mount the drive to your backup folder location: sudo mount /dev/sda1 /mnt/backup Now type mount | grep sda1 again, and you should see something like this: /dev/sda1 on /mnt/backup type ext2 (rw,relatime) Next create a directory that must exist for the backup to continue on the mounted drive. We are using a folder called \"storage\" for this example: sudo mkdir /mnt/backup/storage Note that for a single machine, you will have to either repeat the umount and mount steps each time the drive is plugged in again, or each time the system reboots, or automate these commands with a script. We recommend automation. Automation is the sysadmin way.","title":"Mounting A Drive or Filesystem For Backup"},{"location":"guides/rsnapshot_backup/#configuring-rsnapshot","text":"This is the most important step. It's easy to make a mistake when making changes to the configuration file. The rsnapshot configuration requires tabs for any separation between elements, and a warning to that effect is at the very top of the configuration file. A space character will cause the entire configuration\u2014and your backup\u2014to fail. For instance, near the top of the configuration file is a section for the # SNAPSHOT ROOT DIRECTORY # . If you were adding this in from scratch, you would type snapshot_root then TAB and then type /whatever_the_path_to_the_snapshot_root_will_be/ The best thing is that the default configuration that comes with rsnapshot only needs minor changes to make it work for a backup of a local machine. It's always a good idea, though, to make a backup copy of the configuration file before you start editing: cp /etc/rsnapshot.conf /etc/rsnapshot.conf.bak","title":"Configuring rsnapshot"},{"location":"guides/rsnapshot_backup/#basic-machine-or-single-server-backup","text":"In this case, rsnapshot is going to be run locally to back up a particular machine. In this example, we'll break down the configuration file, and show you exactly what you need to change. You will need to use vi (or edit with your favorite editor) to open the /etc/rsnapshot.conf file. The first thing to change is the snapshot_root setting which by default has this value: snapshot_root /.snapshots/ We need to change this to our mount point that we created above plus the addition of \"storage\". snapshot_root /mnt/backup/storage/ We also want to tell the backup NOT to run if the drive is not mounted. To do this, remove the \"#\" sign (also called a remark, pound sign, number sign, hash symbol, etc.) next to no_create_root so that it looks like this: no_create_root 1 Next go down to the section titled # EXTERNAL PROGRAM DEPENDENCIES # and remove the comment (again, the \"#\" sign) from this line: #cmd_cp /usr/bin/cp So that it now reads: cmd_cp /usr/bin/cp While we do not need cmd_ssh for this particular configuration, we will need it for our other option below and it doesn't hurt to have it enabled. So find the line that says: #cmd_ssh /usr/bin/ssh And remove the \"#\" sign so that it looks like this: cmd_ssh /usr/bin/ssh Next we need to skip down to the section titled # BACKUP LEVELS / INTERVALS # This has been changed from earlier versions of rsnapshot from hourly, daily, monthly, yearly to alpha, beta, gamma, delta . Which is a bit confusing. What you need to do is add a remark to any interval that you won't be using. In the configuration, delta is already remarked out. For this example, we aren't going to be running any other increments other than a nightly backup, so just add a remark to alpha and gamma so that the configuration looks like this when you are done: #retain alpha 6 retain beta 7 #retain gamma 4 #retain delta 3 Now skip down to the logfile line, which by default should read: #logfile /var/log/rsnapshot And remove the remark so that it is enabled: logfile /var/log/rsnapshot Finally, skip down to the ### BACKUP POINTS / SCRIPTS ### section and add any directories that you want to add in the # LOCALHOST section, remember to use TAB rather than SPACE between elements! For now write your changes ( SHIFT :wq! for vi) and exit the configuration file.","title":"Basic Machine or Single Server Backup"},{"location":"guides/rsnapshot_backup/#checking-the-configuration","text":"We want to make sure that we didn't add spaces or any other glaring errors to our configuration file while we were editing it. To do this, we run rsnapshot against our configuration with the configtest option: rsnapshot configtest will show Syntax OK if there are no errors in the configuration. You should get into the habit of running configtest against a particular configuration. The reason for that will be more evident when we get into the Multiple Machine or Multiple Server Backups section. To run configtest against a particular configuration file, run it with the -c option to specify the configuration: rsnapshot -c /etc/rsnapshot.conf configtest","title":"Checking The Configuration"},{"location":"guides/rsnapshot_backup/#running-the-backup-the-first-time","text":"Everything has checked out, so it's time to go ahead and run the backup for the first time. You can run this in test mode first if you like, so that you can see what the backup script is going to do. Again, to do this you don't necessarily have to specify the configuration in this case, but you should get into the habit of doing so: rsnapshot -c /etc/rsnapshot.conf -t beta Which should return something like this, showing you what will happen when the backup is actually run: echo 1441 > /var/run/rsnapshot.pid mkdir -m 0755 -p /mnt/backup/storage/beta.0/ /usr/bin/rsync -a --delete --numeric-ids --relative --delete-excluded \\ /home/ /mnt/backup/storage/beta.0/localhost/ mkdir -m 0755 -p /mnt/backup/storage/beta.0/ /usr/bin/rsync -a --delete --numeric-ids --relative --delete-excluded /etc/ \\ /mnt/backup/storage/beta.0/localhost/ mkdir -m 0755 -p /mnt/backup/storage/beta.0/ /usr/bin/rsync -a --delete --numeric-ids --relative --delete-excluded \\ /usr/local/ /mnt/backup/storage/beta.0/localhost/ touch /mnt/backup/storage/beta.0/ Once you are satisfied with the test, go ahead and run it manually the first time without the test: rsnapshot -c /etc/rsnapshot.conf beta When the backup finishes, navigate to /mnt/backup and take a look at the directory structure that was created there. There will be a storage/beta.0/localhost directory, followed by the directories that you specified to backup.","title":"Running The Backup The First Time"},{"location":"guides/rsnapshot_backup/#further-explanation","text":"Each time the backup is run, it will create a new beta increment, 0-6, or 7 days worth of backups. The newest backup will always be beta.0 where as yesterday's backup will always be beta.1. The size of each of these backups will appear to take up the same amount (or more) of disk space, but this is because of rsnapshot's use of hard links. To restore files from yesterday's backup, you would simply copy them back from beta.1's directory structure. Each backup is only an incremental backup from the previous run, BUT, because of the use of hard links, each backup directory, contains the file, or the hard-link to the file in whichever directory it actually was backed up in. So to restore files, you don't have to pick and choose which directory or increment to restore them from, just what time stamp the backup should have. It's a great system and uses far less disk space than many other backup solutions.","title":"Further Explanation"},{"location":"guides/rsnapshot_backup/#setting-the-backup-to-run-automatically","text":"Once everything has been tested and we know that things will work without issue, the next step is to set up the crontab for the root user, so that all of this can be done automatically every day: sudo crontab -e If you haven't run this before, choose vim.basic as your editor or your own editor preference when the Select an editor line comes up. We are going to set our backup to automatically run at 11 PM, so we will add this to the crontab: ## Running the backup at 11 PM 00 23 * * * /usr/bin/rsnapshot -c /etc/rsnapshot.conf beta`","title":"Setting The Backup To Run Automatically"},{"location":"guides/rsnapshot_backup/#multiple-machine-or-multiple-server-backups","text":"Doing backups of multiple machines from a machine with a RAID array or large storage capacity, either on premises or from across the Internet works very well. If running these backups from across the Internet, you need to make sure that both locations have adequate bandwidth for the backups to occur. You can use rsnapshot to synchronize an on-site server with an off-site backup array or backup server to improve data redundancy.","title":"Multiple Machine or Multiple Server Backups"},{"location":"guides/rsnapshot_backup/#assumptions","text":"We are assuming that you are running rsnapshot from a machine remotely, on-premise. This exact configuration can be duplicated, as indicated above, remotely off-premise as well. In this case, you will want to install rsnapshot on the machine that is doing all of the backups. We are also assuming That the servers you will be backing up to, have a firewall rule that allows the remote machine to SSH into it That each server that you will be backing up has a recent version of rsync installed. For Rocky Linux servers, run dnf install rsync to update your system's version of rsync. That you've either connected to the machine as the root user, or that you have run sudo -s to switch to the root user.","title":"Assumptions"},{"location":"guides/rsnapshot_backup/#ssh-public-private-keys","text":"For the server that will be running the backups, we need to generate an SSH key-pair for use during the backups. For our example, we will be creating RSA keys. If you already have a set of keys generated, you can skip this step. You can find out by doing an ls -al .ssh and looking for an id_rsa and id_rsa.pub key pair. If none exists use the following link to set up your keys and the servers that you want to access: SSH Public Private Key Pairs","title":"SSH Public / Private Keys"},{"location":"guides/rsnapshot_backup/#rsnapshot-configuration","text":"The configuration file needs to be just like the one we created for the Basic Machine or Single Server Backup above, except that we want to change some of the options. The snapshot root can be reverted back to the default like so: snapshot_root /.snapshots/ And this line: no_create_root 1 ... can be commented out again: #no_create_root 1 The other difference here is that each machine will have its very own configuration. Once you get used to this, you'll simply copy one of your existing configuration files over to a new name and then modify it to fit any additional machines that you want to backup. For now, we want to modify the configuration file just like we did above, and then save it. Then copy that file as a template for our first server: cp /etc/rsnapshot.conf /etc/rsnapshot_web.conf We want to modify the new configuration file and create the log and lockfile with the machine's name: logfile /var/log/rsnapshot_web.log lockfile /var/run/rsnapshot_web.pid Next, we want to modify rsnapshot_web.conf so that it includes the directories we want to back up. The only thing that is different here is the target. Here's an example of the web.ourdomain.com configuration: ### BACKUP POINTS / SCRIPTS ### backup root@web.ourourdomain.com:/etc/ web.ourourdomain.com/ backup root@web.ourourdomain.com:/var/www/ web.ourourdomain.com/ backup root@web.ourdomain.com:/usr/local/ web.ourdomain.com/ backup root@web.ourdomain.com:/home/ web.ourdomain.com/ backup root@web.ourdomain.com:/root/ web.ourdomain.com/","title":"Rsnapshot Configuration"},{"location":"guides/rsnapshot_backup/#checking-the-configuration-and-running-the-initial-backup","text":"Just like before, we can now check the configuration to make sure it is syntactically correct: rsnapshot -c /etc/rsnapshot_web.conf configtest And just like before, we are looking for the Syntax OK message. If all is well, we can execute the backup manually: /usr/bin/rsnapshot -c /etc/rsnapshot_web.conf beta Assuming that everything works alright, we can then create the configuration files for the mail server (rsnapshot_mail.conf) and portal server (rsnapshot_portal.conf), test them, and do a trial backup.","title":"Checking The Configuration and Running The Initial Backup"},{"location":"guides/rsnapshot_backup/#automating-the-backup","text":"Automating backups for the multiple machine/server version is slightly different. We want to create a bash script to call the backups in order. When one finishes the next will start. This script will look something like this and be stored in /usr/local/sbin: vi /usr/local/sbin/backup_all With the content: #!/bin/bash # script to run rsnapshot backups in succession /usr/bin/rsnapshot -c /etc/rsnapshot_web.conf beta /usr/bin/rsnapshot -c /etc/rsnapshot_mail.conf beta /usr/bin/rsnapshot -c /etc/rsnapshot_portal.conf beta Then we make the script executabe: chmod +x /usr/local/sbin/backup_all Then create the crontab for root to run the backup script: chrontab -e And add this line: ## Running the backup at 11 PM 00 23 * * * /usr/local/sbin/backup_all","title":"Automating The Backup"},{"location":"guides/rsnapshot_backup/#reporting-the-backup-status","text":"To make sure that everything is backing up according to plan, you might want to send the backup log files to your email. If your are running multiple machine backups using rsnapshot, each log file will have its own name, which you can then send to your email for review by Using postfix For Server Process Reporting procedure.","title":"Reporting The Backup Status"},{"location":"guides/rsnapshot_backup/#conclusions-and-other-resources","text":"Getting the setup right with rsnapshot is a little daunting at first, but can save you loads of time backing up your machines or servers. rsnapshot is very powerful, very fast, and very economical on disk space usage. You can find more information on Rsnapshot, by visiting rsnapshot.org","title":"Conclusions and Other Resources"},{"location":"guides/rsync_ssh/","text":"Using rsync To Keep Two Machines Synchronized \u00b6 Prerequisites \u00b6 This is everything you'll need to understand and follow along with this guide. A machine running Rocky Linux. To be comfortable with modifying configuration files from the command-line. Knowledge of how to use a command line editor (we use vi here, but you could use your favorite editor). You will need root access, and ideally be signed in as the root user in your terminal. Public and Private SSH key pairs. Able to create a simple bash script, using vi or your favorite editor, and test it. Able to use crontab to automate the running of the script. Introduction \u00b6 Using rsync over SSH is neither as powerful as lsyncd (which allows you to watch a directory or file for changes and keep it synchronized in real time), or as flexible as rsnapshot (which offers the ability to easily backup multiple targets from a single machine). But, it does offer the ability to keep two machines up-to-date on a schedule that you define. rsync has been around since the dawn of time (OK, maybe not quite that long, but a long time!) so every Linux distribution has it available, and most still install it with the base packages. rsync over SSH might be a solution, if you need to keep a set of directories up-to-date on a target machine, but real-time syncing is not particularly important. For all of the below, we will be doing things as the root user, so either login as root or use the sudo -s command to switch to the root user in your terminal. Installing rsync \u00b6 While rsync is probably already installed, it's a good idea to update rsync to the latest version on both the source and target machines. To make sure that rsync is installed and up-to-date, do this on both machines: dnf install rsync If the package is not installed, dnf will ask you to confirm installation and if it is installed, dnf will look for an update and give you the opportunity to install it. Preparing The Environment \u00b6 This particular example will use rsync on the target to pull from the source, rather than pushing from the source to the target, so we will need to set up an SSH key pair for this for this. Once the SSH key pairs are created, and you have confirmed access without a password from the target machine to the source, we are ready to start. rsync Parameters And Setting Up A Script \u00b6 Before we get terribly carried away with the setting up a script, we first need to decide what parameters we want to use with rsync. There are a many possibilities, so take a look at the manual for rsync . The most common way to use rsync is to use the -a option, because -a, or archive, combines a number of options into one and these are very common options. What does -a include? -r, recurse the directories -l, maintain symbolic links as symbolic links -p, preserve permissions -t, preserve modification times -g, preserve group- -o, preserve owner -D, preserve device files The only other options that we need to specify in this example is: -e, specify the remote shell to use --delete, which says if the target directory has a file in it that doesn't exist on the source, get rid of it Next, we need to set up a script by creating a file for it. (Again, use your favorite editor if you are not familiar with vi.) To create the file, just use this command: vi /usr/local/sbin/rsync_dirs And then make it executable: chmod +x /usr/local/sbin/rsync_dirs Testing \u00b6 For now, let's make it super simple and safe so that we can test without fear. Note that below where we are using the URL \"source.domain.com\". Replace that with your own source computer's domain or IP address, both will work. Remember too, that in this case we are creating the script on the \"target\" machine, as we are pulling files in from the source machine: #!/bin/bash /usr/bin/rsync -ae ssh --delete root@source.domain.com:/home/your_user /home In this case, we are assuming that your home directory does not exist on the target. If it does, you may want to back it up before you execute the script! Now run the script: /usr/local/sbin/rsync_dirs If all is well, you should get a completely synchronized copy of your home directory on the target machine. Check to be sure this is the case. Assuming all of that worked out as we hoped, go next go ahead and create a new file on the source machine in your home directory: touch /home/your_user/testfile.txt Run the script again: /usr/local/sbin/rsync_dirs And then verify that the target machine received the new file. If so, the next step is to check the delete process. On the source machine again, remove the file we just created: rm -f /home/your_user/testfile.txt Run the script again: /usr/local/sbin/rsync_dirs Verify the file is now gone on the target machine. Finally, let's create a file on the target machine that doesn't exist on the source. So on the target: touch /home/your_user/a_different_file.txt Run the script a final time: /usr/local/sbin/rsync_dirs The file we just created on the target should now be gone, because it does not exist on the source. Assuming all of this worked as expected, go ahead and modify the script to synchronize all the directories that you want. Automating Everything \u00b6 We probably don't want to be running this script manually every time we want to synchronize, so the next step is to automate this. Let's say that you want to want to run this script every evening at 11 PM. To automate that with Rocky Linux, we use crontab: crontab -e This will pull up the cron, which may look something like this: # Edit this file to introduce tasks to be run by cron. # # Each task to run has to be defined through a single line # indicating with different fields when the task will be run # and what command to run for the task # # To define the time you can provide concrete values for # minute (m), hour (h), day of month (dom), month (mon), # and day of week (dow) or use '*' in these fields (for 'any'). # # Notice that tasks will be started based on the cron's system # daemon's notion of time and timezones. # # Output of the crontab jobs (including errors) is sent through # email to the user the crontab file belongs to (unless redirected). # # For example, you can run a backup of all your user accounts # at 5 a.m every week with: # 0 5 * * 1 tar -zcf /var/backups/home.tgz /home/ # # For more information see the manual pages of crontab(5) and cron(8) # # m h dom mon dow command The cron is set up on a 24 hour clock, so what we will need for our entry at the bottom of this file is: 00 23 * * * /usr/local/sbin/rsync_dirs What this says is to run this command at 00 minutes, 23 hundred hours, every day, every month, and every day of the week. Save your cron entry with: Shift : wq! ... or with the commands that your favorite editor uses for saving a file. Conclusions \u00b6 While rsync may not be as flexible or powerful as some of the other options, it offers simple file synchronization. And there's always a use for that.","title":"Using rsync To Keep Two Machines Synchronized"},{"location":"guides/rsync_ssh/#using-rsync-to-keep-two-machines-synchronized","text":"","title":"Using rsync To Keep Two Machines Synchronized"},{"location":"guides/rsync_ssh/#prerequisites","text":"This is everything you'll need to understand and follow along with this guide. A machine running Rocky Linux. To be comfortable with modifying configuration files from the command-line. Knowledge of how to use a command line editor (we use vi here, but you could use your favorite editor). You will need root access, and ideally be signed in as the root user in your terminal. Public and Private SSH key pairs. Able to create a simple bash script, using vi or your favorite editor, and test it. Able to use crontab to automate the running of the script.","title":"Prerequisites"},{"location":"guides/rsync_ssh/#introduction","text":"Using rsync over SSH is neither as powerful as lsyncd (which allows you to watch a directory or file for changes and keep it synchronized in real time), or as flexible as rsnapshot (which offers the ability to easily backup multiple targets from a single machine). But, it does offer the ability to keep two machines up-to-date on a schedule that you define. rsync has been around since the dawn of time (OK, maybe not quite that long, but a long time!) so every Linux distribution has it available, and most still install it with the base packages. rsync over SSH might be a solution, if you need to keep a set of directories up-to-date on a target machine, but real-time syncing is not particularly important. For all of the below, we will be doing things as the root user, so either login as root or use the sudo -s command to switch to the root user in your terminal.","title":"Introduction"},{"location":"guides/rsync_ssh/#installing-rsync","text":"While rsync is probably already installed, it's a good idea to update rsync to the latest version on both the source and target machines. To make sure that rsync is installed and up-to-date, do this on both machines: dnf install rsync If the package is not installed, dnf will ask you to confirm installation and if it is installed, dnf will look for an update and give you the opportunity to install it.","title":"Installing rsync"},{"location":"guides/rsync_ssh/#preparing-the-environment","text":"This particular example will use rsync on the target to pull from the source, rather than pushing from the source to the target, so we will need to set up an SSH key pair for this for this. Once the SSH key pairs are created, and you have confirmed access without a password from the target machine to the source, we are ready to start.","title":"Preparing The Environment"},{"location":"guides/rsync_ssh/#rsync-parameters-and-setting-up-a-script","text":"Before we get terribly carried away with the setting up a script, we first need to decide what parameters we want to use with rsync. There are a many possibilities, so take a look at the manual for rsync . The most common way to use rsync is to use the -a option, because -a, or archive, combines a number of options into one and these are very common options. What does -a include? -r, recurse the directories -l, maintain symbolic links as symbolic links -p, preserve permissions -t, preserve modification times -g, preserve group- -o, preserve owner -D, preserve device files The only other options that we need to specify in this example is: -e, specify the remote shell to use --delete, which says if the target directory has a file in it that doesn't exist on the source, get rid of it Next, we need to set up a script by creating a file for it. (Again, use your favorite editor if you are not familiar with vi.) To create the file, just use this command: vi /usr/local/sbin/rsync_dirs And then make it executable: chmod +x /usr/local/sbin/rsync_dirs","title":"rsync Parameters And Setting Up A Script"},{"location":"guides/rsync_ssh/#testing","text":"For now, let's make it super simple and safe so that we can test without fear. Note that below where we are using the URL \"source.domain.com\". Replace that with your own source computer's domain or IP address, both will work. Remember too, that in this case we are creating the script on the \"target\" machine, as we are pulling files in from the source machine: #!/bin/bash /usr/bin/rsync -ae ssh --delete root@source.domain.com:/home/your_user /home In this case, we are assuming that your home directory does not exist on the target. If it does, you may want to back it up before you execute the script! Now run the script: /usr/local/sbin/rsync_dirs If all is well, you should get a completely synchronized copy of your home directory on the target machine. Check to be sure this is the case. Assuming all of that worked out as we hoped, go next go ahead and create a new file on the source machine in your home directory: touch /home/your_user/testfile.txt Run the script again: /usr/local/sbin/rsync_dirs And then verify that the target machine received the new file. If so, the next step is to check the delete process. On the source machine again, remove the file we just created: rm -f /home/your_user/testfile.txt Run the script again: /usr/local/sbin/rsync_dirs Verify the file is now gone on the target machine. Finally, let's create a file on the target machine that doesn't exist on the source. So on the target: touch /home/your_user/a_different_file.txt Run the script a final time: /usr/local/sbin/rsync_dirs The file we just created on the target should now be gone, because it does not exist on the source. Assuming all of this worked as expected, go ahead and modify the script to synchronize all the directories that you want.","title":"Testing"},{"location":"guides/rsync_ssh/#automating-everything","text":"We probably don't want to be running this script manually every time we want to synchronize, so the next step is to automate this. Let's say that you want to want to run this script every evening at 11 PM. To automate that with Rocky Linux, we use crontab: crontab -e This will pull up the cron, which may look something like this: # Edit this file to introduce tasks to be run by cron. # # Each task to run has to be defined through a single line # indicating with different fields when the task will be run # and what command to run for the task # # To define the time you can provide concrete values for # minute (m), hour (h), day of month (dom), month (mon), # and day of week (dow) or use '*' in these fields (for 'any'). # # Notice that tasks will be started based on the cron's system # daemon's notion of time and timezones. # # Output of the crontab jobs (including errors) is sent through # email to the user the crontab file belongs to (unless redirected). # # For example, you can run a backup of all your user accounts # at 5 a.m every week with: # 0 5 * * 1 tar -zcf /var/backups/home.tgz /home/ # # For more information see the manual pages of crontab(5) and cron(8) # # m h dom mon dow command The cron is set up on a 24 hour clock, so what we will need for our entry at the bottom of this file is: 00 23 * * * /usr/local/sbin/rsync_dirs What this says is to run this command at 00 minutes, 23 hundred hours, every day, every month, and every day of the week. Save your cron entry with: Shift : wq! ... or with the commands that your favorite editor uses for saving a file.","title":"Automating Everything"},{"location":"guides/rsync_ssh/#conclusions","text":"While rsync may not be as flexible or powerful as some of the other options, it offers simple file synchronization. And there's always a use for that.","title":"Conclusions"},{"location":"guides/secure_ftp_server_vsftpd/","text":"Secure FTP Server - vsftpd \u00b6 Prerequisites \u00b6 Proficiency with a command-line editor (we are using vi in this example) A heavy comfort level with issuing commands from the command-line, viewing logs, and other general systems administrator duties An understanding of PAM, as well as openssl commands is helpful. All commands are run as the root user or sudo Introduction \u00b6 vsftpd is the Very Secure FTP Daemon (FTP being the file transfer protocol). It has been available for many years now, and is actually the default FTP daemon in Rocky Linux, as well as many other Linux distributions. vsftpd allows for the use of virtual users with pluggable authentication modules (PAM). These virtual users don't exist in the system, and have no other permissions except to use FTP. This means that if a virtual user gets compromised, the person with those credentials would have no other permissions once they gained access. Using this setup is very secure indeed, but does require a bit of extra work. Installing vsftpd \u00b6 We also need to make sure openssl is installed. If you are running a web server, this probably is already installed, but just to make sure, you can run: dnf install vsftpd openssl You will also want to enable the vsftpd service: systemctl enable vsftpd But don't start the service just yet. Configuring vsftpd \u00b6 We want to make sure that some settings are disabled and that others are enabled. Generally, when you install vsftpd , it comes with the most sane options already set, but it is a good idea to make sure. To check the configuration file and make changes as necessary, run: vi /etc/vsftpd/vsftpd.conf Look for the line \"anonymous_enable=\" and make sure that it is set to \"NO\" and that it is NOT remarked/commented out. (Remarking out this line will enable anonymous logins). The line should look like this when it is correct: anonymous_enable=NO Make sure that local_enable is set to yes: local_enable=YES Add a line for the local root user. If the server that you are installing this on is a web server, we assume that you will be using the Apache Web Server Multi-Site Setup , and that your local root will reflect that. If your setup is different, or if this is not a web server, adjust the local_root setting: local_root=/var/www/sub-domains Make sure that write_enable is set to yes as well: write_enable=YES Find the line to \"chroot_local_users\", and remove the remark. Then add two lines below so that it looks like this: chroot_local_user=YES allow_writeable_chroot=YES hide_ids=YES Beneath this, we want to add an entirely new section that will deal with virtual users: # Virtual User Settings user_config_dir=/etc/vsftpd/vsftpd_user_conf guest_enable=YES virtual_use_local_privs=YES pam_service_name=vsftpd nopriv_user=vsftpd guest_username=vsftpd We need to add a section near the bottom of the file to force passwords sent over the internet to be encrypted. We need openssl installed and we will need to create the certificate file for this as well. Start by adding these lines at the bottom of the file: rsa_cert_file=/etc/vsftpd/vsftpd.pem rsa_private_key_file=/etc/vsftpd/vsftpd.key ssl_enable=YES allow_anon_ssl=NO force_local_data_ssl=YES force_local_logins_ssl=YES ssl_tlsv1=YES ssl_sslv2=NO ssl_sslv3=NO pasv_min_port=7000 pasv_max_port=7500 Now save your configuration. (That's SHIFT:wq if using vi .) Setting Up The RSA Certificate \u00b6 We need to create the vsftpd RSA certificate file. The author generally figures that a server is good for 4 or 5 years, so set the number of days for this certificate based on the number of years you believe you'll have the server up and running on this hardware. Edit the number of days as you see fit, and then use the below format of the command to create the certificate and private key files: openssl req -x509 -nodes -days 1825 -newkey rsa:2048 -keyout /etc/vsftpd/vsftpd.key -out /etc/vsftpd/vsftpd.pem Like all certificate creation processes, this will start a script that will ask you for some information. This is not a difficult process. Many fields can be left blank. The first field is the country code field, fill this one in with your country two letter code: Country Name (2 letter code) [XX]: Next comes the state or province, fill this in by typing the whole name, not the abbreviation: State or Province Name (full name) []: Next is the locality name. This is your city: Locality Name (eg, city) [Default City]: Next is the company or organizational name. You can leave this blank or fill it in as you see fit: Organization Name (eg, company) [Default Company Ltd]: Next is the organizational unit name. You can fill this in if the server is for a specific division, or leave it blank: Organizational Unit Name (eg, section) []: The next field should be filled in, however you can decide how you want to fill it in. This is the common name of your server. Example: webftp.domainname.ext : Common Name (eg, your name or your server's hostname) []: Finally, there is the email field, which you can certainly leave blank without issue: Email Address []: Once you have completed the form, the certificate will be created. Setting Up Virtual Users \u00b6 As stated earlier, using virtual users for vsftpd is much more secure, because they have no system privileges at all. That said, we need to add a user for the virtual users to use. We also need to add a group: groupadd nogroup And then: useradd --home-dir /home/vsftpd --gid nogroup -m --shell /bin/false vsftpd The user must match the guest_username= line in the vsftpd.conf file. Now navigate to the configuration directory for vsftpd : cd /etc/vsftpd We need to create a new password database that will be used to authenticate our virtual users. We need to create a file to read the virtual users and passwords from that will create the database. In the future, when adding new users, we will want to duplicate this process as well: vi vusers.txt The user and password are line separated, so simply type the user, hit enter, and then type the password. Continue until you have added all of the users you currently want to have access to the system. Example: user_name_a user_password_a user_name_b user_password_b Once the text file is created, we now want to generate the password database that vsftpd will use for the virtual users. This is done with db_load . db_load is provided by libdb-utils which should be loaded on your system, but if it is not, you can simply install it with: dnf install libdb-utils Create the database from the text file with: db_load -T -t hash -f vusers.txt vsftpd-virtual-user.db We need to take just a moment here to reference what db_load is doing here: The -T is used to easily allow the import of a text file into the database. The -t says to specify the underlying access method. The hash is the underlying access method we are specifying. The -f says to read from a specified file. The specified file is vusers.txt . And the database we are creating or adding to is vsftpd-virtual-user.db . Change the default permissions of the database file: chmod 600 vsftpd-virtual-user.db And remove the vusers.txt file: rm vusers.txt When adding new users, simply use vi to create a new vusers.txt file, and re-run the db_load command, which will add the new user/s to the database. Setting Up PAM \u00b6 vsftpd installs a default pam file when you install the package. We are going to replace this with our own content, so always make a backup copy of the old file first. Make a directory for your backup file in /root: mkdir /root/backup_vsftpd_pam Then copy the pam file to this directory: cp /etc/pam.d/vsftpd /root/backup_vsftpd_pam/ Now edit the original file: vi /etc/pam.d/vsftpd Remove everything in this file except the \"#%PAM-1.0\" and then add in the following lines: auth required pam_userdb.so db=/etc/vsftpd/vsftpd-virtual-user account required pam_userdb.so db=/etc/vsftpd/vsftpd-virtual-user session required pam_loginuid.so Save your changes and exit ( SHIFT:wq in vi ). This will enable login for your virtual users defined in vsftpd-virtual-user.db , and will disable local logins. Setting Up The Virtual User's Configuration \u00b6 Each virtual user has their own configuration file, which specifies their own local_root directory. This local root must be owned by the user \"vsftpd\" and the group \"nogroup\". Remember that this was set up in the Setting Up Virtual Users section above. To change the ownership for the directory, simply type this at the command line: chown vsftpd.nogroup /var/www/sub-domains/whatever_the_domain_name_is/html We need to create the file that contains the virtual user's configuration: vi /etc/vsftpd/vsftpd_user_conf/username This will have a single line in it that specifies the virtual user's local_root: local_root=/var/www/sub-domains/com.testdomain/html This file path is specified in the \"Virtual User\" section of the vsftpd.conf file. Starting vsftpd \u00b6 Once all of this is completed, start the vsftpd service and then test your users, assuming that the service starts correctly: systemctl restart vsftpd Testing vsftpd \u00b6 You can test your setup using the command line on a machine and test access to the machine using FTP. That said, the easiest way to test is to test with an FTP client, such as FileZilla . When you test with a virtual user to the server running vsftpd , you should get an SSL certificate trust message. This trust message is saying to the person using the FTP client that the server uses a certificate and asks them to approve the certificate before continuing. Once connected as a virtual user, you should be able to place files in the \"local_root\" folder that we setup for that user. If you are unable to upload a file, then you may need to go back and make sure that each of the above steps is completed. For instance, it could be that the ownership permissions for the \"local_root\" have not been set to the \"vsftpd\" user and the \"nogroup\" group. Conclusions \u00b6 vsftpd is a popular and common ftp server and can be set up as a stand alone server, or as part of an Apache Hardened Web Server . If set up to use virtual users and a certificate, it is quite secure. While there are quite a number of steps to setting up vsftpd as outlined in this document, taking the extra time to set it up correctly will ensure that your server is as secure as it can be.","title":"Secure FTP Server - vsftpd"},{"location":"guides/secure_ftp_server_vsftpd/#secure-ftp-server-vsftpd","text":"","title":"Secure FTP Server - vsftpd"},{"location":"guides/secure_ftp_server_vsftpd/#prerequisites","text":"Proficiency with a command-line editor (we are using vi in this example) A heavy comfort level with issuing commands from the command-line, viewing logs, and other general systems administrator duties An understanding of PAM, as well as openssl commands is helpful. All commands are run as the root user or sudo","title":"Prerequisites"},{"location":"guides/secure_ftp_server_vsftpd/#introduction","text":"vsftpd is the Very Secure FTP Daemon (FTP being the file transfer protocol). It has been available for many years now, and is actually the default FTP daemon in Rocky Linux, as well as many other Linux distributions. vsftpd allows for the use of virtual users with pluggable authentication modules (PAM). These virtual users don't exist in the system, and have no other permissions except to use FTP. This means that if a virtual user gets compromised, the person with those credentials would have no other permissions once they gained access. Using this setup is very secure indeed, but does require a bit of extra work.","title":"Introduction"},{"location":"guides/secure_ftp_server_vsftpd/#installing-vsftpd","text":"We also need to make sure openssl is installed. If you are running a web server, this probably is already installed, but just to make sure, you can run: dnf install vsftpd openssl You will also want to enable the vsftpd service: systemctl enable vsftpd But don't start the service just yet.","title":"Installing vsftpd"},{"location":"guides/secure_ftp_server_vsftpd/#configuring-vsftpd","text":"We want to make sure that some settings are disabled and that others are enabled. Generally, when you install vsftpd , it comes with the most sane options already set, but it is a good idea to make sure. To check the configuration file and make changes as necessary, run: vi /etc/vsftpd/vsftpd.conf Look for the line \"anonymous_enable=\" and make sure that it is set to \"NO\" and that it is NOT remarked/commented out. (Remarking out this line will enable anonymous logins). The line should look like this when it is correct: anonymous_enable=NO Make sure that local_enable is set to yes: local_enable=YES Add a line for the local root user. If the server that you are installing this on is a web server, we assume that you will be using the Apache Web Server Multi-Site Setup , and that your local root will reflect that. If your setup is different, or if this is not a web server, adjust the local_root setting: local_root=/var/www/sub-domains Make sure that write_enable is set to yes as well: write_enable=YES Find the line to \"chroot_local_users\", and remove the remark. Then add two lines below so that it looks like this: chroot_local_user=YES allow_writeable_chroot=YES hide_ids=YES Beneath this, we want to add an entirely new section that will deal with virtual users: # Virtual User Settings user_config_dir=/etc/vsftpd/vsftpd_user_conf guest_enable=YES virtual_use_local_privs=YES pam_service_name=vsftpd nopriv_user=vsftpd guest_username=vsftpd We need to add a section near the bottom of the file to force passwords sent over the internet to be encrypted. We need openssl installed and we will need to create the certificate file for this as well. Start by adding these lines at the bottom of the file: rsa_cert_file=/etc/vsftpd/vsftpd.pem rsa_private_key_file=/etc/vsftpd/vsftpd.key ssl_enable=YES allow_anon_ssl=NO force_local_data_ssl=YES force_local_logins_ssl=YES ssl_tlsv1=YES ssl_sslv2=NO ssl_sslv3=NO pasv_min_port=7000 pasv_max_port=7500 Now save your configuration. (That's SHIFT:wq if using vi .)","title":"Configuring vsftpd"},{"location":"guides/secure_ftp_server_vsftpd/#setting-up-the-rsa-certificate","text":"We need to create the vsftpd RSA certificate file. The author generally figures that a server is good for 4 or 5 years, so set the number of days for this certificate based on the number of years you believe you'll have the server up and running on this hardware. Edit the number of days as you see fit, and then use the below format of the command to create the certificate and private key files: openssl req -x509 -nodes -days 1825 -newkey rsa:2048 -keyout /etc/vsftpd/vsftpd.key -out /etc/vsftpd/vsftpd.pem Like all certificate creation processes, this will start a script that will ask you for some information. This is not a difficult process. Many fields can be left blank. The first field is the country code field, fill this one in with your country two letter code: Country Name (2 letter code) [XX]: Next comes the state or province, fill this in by typing the whole name, not the abbreviation: State or Province Name (full name) []: Next is the locality name. This is your city: Locality Name (eg, city) [Default City]: Next is the company or organizational name. You can leave this blank or fill it in as you see fit: Organization Name (eg, company) [Default Company Ltd]: Next is the organizational unit name. You can fill this in if the server is for a specific division, or leave it blank: Organizational Unit Name (eg, section) []: The next field should be filled in, however you can decide how you want to fill it in. This is the common name of your server. Example: webftp.domainname.ext : Common Name (eg, your name or your server's hostname) []: Finally, there is the email field, which you can certainly leave blank without issue: Email Address []: Once you have completed the form, the certificate will be created.","title":"Setting Up The RSA Certificate"},{"location":"guides/secure_ftp_server_vsftpd/#setting-up-virtual-users","text":"As stated earlier, using virtual users for vsftpd is much more secure, because they have no system privileges at all. That said, we need to add a user for the virtual users to use. We also need to add a group: groupadd nogroup And then: useradd --home-dir /home/vsftpd --gid nogroup -m --shell /bin/false vsftpd The user must match the guest_username= line in the vsftpd.conf file. Now navigate to the configuration directory for vsftpd : cd /etc/vsftpd We need to create a new password database that will be used to authenticate our virtual users. We need to create a file to read the virtual users and passwords from that will create the database. In the future, when adding new users, we will want to duplicate this process as well: vi vusers.txt The user and password are line separated, so simply type the user, hit enter, and then type the password. Continue until you have added all of the users you currently want to have access to the system. Example: user_name_a user_password_a user_name_b user_password_b Once the text file is created, we now want to generate the password database that vsftpd will use for the virtual users. This is done with db_load . db_load is provided by libdb-utils which should be loaded on your system, but if it is not, you can simply install it with: dnf install libdb-utils Create the database from the text file with: db_load -T -t hash -f vusers.txt vsftpd-virtual-user.db We need to take just a moment here to reference what db_load is doing here: The -T is used to easily allow the import of a text file into the database. The -t says to specify the underlying access method. The hash is the underlying access method we are specifying. The -f says to read from a specified file. The specified file is vusers.txt . And the database we are creating or adding to is vsftpd-virtual-user.db . Change the default permissions of the database file: chmod 600 vsftpd-virtual-user.db And remove the vusers.txt file: rm vusers.txt When adding new users, simply use vi to create a new vusers.txt file, and re-run the db_load command, which will add the new user/s to the database.","title":"Setting Up Virtual Users"},{"location":"guides/secure_ftp_server_vsftpd/#setting-up-pam","text":"vsftpd installs a default pam file when you install the package. We are going to replace this with our own content, so always make a backup copy of the old file first. Make a directory for your backup file in /root: mkdir /root/backup_vsftpd_pam Then copy the pam file to this directory: cp /etc/pam.d/vsftpd /root/backup_vsftpd_pam/ Now edit the original file: vi /etc/pam.d/vsftpd Remove everything in this file except the \"#%PAM-1.0\" and then add in the following lines: auth required pam_userdb.so db=/etc/vsftpd/vsftpd-virtual-user account required pam_userdb.so db=/etc/vsftpd/vsftpd-virtual-user session required pam_loginuid.so Save your changes and exit ( SHIFT:wq in vi ). This will enable login for your virtual users defined in vsftpd-virtual-user.db , and will disable local logins.","title":"Setting Up PAM"},{"location":"guides/secure_ftp_server_vsftpd/#setting-up-the-virtual-users-configuration","text":"Each virtual user has their own configuration file, which specifies their own local_root directory. This local root must be owned by the user \"vsftpd\" and the group \"nogroup\". Remember that this was set up in the Setting Up Virtual Users section above. To change the ownership for the directory, simply type this at the command line: chown vsftpd.nogroup /var/www/sub-domains/whatever_the_domain_name_is/html We need to create the file that contains the virtual user's configuration: vi /etc/vsftpd/vsftpd_user_conf/username This will have a single line in it that specifies the virtual user's local_root: local_root=/var/www/sub-domains/com.testdomain/html This file path is specified in the \"Virtual User\" section of the vsftpd.conf file.","title":"Setting Up The Virtual User's Configuration"},{"location":"guides/secure_ftp_server_vsftpd/#starting-vsftpd","text":"Once all of this is completed, start the vsftpd service and then test your users, assuming that the service starts correctly: systemctl restart vsftpd","title":"Starting vsftpd"},{"location":"guides/secure_ftp_server_vsftpd/#testing-vsftpd","text":"You can test your setup using the command line on a machine and test access to the machine using FTP. That said, the easiest way to test is to test with an FTP client, such as FileZilla . When you test with a virtual user to the server running vsftpd , you should get an SSL certificate trust message. This trust message is saying to the person using the FTP client that the server uses a certificate and asks them to approve the certificate before continuing. Once connected as a virtual user, you should be able to place files in the \"local_root\" folder that we setup for that user. If you are unable to upload a file, then you may need to go back and make sure that each of the above steps is completed. For instance, it could be that the ownership permissions for the \"local_root\" have not been set to the \"vsftpd\" user and the \"nogroup\" group.","title":"Testing vsftpd"},{"location":"guides/secure_ftp_server_vsftpd/#conclusions","text":"vsftpd is a popular and common ftp server and can be set up as a stand alone server, or as part of an Apache Hardened Web Server . If set up to use virtual users and a certificate, it is quite secure. While there are quite a number of steps to setting up vsftpd as outlined in this document, taking the extra time to set it up correctly will ensure that your server is as secure as it can be.","title":"Conclusions"},{"location":"guides/ssh_public_private_keys/","text":"SSH Public and Private Key \u00b6 Prerequisites \u00b6 A certain amount of comfort operating from the command line Rocky Linux servers and/or workstations with openssh installed Okay technically, this process whould work on any Linux system with openssh installed Optional: familiarity with linux file and directory permissions Introduction \u00b6 SSH is a protocol used to access one machine from another, usually via the command line. With SSH, you can run commands on remote computers and servers, send files, and generally manage everything you do from one place. When you are working with multiple Rocky Linux servers in multiple locations, or if you are just trying to save some time accessing these servers, you'll want to use an SSH public and private key pair. Key pairs basically make logging into remote machines and running commands easier. This document will guide you through the process of creating the keys and setting up your servers for easy access, with said keys. Process For Generating Keys \u00b6 The following commands are all executed from the command line on your Rocky Linux workstation: ssh-keygen -t rsa Which will display the following: Generating public/private rsa key pair. Enter file in which to save the key (/root/.ssh/id_rsa): Hit Enter to accept the default location. Next the system will show: Enter passphrase (empty for no passphrase): So just hit Enter here. Finally, it will ask for you to re-enter the passphrase: Enter same passphrase again: So hit Enter a final time. You now should have an RSA type public and private key pair in your .ssh directory: ls -a .ssh/ . .. id_rsa id_rsa.pub Now we need to send the public key (id_rsa.pub) to every machine that we are going to be accessing... but before we do that, we need to make sure that we can SSH into the servers that we will be sending the key to. For our example, we are going to be using just three servers. You can either access them via SSH by a DNS name or IP address, but for our example we are going to be using the DNS name. Our example servers are web, mail, and portal. For each server, we will attempt to SSH in (nerds love using SSH as a verb) and leave a terminal window open for each machine: ssh -l root web.ourourdomain.com Assuming that we can login without trouble on all three machines, then the next step is to send our public key over to each server: scp .ssh/id_rsa.pub root@web.ourourdomain.com:/root/ Repeat this step with each of our three machines. In each of the open terminal windows, you should now be able to see id_rsa.pub when you enter the following command: ls -a | grep id_rsa.pub If so, we are now ready to either create or append the authorized_keys file in each server's .ssh directory. On each of the servers, enter this command: ls -a .ssh Important! Make sure you read everything below carefully. If you are not sure if you will break something, then make a backup copy of authorized_keys (if it exists) on each of the machines before continuing. If there is no authorized_keys file listed, then we will create it by entering this command while in our /root directory: cat id_rsa.pub > .ssh/authorized_keys If authorized_keys does exist, then we simply want to append our new public key to the ones that are already there: cat id_rsa.pub >> .ssh/authorized_keys Once the key has been either added to authorized_keys , or the authorized_keys file has been created, try to SSH from your Rocky Linux workstation to the server again. You should not be prompted for a password. Once you have verified that you can SSH in without a password, remove the id_rsa.pub file from the /root directory on each machine. rm id_rsa.pub SSH Directory and authorized_keys Security \u00b6 On each of your target machines, make sure that the following permissions are applied: chmod 700 .ssh/ chmod 600 .ssh/authorized_keys","title":"SSH Public and Private Key"},{"location":"guides/ssh_public_private_keys/#ssh-public-and-private-key","text":"","title":"SSH Public and Private Key"},{"location":"guides/ssh_public_private_keys/#prerequisites","text":"A certain amount of comfort operating from the command line Rocky Linux servers and/or workstations with openssh installed Okay technically, this process whould work on any Linux system with openssh installed Optional: familiarity with linux file and directory permissions","title":"Prerequisites"},{"location":"guides/ssh_public_private_keys/#introduction","text":"SSH is a protocol used to access one machine from another, usually via the command line. With SSH, you can run commands on remote computers and servers, send files, and generally manage everything you do from one place. When you are working with multiple Rocky Linux servers in multiple locations, or if you are just trying to save some time accessing these servers, you'll want to use an SSH public and private key pair. Key pairs basically make logging into remote machines and running commands easier. This document will guide you through the process of creating the keys and setting up your servers for easy access, with said keys.","title":"Introduction"},{"location":"guides/ssh_public_private_keys/#process-for-generating-keys","text":"The following commands are all executed from the command line on your Rocky Linux workstation: ssh-keygen -t rsa Which will display the following: Generating public/private rsa key pair. Enter file in which to save the key (/root/.ssh/id_rsa): Hit Enter to accept the default location. Next the system will show: Enter passphrase (empty for no passphrase): So just hit Enter here. Finally, it will ask for you to re-enter the passphrase: Enter same passphrase again: So hit Enter a final time. You now should have an RSA type public and private key pair in your .ssh directory: ls -a .ssh/ . .. id_rsa id_rsa.pub Now we need to send the public key (id_rsa.pub) to every machine that we are going to be accessing... but before we do that, we need to make sure that we can SSH into the servers that we will be sending the key to. For our example, we are going to be using just three servers. You can either access them via SSH by a DNS name or IP address, but for our example we are going to be using the DNS name. Our example servers are web, mail, and portal. For each server, we will attempt to SSH in (nerds love using SSH as a verb) and leave a terminal window open for each machine: ssh -l root web.ourourdomain.com Assuming that we can login without trouble on all three machines, then the next step is to send our public key over to each server: scp .ssh/id_rsa.pub root@web.ourourdomain.com:/root/ Repeat this step with each of our three machines. In each of the open terminal windows, you should now be able to see id_rsa.pub when you enter the following command: ls -a | grep id_rsa.pub If so, we are now ready to either create or append the authorized_keys file in each server's .ssh directory. On each of the servers, enter this command: ls -a .ssh Important! Make sure you read everything below carefully. If you are not sure if you will break something, then make a backup copy of authorized_keys (if it exists) on each of the machines before continuing. If there is no authorized_keys file listed, then we will create it by entering this command while in our /root directory: cat id_rsa.pub > .ssh/authorized_keys If authorized_keys does exist, then we simply want to append our new public key to the ones that are already there: cat id_rsa.pub >> .ssh/authorized_keys Once the key has been either added to authorized_keys , or the authorized_keys file has been created, try to SSH from your Rocky Linux workstation to the server again. You should not be prompted for a password. Once you have verified that you can SSH in without a password, remove the id_rsa.pub file from the /root directory on each machine. rm id_rsa.pub","title":"Process For Generating Keys"},{"location":"guides/ssh_public_private_keys/#ssh-directory-and-authorized_keys-security","text":"On each of your target machines, make sure that the following permissions are applied: chmod 700 .ssh/ chmod 600 .ssh/authorized_keys","title":"SSH Directory and authorized_keys Security"},{"location":"guides/ssl_keys_https/","text":"Generating SSL Keys \u00b6 Prerequisites \u00b6 A workstation and a server running Rocky Linux (OK, Linux, but really, you want Rocky Linux, right?) OpenSSL installed on the machine that you are going to be generating the private key and CSR, as well as on the server where you will eventually be installing your key and certificates Able to run commands comfortably from the command-line Helpful: knowledge of SSL and OpenSSL commands Introduction \u00b6 Nearly every web site today should be running with an SSL (secure socket layer) certificate. This procedure will guide you through generating the private key for your web site and then from this, generating the CSR (certificate signing request) that you will use to purchase your new certificate. Generate The Private Key \u00b6 For the uninitiated, SSL private keys can have different sizes, measured in bits, which basically determines how hard they are to crack. As of 2021, the recommended private key size for a web site is still 2048 bits. You can go higher, but doubling the key size from 2048 bits to 4096 bits is only about 16% more secure, takes more space to store the key, causes higher CPU loads when the key is processed. This slows down your web site performance without gaining any significant security. Stick with the 2048 key size for now and always keep tabs on what is currently recommended. To start with, let's make sure that OpenSSL is installed on both your workstation and server: dnf install openssl If it is not installed, your system will install it and any needed dependencies. Our example domain is ourownwiki.com. Keep in mind that you would need to purchase and register your domain ahead of time. You can purchase domains through a number of \"Registrars\". If you are not running your own DNS (Domain Name System), you can often use the same providers for DNS hosting. DNS translates your named domain, to numbers (IP addresses, either IPv4 or IPv6) that the Internet can understand. These IP addresses will be where the web site is actually hosted. Let's generate the key using openssl: openssl genrsa -des3 -out ourownwiki.com.key.pass 2048 Note that we named the key, with a .pass extension. That's because as soon as we execute this command, it requests that you enter a passphrase. Enter a simple passphrase that you can remember as we are going to be removing this shortly: Enter pass phrase for ourownwiki.com.key.pass: Verifying - Enter pass phrase for ourownwiki.com.key.pass: Next, let's remove that passphrase. The reason for this is that if you don't remove it, each time your web server restarts and loads up your key, you will need to enter that passphrase. You might not even be around to enter it, or worse, might not have a console at the ready to enter it. Remove it now to avoid all of that: openssl rsa -in ourownwiki.com.key.pass -out ourownwiki.com.key This will request that passphrase once again to remove the passphrase from the key: Enter pass phrase for ourownwiki.com.key.pass: Now that you have entered the passphrase a third time, it has been removed from the key file and saved as ourownwiki.com.key Generate the CSR \u00b6 Next, we need to generate the CSR (certificate signing request) that we will use to purchase our certificate. During the generation of the CSR, you will be prompted for several pieces of information. These are the X.509 attributes of the certificate. One of the prompts will be for \"Common Name (e.g., YOUR name)\". It is important that this field be filled in with the fully qualified domain name of the server to be protected by SSL. If the website to be protected will be https://www.ourownwiki.com, then enter www.ourownwiki.com at this prompt: openssl req -new -key ourownwiki.com.key -out ourownwiki.com.csr This opens up a dialog: Country Name (2 letter code) [XX]: enter the two character country code where your site resides, example \"US\" State or Province Name (full name) []: enter the full official name of your state or province, example \"Nebraska\" Locality Name (eg, city) [Default City]: enter the full city name, example \"Omaha\" Organization Name (eg, company) [Default Company Ltd]: If you want, you can enter an organization that this domain is a part of, or just hit 'Enter' to skip. Organizational Unit Name (eg, section) []: This would describe the division of the organization that your domain falls under. Again, you can just hit 'Enter' to skip. Common Name (eg, your name or your server's hostname) []: Here, we have to enter our site hostname, example \"www.ourownwiki.com\" Email Address []: This field is optional, you can decide to fill it out or just hit 'Enter' to skip. Next, you will be asked to enter extra attributes which can be skipped by hitting 'Enter' through both: Please enter the following 'extra' attributes to be sent with your certificate request A challenge password []: An optional company name []: Now you should have generated your CSR. Purchasing The Certificate \u00b6 Each certificate vendor will have basically the same procedure. You purchase the SSL and term (1 or 2 years, etc.) and then you submit your CSR. To do this, you will need to use the more command, and then copy the contents of your CSR file. more ourownwiki.com.csr Which will show you something like this: -----BEGIN CERTIFICATE REQUEST----- MIICrTCCAZUCAQAwaDELMAkGA1UEBhMCVVMxETAPBgNVBAgMCE5lYnJhc2thMQ4w DAYDVQQHDAVPbWFoYTEcMBoGA1UECgwTRGVmYXVsdCBDb21wYW55IEx0ZDEYMBYG A1UEAwwPd3d3Lm91cndpa2kuY29tMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIB CgKCAQEAzwN02erkv9JDhpR8NsJ9eNSm/bLW/jNsZxlxOS3BSOOfQDdUkX0rAt4G nFyBAHRAyxyRvxag13O1rVdKtxUv96E+v76KaEBtXTIZOEZgV1visZoih6U44xGr wcrNnotMB5F/T92zYsK2+GG8F1p9zA8UxO5VrKRL7RL3DtcUwJ8GSbuudAnBhueT nLlPk2LB6g6jCaYbSF7RcK9OL304varo6Uk0zSFprrg/Cze8lxNAxbFzfhOBIsTo PafcA1E8f6y522L9Vaen21XsHyUuZBpooopNqXsG62dcpLy7sOXeBnta4LbHsTLb hOmLrK8RummygUB8NKErpXz3RCEn6wIDAQABoAAwDQYJKoZIhvcNAQELBQADggEB ABMLz/omVg8BbbKYNZRevsSZ80leyV8TXpmP+KaSAWhMcGm/bzx8aVAyqOMLR+rC V7B68BqOdBtkj9g3u8IerKNRwv00pu2O/LOsOznphFrRQUaarQwAvKQKaNEG/UPL gArmKdlDilXBcUFaC2WxBWgxXI6tsE40v4y1zJNZSWsCbjZj4Xj41SB7FemB4SAR RhuaGAOwZnzJBjX60OVzDCZHsfokNobHiAZhRWldVNct0jfFmoRXb4EvWVcbLHnS E5feDUgu+YQ6ThliTrj2VJRLOAv0Qsum5Yl1uF+FZF9x6/nU/SurUhoSYHQ6Co93 HFOltYOnfvz6tOEP39T/wMo= -----END CERTIFICATE REQUEST----- You want to copy everything including the \"BEGIN CERTIFICATE REQUEST\" and \"END CERTIFICATE REQUEST\" lines. Then paste these into the CSR field on the web site where you are purchasing the certificate. You may have to perform other verification steps, depending on ownership of the domain, the registrar you are using, etc., before your certificate is issued. When it is issued, it should be issued along with an intermediate certificate from the provider, which you will use in the configuration as well. Conclusion \u00b6 Generating all of the bits and pieces for the purchase of a web site certificate is not terribly difficult and can be performed by the systems administrator or web site administrator using the above procedure.","title":"Generating SSL Keys"},{"location":"guides/ssl_keys_https/#generating-ssl-keys","text":"","title":"Generating SSL Keys"},{"location":"guides/ssl_keys_https/#prerequisites","text":"A workstation and a server running Rocky Linux (OK, Linux, but really, you want Rocky Linux, right?) OpenSSL installed on the machine that you are going to be generating the private key and CSR, as well as on the server where you will eventually be installing your key and certificates Able to run commands comfortably from the command-line Helpful: knowledge of SSL and OpenSSL commands","title":"Prerequisites"},{"location":"guides/ssl_keys_https/#introduction","text":"Nearly every web site today should be running with an SSL (secure socket layer) certificate. This procedure will guide you through generating the private key for your web site and then from this, generating the CSR (certificate signing request) that you will use to purchase your new certificate.","title":"Introduction"},{"location":"guides/ssl_keys_https/#generate-the-private-key","text":"For the uninitiated, SSL private keys can have different sizes, measured in bits, which basically determines how hard they are to crack. As of 2021, the recommended private key size for a web site is still 2048 bits. You can go higher, but doubling the key size from 2048 bits to 4096 bits is only about 16% more secure, takes more space to store the key, causes higher CPU loads when the key is processed. This slows down your web site performance without gaining any significant security. Stick with the 2048 key size for now and always keep tabs on what is currently recommended. To start with, let's make sure that OpenSSL is installed on both your workstation and server: dnf install openssl If it is not installed, your system will install it and any needed dependencies. Our example domain is ourownwiki.com. Keep in mind that you would need to purchase and register your domain ahead of time. You can purchase domains through a number of \"Registrars\". If you are not running your own DNS (Domain Name System), you can often use the same providers for DNS hosting. DNS translates your named domain, to numbers (IP addresses, either IPv4 or IPv6) that the Internet can understand. These IP addresses will be where the web site is actually hosted. Let's generate the key using openssl: openssl genrsa -des3 -out ourownwiki.com.key.pass 2048 Note that we named the key, with a .pass extension. That's because as soon as we execute this command, it requests that you enter a passphrase. Enter a simple passphrase that you can remember as we are going to be removing this shortly: Enter pass phrase for ourownwiki.com.key.pass: Verifying - Enter pass phrase for ourownwiki.com.key.pass: Next, let's remove that passphrase. The reason for this is that if you don't remove it, each time your web server restarts and loads up your key, you will need to enter that passphrase. You might not even be around to enter it, or worse, might not have a console at the ready to enter it. Remove it now to avoid all of that: openssl rsa -in ourownwiki.com.key.pass -out ourownwiki.com.key This will request that passphrase once again to remove the passphrase from the key: Enter pass phrase for ourownwiki.com.key.pass: Now that you have entered the passphrase a third time, it has been removed from the key file and saved as ourownwiki.com.key","title":"Generate The Private Key"},{"location":"guides/ssl_keys_https/#generate-the-csr","text":"Next, we need to generate the CSR (certificate signing request) that we will use to purchase our certificate. During the generation of the CSR, you will be prompted for several pieces of information. These are the X.509 attributes of the certificate. One of the prompts will be for \"Common Name (e.g., YOUR name)\". It is important that this field be filled in with the fully qualified domain name of the server to be protected by SSL. If the website to be protected will be https://www.ourownwiki.com, then enter www.ourownwiki.com at this prompt: openssl req -new -key ourownwiki.com.key -out ourownwiki.com.csr This opens up a dialog: Country Name (2 letter code) [XX]: enter the two character country code where your site resides, example \"US\" State or Province Name (full name) []: enter the full official name of your state or province, example \"Nebraska\" Locality Name (eg, city) [Default City]: enter the full city name, example \"Omaha\" Organization Name (eg, company) [Default Company Ltd]: If you want, you can enter an organization that this domain is a part of, or just hit 'Enter' to skip. Organizational Unit Name (eg, section) []: This would describe the division of the organization that your domain falls under. Again, you can just hit 'Enter' to skip. Common Name (eg, your name or your server's hostname) []: Here, we have to enter our site hostname, example \"www.ourownwiki.com\" Email Address []: This field is optional, you can decide to fill it out or just hit 'Enter' to skip. Next, you will be asked to enter extra attributes which can be skipped by hitting 'Enter' through both: Please enter the following 'extra' attributes to be sent with your certificate request A challenge password []: An optional company name []: Now you should have generated your CSR.","title":"Generate the CSR"},{"location":"guides/ssl_keys_https/#purchasing-the-certificate","text":"Each certificate vendor will have basically the same procedure. You purchase the SSL and term (1 or 2 years, etc.) and then you submit your CSR. To do this, you will need to use the more command, and then copy the contents of your CSR file. more ourownwiki.com.csr Which will show you something like this: -----BEGIN CERTIFICATE REQUEST----- MIICrTCCAZUCAQAwaDELMAkGA1UEBhMCVVMxETAPBgNVBAgMCE5lYnJhc2thMQ4w DAYDVQQHDAVPbWFoYTEcMBoGA1UECgwTRGVmYXVsdCBDb21wYW55IEx0ZDEYMBYG A1UEAwwPd3d3Lm91cndpa2kuY29tMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIB CgKCAQEAzwN02erkv9JDhpR8NsJ9eNSm/bLW/jNsZxlxOS3BSOOfQDdUkX0rAt4G nFyBAHRAyxyRvxag13O1rVdKtxUv96E+v76KaEBtXTIZOEZgV1visZoih6U44xGr wcrNnotMB5F/T92zYsK2+GG8F1p9zA8UxO5VrKRL7RL3DtcUwJ8GSbuudAnBhueT nLlPk2LB6g6jCaYbSF7RcK9OL304varo6Uk0zSFprrg/Cze8lxNAxbFzfhOBIsTo PafcA1E8f6y522L9Vaen21XsHyUuZBpooopNqXsG62dcpLy7sOXeBnta4LbHsTLb hOmLrK8RummygUB8NKErpXz3RCEn6wIDAQABoAAwDQYJKoZIhvcNAQELBQADggEB ABMLz/omVg8BbbKYNZRevsSZ80leyV8TXpmP+KaSAWhMcGm/bzx8aVAyqOMLR+rC V7B68BqOdBtkj9g3u8IerKNRwv00pu2O/LOsOznphFrRQUaarQwAvKQKaNEG/UPL gArmKdlDilXBcUFaC2WxBWgxXI6tsE40v4y1zJNZSWsCbjZj4Xj41SB7FemB4SAR RhuaGAOwZnzJBjX60OVzDCZHsfokNobHiAZhRWldVNct0jfFmoRXb4EvWVcbLHnS E5feDUgu+YQ6ThliTrj2VJRLOAv0Qsum5Yl1uF+FZF9x6/nU/SurUhoSYHQ6Co93 HFOltYOnfvz6tOEP39T/wMo= -----END CERTIFICATE REQUEST----- You want to copy everything including the \"BEGIN CERTIFICATE REQUEST\" and \"END CERTIFICATE REQUEST\" lines. Then paste these into the CSR field on the web site where you are purchasing the certificate. You may have to perform other verification steps, depending on ownership of the domain, the registrar you are using, etc., before your certificate is issued. When it is issued, it should be issued along with an intermediate certificate from the provider, which you will use in the configuration as well.","title":"Purchasing The Certificate"},{"location":"guides/ssl_keys_https/#conclusion","text":"Generating all of the bits and pieces for the purchase of a web site certificate is not terribly difficult and can be performed by the systems administrator or web site administrator using the above procedure.","title":"Conclusion"},{"location":"guides/apache_hardened_webserver/","text":"Introduction \u00b6 Prerequisites And Assumptions \u00b6 A Rocky Linux Web Server running Apache A heavy comfort level with issuing commands from the command-line, viewing logs, and other general systems administrator duties A comfort level with a command line editor (our examples use vi , but you can substitute in your favorite editor) Assumes an iptables firewall, rather than firewalld or hardware firewall. Assumes the use of a hardware firewall that our trusted devices will sit behind. Assumes a public IP address directly applied to the web server. We are substituting a private IP address for all of our examples. Introduction \u00b6 Whether you are hosting multiple web sites for customers or a single, very important, web site for your business, hardening your web server will give you peace of mind, at the expense of a little more up-front work for the administrator. With multiple web sites uploaded by your customers, you can pretty much be guaranteed that one of them will upload a Content Management System (CMS) with the possibility of vulnerabilities. Most customers are focused on ease of use, not security, and what happens is that updating their own CMS becomes a process that falls out of their priority list altogether. While notifying customers of vulnerabilities in their CMS may be possible for a company with a large IT staff, it may not be possible for a small department. The best defense is a hardened web server. Web server hardening can take many forms, which may include any or all of the below tools, and possibly others not defined here. You might elect to use a couple of these tools and not the others, so for clarity and readability this document is split out into separate documents for each tool. The exception will be the packet-based firewall ( iptables ) which will be included in this main document. A good packet filter firewall based on ports (iptables, firewalld, or hardware firewall - we will use iptables for our example) iptables procedure A Host-based Intrusion Detection System (HIDS), in this case ossec-hids Apache Hardened Web Server - ossec-hids A Web-based Application Firewall (WAF), with mod_security rules Apache Hardened Web Server - mod_security Rootkit Hunter (rkhunter): A scan tool that checks against Linux malware Apache Hardened Web Server - rkhunter Database security (we are using mariadb-server here) Database - mariadb-server A secure FTP or SFTP server (we are using vsftpd here) Secure FTP Server - vsftpd This procedure does not replace the Apache Web Server Multi-Site Setup , it simply adds these security elements to it. If you haven't read it, take some time to look at it before proceeding. Other Considerations \u00b6 Some of the tools outlined here have both free and fee-based options. Depending on your needs or support requirements, you may want to consider the fee-based versions. You should research what is out there and make a decision after weighing all of your options. Know, too, that most of these options can be purchased as hardware appliances. If you'd prefer not to hassle with installing and maintaining your own system, there are options available other than those outlined here. This document uses a straight iptables firewall and requires this procedure on Rocky Linux to disable firewalld and enable the iptables services . If you prefer to use firewalld , simply skip this step and apply the rules needed. The firewall in our examples here, needs no OUTPUT or FORWARD chains, only INPUT. Your needs may differ! All of these tools need to be tuned to your system. That can only be done with careful monitoring of logs, and reported web experience by your customers. In addition, you will find that there will be ongoing tuning required over time. Even though we are using a private IP address to simulate a public one, all of this could have been done using a one-to-one NAT on the hardware firewall and connecting the web server to that hardware firewall, rather than to the gateway router, with a private IP address. Explaining that requires digging into the hardware firewall shown below, and since that is outside of the scope of this document, it is better to stick with our example of a simulated public IP address. Conventions \u00b6 IP Addresses: We are simulating the public IP address here with a private block: 192.168.1.0/24 and we are using the LAN IP address block as 10.0.0.0/24 In other words, it cannot be routed over the Internet. In reality, neither IP block can be routed over the Internet as they are both reserved for private use, but there is no good way to simulate the public IP block, without using a real IP address that is assigned to some company. Just remember that for our purposes, the 192.168.1.0/24 block is the \"public\" IP block and the 10.0.0.0/24 is the \"private\" IP block. Hardware Firewall: This is the firewall that controls access to your server room devices from your trusted network. This is not the same as our iptables firewall, though it could be another instance of iptables running on another machine. This device will allow ICMP (ping) and SSH (secure shell) to our trusted devices. Defining this device is outside of the scope of this document. The author has used both PfSense and OPNSense and installed on dedicated hardware for this device with great success. This device will have two IP addresses assigned to it. One that will connect to the Internet router's simulated public IP (192.168.1.2) and one that will connect to our local area network, 10.0.0.1. Internet Router IP: We are simulating this with 192.168.1.1/24 Web Server IP: This is the \"public\" IP address assigned to our web server. Again, we are simulating this with the private IP address 192.168.1.10/24 The diagram above shows our general layout. The iptables packet-based firewall runs on the web server (shown above). Install Packages \u00b6 Each individual package section has the needed installation files and any configuration procedure listed. The installation instructions for iptables is part of the disable firewalld and enable the iptables services procedure. Configuring iptables \u00b6 This portion of the documentation assumes that you have elected to install the iptables services and utilities and that you are not planning on using firewalld . If you are planning on using firewalld , you can use this iptables script to guide you in creating the appropriate rules in the firewalld format. Once the script is shown here, we will break it down to describe what is happening. Only the INPUT chain is needed here. The script is being placed in the /etc/ directory and for our example, it is named firewall.conf: vi /etc/firewall.conf and the contents will be: #!/bin/sh # #IPTABLES=/usr/sbin/iptables # Unless specified, the defaults for OUTPUT is ACCEPT # The default for FORWARD and INPUT is DROP # echo \" clearing any existing rules and setting default policy..\" iptables -F INPUT iptables -P INPUT DROP iptables -A INPUT -p tcp -m tcp -s 192.168.1.2 --dport 22 -j ACCEPT iptables -A INPUT -p icmp -m icmp --icmp-type 8 -s 192.168.1.2 -j ACCEPT # dns rules iptables -A INPUT -p udp -m udp -s 8.8.8.8 --sport 53 -d 0/0 -j ACCEPT iptables -A INPUT -p udp -m udp -s 8.8.4.4 --sport 53 -d 0/0 -j ACCEPT # web ports iptables -A INPUT -p tcp -m tcp --dport 80 -j ACCEPT iptables -A INPUT -p tcp -m tcp --dport 443 -j ACCEPT # ftp ports iptables -A INPUT -p tcp -m tcp --dport 20-21 -j ACCEPT iptables -A INPUT -p tcp -m tcp --dport 7000-7500 -j ACCEPT iptables -A INPUT -i lo -j ACCEPT iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT iptables -A INPUT -p tcp -j REJECT --reject-with tcp-reset iptables -A INPUT -p udp -j REJECT --reject-with icmp-port-unreachable /usr/sbin/service iptables save So here's what is happening above: When we start, we flush all of the rules We then set the default policy for our INPUT chain to DROP, which says, \"Hey, if we haven't explicitly allowed you here, then we are dropping you!\" Then we allow SSH (port 22) from our trusted network, the devices behind the hardware firewall We allow DNS from some public DNS resolvers. (these can also be local DNS servers, if you have them) We allow our web traffic in from anywhere over port 80 and 443. We allow standard FTP (ports 20-21) and the passive ports needed to exchange two-way communications in FTP (7000-7500). These ports can be arbitrarily changed to other ports based on your ftp server configuration. We allow any traffic on the local interface (127.0.0.1) Then we say, that any traffic that has successfully connected based on the rules, should be allowed other traffic (ports) to maintain their connection (ESTABLISHED,RELATED). And finally, we reject all other traffic and set the script to save the rules where iptables expects to find them. Once this script is there, we need to make it executable: chmod +x /etc/firewall.conf We need to enable iptables if we haven't already: systemctl enable iptables We need to start iptables : systemctl start iptables We need to run /etc/firewall.conf: /etc/firewall.conf If we add new rules to the /etc/firewall.conf, just run it again to take those rules live. Keep in mind that with a default DROP policy for the INPUT chain, if you make a mistake, you could lock yourself out remotely. You can always fix this however, from the console on the server. Because the iptables service is enabled, a reboot will restore all rules that have been added with /etc/firewall.conf . Conclusions \u00b6 There are a number of ways to harden an Apache web server to make it more secure. Each operates independently of the other options, so you can choose to install any or all of them based on your needs. Each requires some configuration with various tuning required for some to meet your specific needs. Since web services are constantly attacked by unscrupulous actors, implementing at least some of these will help an administrator sleep at night.","title":"Introduction"},{"location":"guides/apache_hardened_webserver/#introduction","text":"","title":"Introduction"},{"location":"guides/apache_hardened_webserver/#prerequisites-and-assumptions","text":"A Rocky Linux Web Server running Apache A heavy comfort level with issuing commands from the command-line, viewing logs, and other general systems administrator duties A comfort level with a command line editor (our examples use vi , but you can substitute in your favorite editor) Assumes an iptables firewall, rather than firewalld or hardware firewall. Assumes the use of a hardware firewall that our trusted devices will sit behind. Assumes a public IP address directly applied to the web server. We are substituting a private IP address for all of our examples.","title":"Prerequisites And Assumptions"},{"location":"guides/apache_hardened_webserver/#introduction_1","text":"Whether you are hosting multiple web sites for customers or a single, very important, web site for your business, hardening your web server will give you peace of mind, at the expense of a little more up-front work for the administrator. With multiple web sites uploaded by your customers, you can pretty much be guaranteed that one of them will upload a Content Management System (CMS) with the possibility of vulnerabilities. Most customers are focused on ease of use, not security, and what happens is that updating their own CMS becomes a process that falls out of their priority list altogether. While notifying customers of vulnerabilities in their CMS may be possible for a company with a large IT staff, it may not be possible for a small department. The best defense is a hardened web server. Web server hardening can take many forms, which may include any or all of the below tools, and possibly others not defined here. You might elect to use a couple of these tools and not the others, so for clarity and readability this document is split out into separate documents for each tool. The exception will be the packet-based firewall ( iptables ) which will be included in this main document. A good packet filter firewall based on ports (iptables, firewalld, or hardware firewall - we will use iptables for our example) iptables procedure A Host-based Intrusion Detection System (HIDS), in this case ossec-hids Apache Hardened Web Server - ossec-hids A Web-based Application Firewall (WAF), with mod_security rules Apache Hardened Web Server - mod_security Rootkit Hunter (rkhunter): A scan tool that checks against Linux malware Apache Hardened Web Server - rkhunter Database security (we are using mariadb-server here) Database - mariadb-server A secure FTP or SFTP server (we are using vsftpd here) Secure FTP Server - vsftpd This procedure does not replace the Apache Web Server Multi-Site Setup , it simply adds these security elements to it. If you haven't read it, take some time to look at it before proceeding.","title":"Introduction"},{"location":"guides/apache_hardened_webserver/#other-considerations","text":"Some of the tools outlined here have both free and fee-based options. Depending on your needs or support requirements, you may want to consider the fee-based versions. You should research what is out there and make a decision after weighing all of your options. Know, too, that most of these options can be purchased as hardware appliances. If you'd prefer not to hassle with installing and maintaining your own system, there are options available other than those outlined here. This document uses a straight iptables firewall and requires this procedure on Rocky Linux to disable firewalld and enable the iptables services . If you prefer to use firewalld , simply skip this step and apply the rules needed. The firewall in our examples here, needs no OUTPUT or FORWARD chains, only INPUT. Your needs may differ! All of these tools need to be tuned to your system. That can only be done with careful monitoring of logs, and reported web experience by your customers. In addition, you will find that there will be ongoing tuning required over time. Even though we are using a private IP address to simulate a public one, all of this could have been done using a one-to-one NAT on the hardware firewall and connecting the web server to that hardware firewall, rather than to the gateway router, with a private IP address. Explaining that requires digging into the hardware firewall shown below, and since that is outside of the scope of this document, it is better to stick with our example of a simulated public IP address.","title":"Other Considerations"},{"location":"guides/apache_hardened_webserver/#conventions","text":"IP Addresses: We are simulating the public IP address here with a private block: 192.168.1.0/24 and we are using the LAN IP address block as 10.0.0.0/24 In other words, it cannot be routed over the Internet. In reality, neither IP block can be routed over the Internet as they are both reserved for private use, but there is no good way to simulate the public IP block, without using a real IP address that is assigned to some company. Just remember that for our purposes, the 192.168.1.0/24 block is the \"public\" IP block and the 10.0.0.0/24 is the \"private\" IP block. Hardware Firewall: This is the firewall that controls access to your server room devices from your trusted network. This is not the same as our iptables firewall, though it could be another instance of iptables running on another machine. This device will allow ICMP (ping) and SSH (secure shell) to our trusted devices. Defining this device is outside of the scope of this document. The author has used both PfSense and OPNSense and installed on dedicated hardware for this device with great success. This device will have two IP addresses assigned to it. One that will connect to the Internet router's simulated public IP (192.168.1.2) and one that will connect to our local area network, 10.0.0.1. Internet Router IP: We are simulating this with 192.168.1.1/24 Web Server IP: This is the \"public\" IP address assigned to our web server. Again, we are simulating this with the private IP address 192.168.1.10/24 The diagram above shows our general layout. The iptables packet-based firewall runs on the web server (shown above).","title":"Conventions"},{"location":"guides/apache_hardened_webserver/#install-packages","text":"Each individual package section has the needed installation files and any configuration procedure listed. The installation instructions for iptables is part of the disable firewalld and enable the iptables services procedure.","title":"Install Packages"},{"location":"guides/apache_hardened_webserver/#configuring-iptables","text":"This portion of the documentation assumes that you have elected to install the iptables services and utilities and that you are not planning on using firewalld . If you are planning on using firewalld , you can use this iptables script to guide you in creating the appropriate rules in the firewalld format. Once the script is shown here, we will break it down to describe what is happening. Only the INPUT chain is needed here. The script is being placed in the /etc/ directory and for our example, it is named firewall.conf: vi /etc/firewall.conf and the contents will be: #!/bin/sh # #IPTABLES=/usr/sbin/iptables # Unless specified, the defaults for OUTPUT is ACCEPT # The default for FORWARD and INPUT is DROP # echo \" clearing any existing rules and setting default policy..\" iptables -F INPUT iptables -P INPUT DROP iptables -A INPUT -p tcp -m tcp -s 192.168.1.2 --dport 22 -j ACCEPT iptables -A INPUT -p icmp -m icmp --icmp-type 8 -s 192.168.1.2 -j ACCEPT # dns rules iptables -A INPUT -p udp -m udp -s 8.8.8.8 --sport 53 -d 0/0 -j ACCEPT iptables -A INPUT -p udp -m udp -s 8.8.4.4 --sport 53 -d 0/0 -j ACCEPT # web ports iptables -A INPUT -p tcp -m tcp --dport 80 -j ACCEPT iptables -A INPUT -p tcp -m tcp --dport 443 -j ACCEPT # ftp ports iptables -A INPUT -p tcp -m tcp --dport 20-21 -j ACCEPT iptables -A INPUT -p tcp -m tcp --dport 7000-7500 -j ACCEPT iptables -A INPUT -i lo -j ACCEPT iptables -A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT iptables -A INPUT -p tcp -j REJECT --reject-with tcp-reset iptables -A INPUT -p udp -j REJECT --reject-with icmp-port-unreachable /usr/sbin/service iptables save So here's what is happening above: When we start, we flush all of the rules We then set the default policy for our INPUT chain to DROP, which says, \"Hey, if we haven't explicitly allowed you here, then we are dropping you!\" Then we allow SSH (port 22) from our trusted network, the devices behind the hardware firewall We allow DNS from some public DNS resolvers. (these can also be local DNS servers, if you have them) We allow our web traffic in from anywhere over port 80 and 443. We allow standard FTP (ports 20-21) and the passive ports needed to exchange two-way communications in FTP (7000-7500). These ports can be arbitrarily changed to other ports based on your ftp server configuration. We allow any traffic on the local interface (127.0.0.1) Then we say, that any traffic that has successfully connected based on the rules, should be allowed other traffic (ports) to maintain their connection (ESTABLISHED,RELATED). And finally, we reject all other traffic and set the script to save the rules where iptables expects to find them. Once this script is there, we need to make it executable: chmod +x /etc/firewall.conf We need to enable iptables if we haven't already: systemctl enable iptables We need to start iptables : systemctl start iptables We need to run /etc/firewall.conf: /etc/firewall.conf If we add new rules to the /etc/firewall.conf, just run it again to take those rules live. Keep in mind that with a default DROP policy for the INPUT chain, if you make a mistake, you could lock yourself out remotely. You can always fix this however, from the console on the server. Because the iptables service is enabled, a reboot will restore all rules that have been added with /etc/firewall.conf .","title":"Configuring iptables"},{"location":"guides/apache_hardened_webserver/#conclusions","text":"There are a number of ways to harden an Apache web server to make it more secure. Each operates independently of the other options, so you can choose to install any or all of them based on your needs. Each requires some configuration with various tuning required for some to meet your specific needs. Since web services are constantly attacked by unscrupulous actors, implementing at least some of these will help an administrator sleep at night.","title":"Conclusions"},{"location":"guides/apache_hardened_webserver/modsecurity/","text":"mod_security \u00b6 Prerequisites \u00b6 A Rocky Linux Web Server running Apache Proficiency with a command-line editor (we are using vi in this example) A heavy comfort level with issuing commands from the command-line, viewing logs, and other general systems administrator duties An understanding that installing this tool also requires monitoring of actions and tuning to your environment An account on Comodo's WAF site All commands are run as the root user or sudo Introduction \u00b6 mod_security is an open-source web-based application firewall (WAF). It is just one possible component of a hardened Apache web server setup and can be used with or without other tools. If you'd like to use this along with other tools for hardening, refer back to the Apache Hardened Web Server guide . This document also uses all of the assumptions and conventions outlined in that original document, so it is a good idea to review it before continuing. One thing that is missing with mod_security when installed from the generic Rocky Linux repositories, is that the rules installed are minimal at best. To get a more extensive package of free mod_security rules, we are using Comodo's WAF installation procedure after installing the base package. Note that Comodo is a business that sells lots of tools to help secure networks. The free mod_security tools may not be free forever and they do require that you setup a login with Comodo in order to gain access to the rules. Installing mod_security \u00b6 To install the base package, use this command which will install any missing dependencies. We also need wget so if you haven't installed it, do that as well: dnf install mod_security wget Setting Up Your Comodo account \u00b6 To setup your free account, go to Comodo's WAF site , and click the \"Signup\" link at the top of the page. You will be required to setup username and password information but no credit-card or other billing will be done. The credentials that you use for signing on to the web site will be used in your setup of Comodo's software and also to obtain the rules, so you will need to keep these safe in a password manager somewhere. Please note that the \"Terms and Conditions\" section of the form that you need to fill out to use Comodo Web Application Firewall (CWAF) is written to cover all of their products and services. That said, you should read this carefully before agreeing to the terms! Installing CWAF \u00b6 Before you start, in order for the script to actually run after we download it, you are going to need some development tools. Install the package with: dnf group install 'Development Tools' In addition, you will need to have your web server running for Comodo to see mod_security correctly. So start it if it is not already running: systemctl start httpd After signing up with Comodo, you will get an email with instructions on what to do next. Essentially, what you need to do is to login to the web site with your new credentials and then download the client install script. From the root directory of your server, use the wget command to download the installer: wget https://waf.comodo.com/cpanel/cwaf_client_install.sh Run the installer by typing: bash cwaf_client_install.sh This will extract the installer and start the process, echoing to the screen. You'll get a message part way down: No web host management panel found, continue in 'standalone' mode? [y/n]: Type \"y\" and let the script continue. You may also get this notice: Some required perl modules are missed. Install them? This can take a while. [y/n]: If so type \"y\" and allow those missing modules to install. Enter CWAF login: username@domain.com Enter password for 'username@domain.com' (will not be shown): ************************* Confirm password for 'username@domain.com' (will not be shown): ************************ Please note here that you will probably have to download the rules and install them in the correct location, as the password field requires a punctuation or special character, but the configuration file apparently has issues with this when sending it to Comodo's site from the installer or update script. These scripts will always fail with a credentials error. This probably doesn't affect administrators who have web servers running with a GUI front end (Cpanel / Plesk) but if you are running the program standalone as we are in our example, it does. You can find the workaround below . Enter absolute CWAF installation path prefix (/cwaf will be appended): /usr/local Install into '/usr/local/cwaf' ? [y/n]: Just accept the path as given and then type \"y\" in the next field for the install path. If you have a non-standard path to the configuration file for Apache/nginx, you would enter it here, otherwise just hit 'Enter' for no changes: If you have non-standard Apache/nginx config path enter it here: Here is where the failure comes in, and the only workaround is to manually download and install the rules. Answer the prompts as shown below: Do you want to use HTTP GUI to manage CWAF rules? [y/n]: n Do you want to protect your server with default rule set? [y/n]: y But expect to get the next message as well: Warning! Rules have not been updated. Check your credentials and try again later manually +------------------------------------------------------ | LOG : Warning! Rules have not been updated. Check your credentials and try again later manually +------------------------------------------------------ | Installation complete! | Please add the line: | Include \"/usr/local/cwaf/etc/modsec2_standalone.conf\" | to Apache config file. | To update ModSecurity ruleset run | /usr/local/cwaf/scripts/updater.pl | Restart Apache after that. | You may find useful utility /usr/local/cwaf/scripts/cwaf-cli.pl | Also you may examine file | /usr/local/cwaf/INFO.TXT | for some useful software information. +------------------------------------------------------ | LOG : All Done! | LOG : Exiting That's a little frustrating. You can go to your account on the Comodo web site and change your password and re-run the install script, BUT, it won't change anything. The credentials will still fail. CWAF Rules File Workaround \u00b6 To fix this, we need to manually install the rules from the web site. This is done by logging into your account on https://waf.comodo.com and clicking on the the \"Download Full Rule Set\" link. You'll then need to copy the rules to your web server using scp' Example: scp cwaf_rules-1.233.tgz root@mywebserversdomainname.com:/root/ Once the tar gzip file has been copied over, move the file to the rules directory: mv /root/cwaf_rules-1.233.tgz /usr/local/cwaf/rules/ Then navigate to the rules directory: cd /usr/local/cwaf/rules/ And uncompress the rules: tar xzvf cwaf_rules-1.233.tgz Any partial updates to the rules will have to be handled in the same way. This is where paying for rules and support can come in handy. It all depends on your budget. Configuring CWAF \u00b6 When we installed mod_security , the default configuration file was installed in /etc/httpd/conf.d/mod_security.conf . The next thing we need to do is to modify this in two places. Start by editing the file: vi /etc/httpd/conf.d/mod_security.conf At the very top of the file, you will see: <IfModule mod_security2.c> # Default recommended configuration SecRuleEngine On Beneath the SecRuleEngine On line add SecStatusEngine On so that the top of the file will now look like this: <IfModule mod_security2.c> # Default recommended configuration SecRuleEngine On SecStatusEngine On Next go to the bottom of this configuration file. We need to tell mod_security where to load the rules. You should see this at the bottom of the file before you make changes: # ModSecurity Core Rules Set and Local configuration IncludeOptional modsecurity.d/*.conf IncludeOptional modsecurity.d/activated_rules/*.conf IncludeOptional modsecurity.d/local_rules/*.conf </IfModule> We need to add in one line at the bottom to add the CWAF configuration, which in turn loads the CWAF rules. That line is Include \"/usr/local/cwaf/etc/cwaf.conf\" . The bottom of this file should look like this when you are done: # ModSecurity Core Rules Set and Local configuration IncludeOptional modsecurity.d/*.conf IncludeOptional modsecurity.d/activated_rules/*.conf IncludeOptional modsecurity.d/local_rules/*.conf Include \"/usr/local/cwaf/etc/cwaf.conf\" </IfModule> Now save your changes (with vi it's SHIFT+:+wq! ) and restart httpd: systemctl restart httpd If httpd starts OK, then you are ready to start using mod_security with the CWAF. Conclusions \u00b6 mod_security with CWAF is another tool that can be used to help harden an Apache web server. Because CWAF's passwords require punctuation and because the standalone installation does not send that punctuation correctly, managing CWAF rules requires logging into the CWAF site and downloading rules and changes. mod_security , like other hardening tools, has the potential of false-positive responses, so you must be prepared to tune this tool to your installation. Like other solutions mentioned in the Apache Hardened Web Server guide , there are other free and fee-based solutions for mod_security rules, and for that matter, other WAF applications available. You can take a look at one of these at Atomicorp's mod_security site .","title":"mod_security"},{"location":"guides/apache_hardened_webserver/modsecurity/#mod_security","text":"","title":"mod_security"},{"location":"guides/apache_hardened_webserver/modsecurity/#prerequisites","text":"A Rocky Linux Web Server running Apache Proficiency with a command-line editor (we are using vi in this example) A heavy comfort level with issuing commands from the command-line, viewing logs, and other general systems administrator duties An understanding that installing this tool also requires monitoring of actions and tuning to your environment An account on Comodo's WAF site All commands are run as the root user or sudo","title":"Prerequisites"},{"location":"guides/apache_hardened_webserver/modsecurity/#introduction","text":"mod_security is an open-source web-based application firewall (WAF). It is just one possible component of a hardened Apache web server setup and can be used with or without other tools. If you'd like to use this along with other tools for hardening, refer back to the Apache Hardened Web Server guide . This document also uses all of the assumptions and conventions outlined in that original document, so it is a good idea to review it before continuing. One thing that is missing with mod_security when installed from the generic Rocky Linux repositories, is that the rules installed are minimal at best. To get a more extensive package of free mod_security rules, we are using Comodo's WAF installation procedure after installing the base package. Note that Comodo is a business that sells lots of tools to help secure networks. The free mod_security tools may not be free forever and they do require that you setup a login with Comodo in order to gain access to the rules.","title":"Introduction"},{"location":"guides/apache_hardened_webserver/modsecurity/#installing-mod_security","text":"To install the base package, use this command which will install any missing dependencies. We also need wget so if you haven't installed it, do that as well: dnf install mod_security wget","title":"Installing mod_security"},{"location":"guides/apache_hardened_webserver/modsecurity/#setting-up-your-comodo-account","text":"To setup your free account, go to Comodo's WAF site , and click the \"Signup\" link at the top of the page. You will be required to setup username and password information but no credit-card or other billing will be done. The credentials that you use for signing on to the web site will be used in your setup of Comodo's software and also to obtain the rules, so you will need to keep these safe in a password manager somewhere. Please note that the \"Terms and Conditions\" section of the form that you need to fill out to use Comodo Web Application Firewall (CWAF) is written to cover all of their products and services. That said, you should read this carefully before agreeing to the terms!","title":"Setting Up Your Comodo account"},{"location":"guides/apache_hardened_webserver/modsecurity/#installing-cwaf","text":"Before you start, in order for the script to actually run after we download it, you are going to need some development tools. Install the package with: dnf group install 'Development Tools' In addition, you will need to have your web server running for Comodo to see mod_security correctly. So start it if it is not already running: systemctl start httpd After signing up with Comodo, you will get an email with instructions on what to do next. Essentially, what you need to do is to login to the web site with your new credentials and then download the client install script. From the root directory of your server, use the wget command to download the installer: wget https://waf.comodo.com/cpanel/cwaf_client_install.sh Run the installer by typing: bash cwaf_client_install.sh This will extract the installer and start the process, echoing to the screen. You'll get a message part way down: No web host management panel found, continue in 'standalone' mode? [y/n]: Type \"y\" and let the script continue. You may also get this notice: Some required perl modules are missed. Install them? This can take a while. [y/n]: If so type \"y\" and allow those missing modules to install. Enter CWAF login: username@domain.com Enter password for 'username@domain.com' (will not be shown): ************************* Confirm password for 'username@domain.com' (will not be shown): ************************ Please note here that you will probably have to download the rules and install them in the correct location, as the password field requires a punctuation or special character, but the configuration file apparently has issues with this when sending it to Comodo's site from the installer or update script. These scripts will always fail with a credentials error. This probably doesn't affect administrators who have web servers running with a GUI front end (Cpanel / Plesk) but if you are running the program standalone as we are in our example, it does. You can find the workaround below . Enter absolute CWAF installation path prefix (/cwaf will be appended): /usr/local Install into '/usr/local/cwaf' ? [y/n]: Just accept the path as given and then type \"y\" in the next field for the install path. If you have a non-standard path to the configuration file for Apache/nginx, you would enter it here, otherwise just hit 'Enter' for no changes: If you have non-standard Apache/nginx config path enter it here: Here is where the failure comes in, and the only workaround is to manually download and install the rules. Answer the prompts as shown below: Do you want to use HTTP GUI to manage CWAF rules? [y/n]: n Do you want to protect your server with default rule set? [y/n]: y But expect to get the next message as well: Warning! Rules have not been updated. Check your credentials and try again later manually +------------------------------------------------------ | LOG : Warning! Rules have not been updated. Check your credentials and try again later manually +------------------------------------------------------ | Installation complete! | Please add the line: | Include \"/usr/local/cwaf/etc/modsec2_standalone.conf\" | to Apache config file. | To update ModSecurity ruleset run | /usr/local/cwaf/scripts/updater.pl | Restart Apache after that. | You may find useful utility /usr/local/cwaf/scripts/cwaf-cli.pl | Also you may examine file | /usr/local/cwaf/INFO.TXT | for some useful software information. +------------------------------------------------------ | LOG : All Done! | LOG : Exiting That's a little frustrating. You can go to your account on the Comodo web site and change your password and re-run the install script, BUT, it won't change anything. The credentials will still fail.","title":"Installing CWAF"},{"location":"guides/apache_hardened_webserver/modsecurity/#cwaf-rules-file-workaround","text":"To fix this, we need to manually install the rules from the web site. This is done by logging into your account on https://waf.comodo.com and clicking on the the \"Download Full Rule Set\" link. You'll then need to copy the rules to your web server using scp' Example: scp cwaf_rules-1.233.tgz root@mywebserversdomainname.com:/root/ Once the tar gzip file has been copied over, move the file to the rules directory: mv /root/cwaf_rules-1.233.tgz /usr/local/cwaf/rules/ Then navigate to the rules directory: cd /usr/local/cwaf/rules/ And uncompress the rules: tar xzvf cwaf_rules-1.233.tgz Any partial updates to the rules will have to be handled in the same way. This is where paying for rules and support can come in handy. It all depends on your budget.","title":" CWAF Rules File Workaround"},{"location":"guides/apache_hardened_webserver/modsecurity/#configuring-cwaf","text":"When we installed mod_security , the default configuration file was installed in /etc/httpd/conf.d/mod_security.conf . The next thing we need to do is to modify this in two places. Start by editing the file: vi /etc/httpd/conf.d/mod_security.conf At the very top of the file, you will see: <IfModule mod_security2.c> # Default recommended configuration SecRuleEngine On Beneath the SecRuleEngine On line add SecStatusEngine On so that the top of the file will now look like this: <IfModule mod_security2.c> # Default recommended configuration SecRuleEngine On SecStatusEngine On Next go to the bottom of this configuration file. We need to tell mod_security where to load the rules. You should see this at the bottom of the file before you make changes: # ModSecurity Core Rules Set and Local configuration IncludeOptional modsecurity.d/*.conf IncludeOptional modsecurity.d/activated_rules/*.conf IncludeOptional modsecurity.d/local_rules/*.conf </IfModule> We need to add in one line at the bottom to add the CWAF configuration, which in turn loads the CWAF rules. That line is Include \"/usr/local/cwaf/etc/cwaf.conf\" . The bottom of this file should look like this when you are done: # ModSecurity Core Rules Set and Local configuration IncludeOptional modsecurity.d/*.conf IncludeOptional modsecurity.d/activated_rules/*.conf IncludeOptional modsecurity.d/local_rules/*.conf Include \"/usr/local/cwaf/etc/cwaf.conf\" </IfModule> Now save your changes (with vi it's SHIFT+:+wq! ) and restart httpd: systemctl restart httpd If httpd starts OK, then you are ready to start using mod_security with the CWAF.","title":"Configuring CWAF"},{"location":"guides/apache_hardened_webserver/modsecurity/#conclusions","text":"mod_security with CWAF is another tool that can be used to help harden an Apache web server. Because CWAF's passwords require punctuation and because the standalone installation does not send that punctuation correctly, managing CWAF rules requires logging into the CWAF site and downloading rules and changes. mod_security , like other hardening tools, has the potential of false-positive responses, so you must be prepared to tune this tool to your installation. Like other solutions mentioned in the Apache Hardened Web Server guide , there are other free and fee-based solutions for mod_security rules, and for that matter, other WAF applications available. You can take a look at one of these at Atomicorp's mod_security site .","title":"Conclusions"},{"location":"guides/apache_hardened_webserver/ossec-hids/","text":"ossec-hids \u00b6 Prerequisites \u00b6 Proficiency with a command-line text editor (we are using vi in this example) A heavy comfort level with issuing commands from the command-line, viewing logs, and other general systems administrator duties An understanding that installing this tool also requires monitoring of actions and tuning to your environment All commands are run as the root user or sudo Introduction \u00b6 ossec-hids is a host intrusion detection system that offers automatic action-response steps to help mitigate host intrusion attacks. It is just one possible component of a hardened Apache web server setup and can be used with or without other tools. If you'd like to use this along with other tools for hardening, refer back to the Apache Hardened Web Server routine . This document also uses all of the assumptions and conventions outlined in that original document, so it is a good idea to review it before continuing. Installing Atomicorp's Repository \u00b6 To install ossec-hids , we need a third-party repository from Atomicorp. Atomicorp also offers a reasonably priced fee-based supported version for those who would like some human help if they run into trouble. If you'd prefer support and have the budget for it, check out Atomicorp's non-free ossec-hids . Since we are going to need just a few packages from Atomicorp's free repository, we are going to modify the repository after we have it downloaded. Downloading the repository requires wget so install that first if you don't have it. Install the EPEL repository as well if you do not have it installed already, with: dnf install wget epel-release Now download and enable Atomicorp's free repository: wget -q -O - http://www.atomicorp.com/installers/atomic | sh This script will ask you to agree to the terms. Either type \"yes\" or hit 'Enter' to accept the \"yes\" as the default. Next, it will ask you if you want to enable the repository by default, and again we want to accept the default or type \"yes\". Configuring The Atomicorp Repository \u00b6 We only need the atomic repository for a couple of packages. For this reason, we are going to modify the repository and specify only those packages be chosen: vi /etc/yum.repos.d/atomic.repo And then add this line beneath the \"enabled = 1\" in the top section: includepkgs = ossec* inotify-tools That's the only change we need, so save your changes and get out of the repository. (That'd be Shift: wq! in vi.) This restricts the Atomicorp repository to only install and update these packages. Installing ossec-hids \u00b6 Now that we have the repository downloaded and configured, we need to install the packages: dnf install ossec-hids-server ossec-hids inotify-tools Configuring ossec-hids \u00b6 There are a number of changes that need to be made to the ossec-hids configuration file. Most of these have to do with server administrator notification and log locations. ossec-hids looks at the logs to try and determine if there is an attack, and whether to apply mitigation. It also sends reports to the server administrator, either just as a notification, or that a mitigation procedure has been activated based on what ossec-hids has seen. To edit the configuration file type: vi /var/ossec/etc/ossec.conf We will break apart this configuration showing the changes in line and explaining them as we go: <global> <email_notification>yes</email_notification> <email_to>admin1@youremaildomain.com</email_to> <email_to>admin2@youremaildomain.com</email_to> <smtp_server>localhost</smtp_server> <email_from>ossec-webvms@yourwebserverdomain.com.</email_from> <email_maxperhour>1</email_maxperhour> <white_list>127.0.0.1</white_list> <white_list>192.168.1.2</white_list> </global> By default, email notifications are turned off and the \"\\<global>\" configuration is basically empty. You want to turn on email notification and identify the people who should receive the email reports by email address. The \"\\<smtp_server>\" section currently shows localhost, however you can specify an email server relay if you prefer, or simply setup the postfix email settings for the local host by following this guide . Y ou need to set the \"from\" address, so that you can deal with SPAM filters on your email server which may see this email as SPAM. To avoid getting inundated with email, set the email reporting to 1 per hour. You can expand this or remark out this command if you like while you are getting started with ossec-hids and need to see things quickly. The \"\\<white_list>\" sections deal with the server's localohost IP and with the \"public\" address (remember, we are using a private address to demonstrate this) of the firewall, from which all connections on the trusted network will show. You can add multiple \"\\<white_list>\" entries as needed. <syscheck> <!-- Frequency that syscheck is executed -- default every 22 hours --> <frequency>86400</frequency> ... </syscheck> The \"\\<syscheck>\" section takes a look at a list of directories to include and exclude when looking for compromised files. Think of this as yet another tool for watching and protecting the file system against vulnerabilities. You should review the list of directories and see if there are others that you want to add in to the \"\\<syscheck>\" section. The \"\\<rootcheck>\" section just beneath the \"\\<syscheck>\" section is yet another protection layer. The locations that both \"\\<syscheck>\" and \"\\<rootcheck>\" watch are editable, but you probably will not need to make any changes to them. Changing the \"\\<frequency>\" for the \"\\<syscheck>\" run to once every 24 hours (86400 seconds) from the default of 22 hours is an optional change shown above. <localfile> <log_format>apache</log_format> <location>/var/log/httpd/*access_log</location> </localfile> <localfile> <log_format>apache</log_format> <location>/var/log/httpd/*error_log</location> </localfile> The \"\\<localfile>\" section deals with the locations of the logs we want to watch. There are entries already in place for syslog and secure logs that you just need to verify the path to, but everything else can be left as is. We do need to add in the Apache log locations however, and we want to add these in as wild_cards, because we could have a bunch of logs for a lot of different web customers. That format is shown above. <command> <name>firewall-drop</name> <executable>firewall-drop.sh</executable> <expect>srcip</expect> </command> <active-response> <command>firewall-drop</command> <location>local</location> <level>7</level> <timeout>1200</timeout> </active-response> Finally, towards the end of the file we need to add the active response section. This section contains two parts, a \"\\<command>\" section, and the \"\\<active-response>\" section. The \"firewall-drop\" script already exists within the ossec path. It tells ossec_hids that if a level of 7 is reached, add a firewall rule to block the IP address for 20 minutes. Obviously, you can change the timeout value. Just remember that the configuration file times are all in seconds. Once you have made all of the configuration changes you need, simply enable and start the service. If everything starts correctly, you should be ready to move on: systemctl enable ossec-hids And then: systemctl start ossec-hids There are a lot of options for the ossec-hids configuration file. You can find out about these options by visiting the official documentation site . Conclusions \u00b6 ossec-hids is just one element of an Apache hardened web server. It can be used with other tools to gain better security for your web site. While the installation and configuration are relatively straight forward, you will find that this is not an 'install it and forget it' application. You will need to tune it to your environment to gain the most security with the least amount of false-positive responses.","title":"ossec-hids"},{"location":"guides/apache_hardened_webserver/ossec-hids/#ossec-hids","text":"","title":"ossec-hids"},{"location":"guides/apache_hardened_webserver/ossec-hids/#prerequisites","text":"Proficiency with a command-line text editor (we are using vi in this example) A heavy comfort level with issuing commands from the command-line, viewing logs, and other general systems administrator duties An understanding that installing this tool also requires monitoring of actions and tuning to your environment All commands are run as the root user or sudo","title":"Prerequisites"},{"location":"guides/apache_hardened_webserver/ossec-hids/#introduction","text":"ossec-hids is a host intrusion detection system that offers automatic action-response steps to help mitigate host intrusion attacks. It is just one possible component of a hardened Apache web server setup and can be used with or without other tools. If you'd like to use this along with other tools for hardening, refer back to the Apache Hardened Web Server routine . This document also uses all of the assumptions and conventions outlined in that original document, so it is a good idea to review it before continuing.","title":"Introduction"},{"location":"guides/apache_hardened_webserver/ossec-hids/#installing-atomicorps-repository","text":"To install ossec-hids , we need a third-party repository from Atomicorp. Atomicorp also offers a reasonably priced fee-based supported version for those who would like some human help if they run into trouble. If you'd prefer support and have the budget for it, check out Atomicorp's non-free ossec-hids . Since we are going to need just a few packages from Atomicorp's free repository, we are going to modify the repository after we have it downloaded. Downloading the repository requires wget so install that first if you don't have it. Install the EPEL repository as well if you do not have it installed already, with: dnf install wget epel-release Now download and enable Atomicorp's free repository: wget -q -O - http://www.atomicorp.com/installers/atomic | sh This script will ask you to agree to the terms. Either type \"yes\" or hit 'Enter' to accept the \"yes\" as the default. Next, it will ask you if you want to enable the repository by default, and again we want to accept the default or type \"yes\".","title":"Installing Atomicorp's Repository"},{"location":"guides/apache_hardened_webserver/ossec-hids/#configuring-the-atomicorp-repository","text":"We only need the atomic repository for a couple of packages. For this reason, we are going to modify the repository and specify only those packages be chosen: vi /etc/yum.repos.d/atomic.repo And then add this line beneath the \"enabled = 1\" in the top section: includepkgs = ossec* inotify-tools That's the only change we need, so save your changes and get out of the repository. (That'd be Shift: wq! in vi.) This restricts the Atomicorp repository to only install and update these packages.","title":"Configuring The Atomicorp Repository"},{"location":"guides/apache_hardened_webserver/ossec-hids/#installing-ossec-hids","text":"Now that we have the repository downloaded and configured, we need to install the packages: dnf install ossec-hids-server ossec-hids inotify-tools","title":"Installing ossec-hids"},{"location":"guides/apache_hardened_webserver/ossec-hids/#configuring-ossec-hids","text":"There are a number of changes that need to be made to the ossec-hids configuration file. Most of these have to do with server administrator notification and log locations. ossec-hids looks at the logs to try and determine if there is an attack, and whether to apply mitigation. It also sends reports to the server administrator, either just as a notification, or that a mitigation procedure has been activated based on what ossec-hids has seen. To edit the configuration file type: vi /var/ossec/etc/ossec.conf We will break apart this configuration showing the changes in line and explaining them as we go: <global> <email_notification>yes</email_notification> <email_to>admin1@youremaildomain.com</email_to> <email_to>admin2@youremaildomain.com</email_to> <smtp_server>localhost</smtp_server> <email_from>ossec-webvms@yourwebserverdomain.com.</email_from> <email_maxperhour>1</email_maxperhour> <white_list>127.0.0.1</white_list> <white_list>192.168.1.2</white_list> </global> By default, email notifications are turned off and the \"\\<global>\" configuration is basically empty. You want to turn on email notification and identify the people who should receive the email reports by email address. The \"\\<smtp_server>\" section currently shows localhost, however you can specify an email server relay if you prefer, or simply setup the postfix email settings for the local host by following this guide . Y ou need to set the \"from\" address, so that you can deal with SPAM filters on your email server which may see this email as SPAM. To avoid getting inundated with email, set the email reporting to 1 per hour. You can expand this or remark out this command if you like while you are getting started with ossec-hids and need to see things quickly. The \"\\<white_list>\" sections deal with the server's localohost IP and with the \"public\" address (remember, we are using a private address to demonstrate this) of the firewall, from which all connections on the trusted network will show. You can add multiple \"\\<white_list>\" entries as needed. <syscheck> <!-- Frequency that syscheck is executed -- default every 22 hours --> <frequency>86400</frequency> ... </syscheck> The \"\\<syscheck>\" section takes a look at a list of directories to include and exclude when looking for compromised files. Think of this as yet another tool for watching and protecting the file system against vulnerabilities. You should review the list of directories and see if there are others that you want to add in to the \"\\<syscheck>\" section. The \"\\<rootcheck>\" section just beneath the \"\\<syscheck>\" section is yet another protection layer. The locations that both \"\\<syscheck>\" and \"\\<rootcheck>\" watch are editable, but you probably will not need to make any changes to them. Changing the \"\\<frequency>\" for the \"\\<syscheck>\" run to once every 24 hours (86400 seconds) from the default of 22 hours is an optional change shown above. <localfile> <log_format>apache</log_format> <location>/var/log/httpd/*access_log</location> </localfile> <localfile> <log_format>apache</log_format> <location>/var/log/httpd/*error_log</location> </localfile> The \"\\<localfile>\" section deals with the locations of the logs we want to watch. There are entries already in place for syslog and secure logs that you just need to verify the path to, but everything else can be left as is. We do need to add in the Apache log locations however, and we want to add these in as wild_cards, because we could have a bunch of logs for a lot of different web customers. That format is shown above. <command> <name>firewall-drop</name> <executable>firewall-drop.sh</executable> <expect>srcip</expect> </command> <active-response> <command>firewall-drop</command> <location>local</location> <level>7</level> <timeout>1200</timeout> </active-response> Finally, towards the end of the file we need to add the active response section. This section contains two parts, a \"\\<command>\" section, and the \"\\<active-response>\" section. The \"firewall-drop\" script already exists within the ossec path. It tells ossec_hids that if a level of 7 is reached, add a firewall rule to block the IP address for 20 minutes. Obviously, you can change the timeout value. Just remember that the configuration file times are all in seconds. Once you have made all of the configuration changes you need, simply enable and start the service. If everything starts correctly, you should be ready to move on: systemctl enable ossec-hids And then: systemctl start ossec-hids There are a lot of options for the ossec-hids configuration file. You can find out about these options by visiting the official documentation site .","title":"Configuring ossec-hids"},{"location":"guides/apache_hardened_webserver/ossec-hids/#conclusions","text":"ossec-hids is just one element of an Apache hardened web server. It can be used with other tools to gain better security for your web site. While the installation and configuration are relatively straight forward, you will find that this is not an 'install it and forget it' application. You will need to tune it to your environment to gain the most security with the least amount of false-positive responses.","title":"Conclusions"},{"location":"guides/apache_hardened_webserver/rkhunter/","text":"rkhunter \u00b6 Prerequisites \u00b6 A Rocky Linux Web Server running Apache Proficiency with a command-line editor (we are using vi in this example) A heavy comfort level with issuing commands from the command-line, viewing logs, and other general systems administrator duties An understanding of what can trigger a response to changed files on the file system (such as package updates) is helpful All commands are run as the root user or sudo Introduction \u00b6 rkhunter (Root Kit Hunter) is a Unix-based tool that scans for rootkits, backdoors, and possible local exploits. It is a good part of a hardened web server, and is designed to notify the administrator quickly when something suspicious happens on the server's file system. rkhunter is just one possible component of a hardened Apache web server setup and can be used with or without other tools. If you'd like to use this along with other tools for hardening, refer back to the Apache Hardened Web Server guide . This document also uses all of the assumptions and conventions outlined in that original document, so it is a good idea to review it before continuing. Installing rkhunter \u00b6 rkhunter requires the EPEL (Extra Packages for Enterprise Linux) repository. So install that repository if you don't have it installed already: dnf install epel-release Then install rkhunter : dnf install rkhunter Configuring rkhunter \u00b6 The only configuration options that need to be set are those dealing with mailing reports to the administrator. To modify the configuration file, run: vi /etc/rkhunter.conf And then search for: #MAIL-ON-WARNING=me@mydomain root@mydomain Remove the remark here and change the me@mydomain.com to reflect your email address. Then change the root@mydomain to root@whatever_the_server_name_is. You may also need to setup Postfix Email for Reporting in order to get the email section to work correctly. Running rkhunter \u00b6 rkhunter can be run by typing it at the command-line. There is a cron job installed for you in /etc/cron.daily , but if you want to automate the procedure on a different schedule, look at the Automating cron jobs guide . You'll also need to move the script somewhere other than /etc/cron.daily , such as /usr/local/sbin and then call it from your custom cron job. The easiest method, of course, is to leave the default cron.daily setup intact. Before you run allow rkhunter to run automatically, run the command manually with the \"--propupd\" flag to create the rkhunter.dat file, and to make sure that your new environment is recognized without issue: rkhunter --propupd To run rkhunter manually: rkhunter --check This will echo back to the screen as the checks are performed, prompting you to [Press <ENTER> to continue] after each section. Conclusions \u00b6 rkhunter is one part of a hardened server strategy that can help in monitoring the file system and reporting any issues to the administrator. It is perhaps one of the easiest hardening tools to install, configure, and run.","title":"rkhunter"},{"location":"guides/apache_hardened_webserver/rkhunter/#rkhunter","text":"","title":"rkhunter"},{"location":"guides/apache_hardened_webserver/rkhunter/#prerequisites","text":"A Rocky Linux Web Server running Apache Proficiency with a command-line editor (we are using vi in this example) A heavy comfort level with issuing commands from the command-line, viewing logs, and other general systems administrator duties An understanding of what can trigger a response to changed files on the file system (such as package updates) is helpful All commands are run as the root user or sudo","title":"Prerequisites"},{"location":"guides/apache_hardened_webserver/rkhunter/#introduction","text":"rkhunter (Root Kit Hunter) is a Unix-based tool that scans for rootkits, backdoors, and possible local exploits. It is a good part of a hardened web server, and is designed to notify the administrator quickly when something suspicious happens on the server's file system. rkhunter is just one possible component of a hardened Apache web server setup and can be used with or without other tools. If you'd like to use this along with other tools for hardening, refer back to the Apache Hardened Web Server guide . This document also uses all of the assumptions and conventions outlined in that original document, so it is a good idea to review it before continuing.","title":"Introduction"},{"location":"guides/apache_hardened_webserver/rkhunter/#installing-rkhunter","text":"rkhunter requires the EPEL (Extra Packages for Enterprise Linux) repository. So install that repository if you don't have it installed already: dnf install epel-release Then install rkhunter : dnf install rkhunter","title":"Installing rkhunter"},{"location":"guides/apache_hardened_webserver/rkhunter/#configuring-rkhunter","text":"The only configuration options that need to be set are those dealing with mailing reports to the administrator. To modify the configuration file, run: vi /etc/rkhunter.conf And then search for: #MAIL-ON-WARNING=me@mydomain root@mydomain Remove the remark here and change the me@mydomain.com to reflect your email address. Then change the root@mydomain to root@whatever_the_server_name_is. You may also need to setup Postfix Email for Reporting in order to get the email section to work correctly.","title":"Configuring rkhunter"},{"location":"guides/apache_hardened_webserver/rkhunter/#running-rkhunter","text":"rkhunter can be run by typing it at the command-line. There is a cron job installed for you in /etc/cron.daily , but if you want to automate the procedure on a different schedule, look at the Automating cron jobs guide . You'll also need to move the script somewhere other than /etc/cron.daily , such as /usr/local/sbin and then call it from your custom cron job. The easiest method, of course, is to leave the default cron.daily setup intact. Before you run allow rkhunter to run automatically, run the command manually with the \"--propupd\" flag to create the rkhunter.dat file, and to make sure that your new environment is recognized without issue: rkhunter --propupd To run rkhunter manually: rkhunter --check This will echo back to the screen as the checks are performed, prompting you to [Press <ENTER> to continue] after each section.","title":"Running rkhunter"},{"location":"guides/apache_hardened_webserver/rkhunter/#conclusions","text":"rkhunter is one part of a hardened server strategy that can help in monitoring the file system and reporting any issues to the administrator. It is perhaps one of the easiest hardening tools to install, configure, and run.","title":"Conclusions"},{"location":"labs/security/","text":"Table of Contents \u00b6 Introduction Lab 1: Installing Rocky Linux Installing the Operating System Lab 2: Patching the System Updating and Patching Configuring and using dnf Third party solutions Lab 3: Auditing the System A simple home grown integrity checker Tripwire Integrity checking and viewing reports Fine tuning tripwire Lab 4: Gathering information netstat lsof nmap rpcinfo tcpdump telnet Lab 5: Local Security Cracking the system through the boot loader Password protecting the boot loader Disabling un-necessary tty\u2019s Disabling reboot via CTRL+ALT+DEL Enforcing password prompting in single user-mode Set-UID programs John the ripper Lab 6: A staged Hack The PATH Lab 7: TCP wrappers Tcp_wrappers Lab 8: Iptables Iptables essentials Basic Packet Filtering Basic Packet Forwarding Lab 9: Cryptography GnuPG Key Administration Revocation certificates Digital signatures Encrypting and decrypting files sshd ssh scp Authenticating via Public-Key ssh-agent Lab 10: Kernel Level Security Installing GRsecurity gradm ACLs GRsecurity Learning mode SElinux","title":"Table of Contents"},{"location":"labs/security/#table-of-contents","text":"Introduction Lab 1: Installing Rocky Linux Installing the Operating System Lab 2: Patching the System Updating and Patching Configuring and using dnf Third party solutions Lab 3: Auditing the System A simple home grown integrity checker Tripwire Integrity checking and viewing reports Fine tuning tripwire Lab 4: Gathering information netstat lsof nmap rpcinfo tcpdump telnet Lab 5: Local Security Cracking the system through the boot loader Password protecting the boot loader Disabling un-necessary tty\u2019s Disabling reboot via CTRL+ALT+DEL Enforcing password prompting in single user-mode Set-UID programs John the ripper Lab 6: A staged Hack The PATH Lab 7: TCP wrappers Tcp_wrappers Lab 8: Iptables Iptables essentials Basic Packet Filtering Basic Packet Forwarding Lab 9: Cryptography GnuPG Key Administration Revocation certificates Digital signatures Encrypting and decrypting files sshd ssh scp Authenticating via Public-Key ssh-agent Lab 10: Kernel Level Security Installing GRsecurity gradm ACLs GRsecurity Learning mode SElinux","title":"Table of Contents"},{"location":"labs/security/introduction/","text":"Introduction \u00b6 The Labs are designed around a fictitious company (called Example Inc.). Example Inc. has offices all over the world. Example Inc. makes widgets. The company has all the usual bells and whistles that a modern company requires to conduct its business. They have networked branch offices, with computers that perform different roles. Some of the computers are workstations, some are firewalls, and some are servers (file servers, web servers, mail servers, database servers, application servers, dialup servers, etc. And most importantly to us in this manual \u2013 the company has administrators to administer/manage the computers. You, The Reader, will be the administrator at one of the branch offices. You will be working with a partner (who is also an administrator) to make sure that the company\u2019s systems are up and running all the time. Example Inc. deploys Rocky Linux on its systems, because the company has great taste. Most tasks that can be accomplished from the command line (the shell) of the Linux OS can be easily accomplished from the graphical user interface (GUI) of the operating system. But most of your work will be done from the command line in this manual. The idea is to get you very comfortable with the command line \u2013 after which there will be no task you cannot perform from the command line. The command line is a very fast way to get things done and it is also one of the features of Linux (besides the Kernel) that you will find remains consistent in its look, feel, and functionality amongst the various flavors of Linux.","title":"Introduction"},{"location":"labs/security/introduction/#introduction","text":"The Labs are designed around a fictitious company (called Example Inc.). Example Inc. has offices all over the world. Example Inc. makes widgets. The company has all the usual bells and whistles that a modern company requires to conduct its business. They have networked branch offices, with computers that perform different roles. Some of the computers are workstations, some are firewalls, and some are servers (file servers, web servers, mail servers, database servers, application servers, dialup servers, etc. And most importantly to us in this manual \u2013 the company has administrators to administer/manage the computers. You, The Reader, will be the administrator at one of the branch offices. You will be working with a partner (who is also an administrator) to make sure that the company\u2019s systems are up and running all the time. Example Inc. deploys Rocky Linux on its systems, because the company has great taste. Most tasks that can be accomplished from the command line (the shell) of the Linux OS can be easily accomplished from the graphical user interface (GUI) of the operating system. But most of your work will be done from the command line in this manual. The idea is to get you very comfortable with the command line \u2013 after which there will be no task you cannot perform from the command line. The command line is a very fast way to get things done and it is also one of the features of Linux (besides the Kernel) that you will find remains consistent in its look, feel, and functionality amongst the various flavors of Linux.","title":"Introduction"},{"location":"labs/security/rocky-lab9-cryptography/","text":"Lab 9: Cryptography \u00b6 Objectives After completing this lab, you will be able to apply cryptographic concepts in securing data and communication Estimated time to complete this lab: 120 minutes Table of Contents Common cryptography terms and definitions Exercise 1 Gnupg Exercise 2 Key Administration Exercise 3 Digital Signatures Common Cryptography terms and definitions \u00b6 Cryptography In general everyday usage, Cryptography is the act or art of writing in secret characters. In technical jargon it may be defined as the science of using mathematics to encrypt and decrypt data. Cryptanalysis Cryptanalysis is the study of how to compromise (defeat) cryptographic mechanisms. It is the science of cracking code, decoding secrets, violating authentication schemes, and in general, breaking cryptographic protocols. Cryptology Cryptology is the discipline of cryptography and cryptanalysis combined. Cryptology is the branch of mathematics that studies the mathematical foundations of cryptographic methods. Encryption Encryption is the transformation of data into a form that is as close to impossible as possible to read without the appropriate knowledge (e.g. a key). Its purpose is to ensure privacy by keeping information hidden from anyone for whom it is not intended. Decryption Decryption is the reverse of encryption; it is the transformation of encrypted data back into an intelligible form. Cipher A method of encryption and decryption is called a cipher. Hash Functions (Digest algorithms) Cryptographic hash functions are used in various contexts, for example to compute the message digest when making a digital signature. A hash function compresses the bits of a message to a fixed-size hash value in a way that distributes the possible messages evenly among the possible hash values. A cryptographic hash function does this in a way that makes it extremely difficult to come up with a message that would hash to a particular hash value. Some examples of the best known and most widely used hash functions are described below. a) - SHA-1 (Secure Hash Algorithm) -This is a cryptographic hash algorithm published by the United States Government. It produces a 160 bit hash value from an arbitrary length string. It is considered to be very good. b) - MD5 (Message Digest Algorithm 5) - is a cryptographic hash algorithm developed at RSA Laboratories. It can be used to hash an arbitrary length byte string into a 128 bit value. Algorithm It describes a step-by-step problem-solving procedure, especially an established, recursive computational procedure for solving a problem in a finite number of steps. Technically, an algorithm must reach a result after a finite number of steps. The efficiency of an algorithm can be measured as the number of elementary steps it takes to solve the problem. There are two classes of key-based algorithms. They are: a) -- Symmetric Encryption Algorithms ( secret-key) Symmetric algorithms use the same key for encryption and decryption (or the decryption key is easily derived from the encryption key). Secret key algorithms use the same key for both encryption and decryption (or one is easily derivable from the other). This is the more straightforward approach to data encryption, it is mathematically less complicated than public-key cryptography. Symmetric algorithms can be divided into stream ciphers and block ciphers. Stream ciphers can encrypt a single bit of plaintext at a time, whereas block ciphers take a number of bits (typically 64 bits in modern ciphers), and encrypt them as a single unit. Symmetric algorithms are much faster to execute on a computer than asymmetric ones. Examples of symmetric algorithms are: AES, 3DES, Blowfish, CAST5, IDEA and Twofish. b) -- Asymmetric algorithms (Public-key algorithms) Asymmetric algorithms on the other hand use a different key for encryption and decryption, and the decryption key cannot be derived from the encryption key. Asymmetric ciphers permit the encryption key to be public, allowing anyone to encrypt with the key, whereas only the proper recipient (who knows the decryption key) can decrypt the message. The encryption key is also called the public key and the decryption key the private key or secret key. RSA is probably the best known asymmetric encryption algorithm. Digital Signature A digital signature binds a document to the owner of a particular key. Digital signatures are used to verify that a message really comes from the claimed sender. The digital signature of a document is a piece of information based on both the document and the signer's private key. It is typically created through the use of a hash function and a private signing function (encrypting with the signer's private key). A digital signature is a small amount of data that was created using some secret key, and there is a public key that can be used to verify that the signature was really generated using the corresponding private key. Several methods for making and verifying digital signatures are freely available but the most widely known algorithm is the RSA public-key algorithm. Cryptographic Protocols Cryptography works on many levels. On one level you have algorithms, such as block ciphers and public key cryptosystems. Building upon these you obtain protocols, and building upon protocols you find applications (or other protocols). Below is a list of common everyday applications that make use of cryptographic protocols. These protocols are built on lower level cryptographic algorithms. i.) Domain Name Server Security (DNSSEC) This is a protocol for secure distributed name services. It is currently available as an Internet Draft. ii.) Secure Socket Layer (SSL) SSL is one of the two protocols used for secure WWW connections (the other is SHTTP). WWW security has become important as, increasing amounts of sensitive information, such as credit card numbers, are being transmitted over the Internet. iii.) Secure Hypertext Transfer Protocol (SHTTP) This is another protocol for providing more security for WWW transactions. iv) E-Mail security and related services GnuPG - The GNU Privacy Guard - is compliant with the proposed OpenPGP Internet standard as described in RFC2440. v) SSH2 Protocol This protocol is versatile for the needs of the internet, and is currently used in the SSH2 software. The protocol is used to secure terminal sessions and TCP connections. The following exercises examine two particular applications that make use of cryptographic protocols - GnuPG and OpenSSH. Exercise 1 \u00b6 GnuPG \u00b6 GnuPG (GNU Privacy Guard) is a set of programs for public key encryption and digital signatures. The tools can be used to encrypt data and to create digital signatures. It also includes an advanced key management facility. GnuPG uses public-key cryptography to enable users to communicate securely Perform the following exercises as a regular user. e.g. user ying To create a new keypair Log into the system as user \u201c ying \u201d Make sure that the GnuPG package is installed on your system. Type: [ying@serverXY ying]$ ***rpm -q gnupg*** gnupg-*.* If it isn\u2019t, get the super-user to install it. List and make a note of all the hidden directories in your home directory. List the keys you currently have in your key-ring. Type: [ying@serverXY ying]$ ***gpg --list-keys*** NOTE :- You shouldn\u2019t have any keys in your key-ring yet. But the above command will also help create a default environment to enable you create a new key-pair successfully the first time. List the hidden directories in your home directory again. What is the name of the new directory added? Use the gpg program to create your new key-pairs. Type: [ying@serverXY ying\\]$ ***gpg --gen-key*** ...................................... gpg: keyring \\`/home/ying/.gnupg/secring.gpg' created gpg: keyring \\`/home/ying/.gnupg/pubring.gpg' created Please select what kind of key you want: (1) DSA and ElGamal (default) (2) DSA (sign only) (5) RSA (sign only) Your selection? 1 At the prompt for the type of key your want to create accept the default i.e.(DSA and ElGamal). Type 1 NOTES : Option (1) will create two key-pairs for you. The DSA key-pair will be the primary keypair - for making digital signatures and a subordinate ELGamel keypair for data encryption. You will create an ELG-E keysize of 1024. Accept the default again at the prompt below: DSA keypair will have 1024 bits. About to generate a new ELG-E keypair. minimum keysize is 768 bits default keysize is 1024 bits highest suggested keysize is 2048 bits What keysize do you want? (1024) 1024 Create keys that will expire in a year. Type \u201c1y\u201d at the prompt below: Please specify how long the key should be valid. 0 = key does not expire <n> = key expires in n days <n>w = key expires in n weeks <n>m = key expires in n months <n>y = key expires in n years Key is valid for? (0) 1y Type \u201cy\u201d to accept the expiry date shown at the prompt: Is this correct (y/n)? y Create a User-ID to identify your key with: You need a User-ID to identify your key; the software constructs the user id from Real Name, Comment and Email Address in this form: \"Firstname Lastname (any comment) <yourname@serverXY>\" Real name: Ying Yang[ENTER] Comment : my test[ENTER] Email address: ying@serverXY [ENTER] At the confirmation prompt type \u201co\u201d (Okay) to accept the correct values. You selected this USER-ID: \"Ying Yang (my test) <ying@serverXY>\" Change (N)ame, (C)omment, (E)mail or (O)kay/(Q)uit? O Select a passphrase that you WILL NOT forget at the next prompt: Enter passphrase: ******** Repeat passphrase: ******** Exercise 2 \u00b6 Key Administration \u00b6 The gpg program is also used in key administration. Listing your keys While still logged into the system as the user ying. Display the keys in your key-ring. Type: [ying@serverXY ying]$ gpg --list-keys gpg: WARNING: using insecure memory! /home/ying/.gnupg/pubring.gpg pub 1024D/1D12E484 2003-10-16 Ying Yang (my test) <ying@serverXY> sub 1024g/1EDB00AC 2003-10-16 [expires: 2004-10-15] To suppress the somewhat annoying \u201cwarning\u201d about \u201cinsecure memory\u201d add the following option to your personal gpg configuration file. Type: [ying@serverXY ying]$ echo \"no-secmem-warning\" >> ~/.gnupg/gpg.conf Run the command to list your keys again. to make sure your change is in effect. List your keys along with their signatures. Type: [ying@serverXY ying]$ gpg --list-sigs /home/ying/.gnupg/pubring.gpg ........<SNIP>............. List only your secret keys. Type: [ying@serverXY ying]$ gpg --list-secret-keys /home/ying/.gnupg/secring.gpg sec 1024D/1D12E484 2003-10-16 Ying Yang (my test) <ying@serverXY> ssb 1024g/1EDB00AC 2003-10-16 Display the key fingerprints. Type: [ying@serverXY ying]$ gpg --fingerprint /home/ying/.gnupg/pubring.gpg pub 1024D/1D12E484 2003-10-16 Ying Yang (my test) <ying@serverXY> Key fingerprint = D61E 1538 EA12 9049 4ED3 5590 3BC4 A3C1 1D12 E484 sub 1024g/1EDB00AC 2003-10-16 [expires: 2004-10-15] Revocation certificates Revocation certificates are used revoking keys in case someone gets knowledge of your secret key or incase you forget your passphrase. They are also useful for other various functions. To create a revocation certificate While still logged in as the user ying. Create a revocation certificate. It will be displayed on your standard output. Type: [ying@serverXY ying]$ gpg --gen-revoke ying@serverXY Follow the prompts and enter your passphrase when prompted to do so. Now create a revocation certificate that will be stored in an ASCII format in a file called - \u201crevoke.asc\u201d. Type: [ying@serverXY ying]$ gpg --output revoke.asc --gen-revoke ying@serverXY You should store the revocation certificate in a safe place and even make a hard printed copy. Exporting Public Keys The whole point of all this encrypting, signing and decrypting business is because people wish to communicate with one another - but they also wish to do so in as secure a manner as possible. With that said - the perhaps not to so obvious has to be stated: To communicate with other people using a public-key based cryptosystem - you must exchange public keys. Or at least make your public key available in any publicly accessible place (Bill-boards, web pages, key servers, radio, T.V, SPAMMING via e-mail ..etc \u2026.. \uf04a) To export your public keys Export your public key in binary format to a file called \u201cying-pub.gpg\u201d. Type: [ying@serverXY ying]$ gpg --output ying-pub.gpg --export <your_key\u2019s_user_ID> NOTE: Please replace <your_key\u2019s_user_ID> with any string that correctly identifies your keys. On our sample system this value can be any one of the following: ying@serverXY, ying, yang OR The actual key ID - 1D12E484 Export your public key to a file called \u201cying-pub.asc\u201d. But this time generate it in ASCII-armored format. Type: [ying@serverXY ying]$ gpg --output ying-pub.asc --armor --export ying@serverXY Use the cat command to view the binary version of ying\u2019s public key (ying-pub.gpg) \uf04a \uf04a (To reset your terminal type: \u201creset\u201d) Use the cat command to view the ASCII version of ying\u2019s public key (ying-pub.asc) You will observe that the ASCII version is more suited for posting on web-pages or spamming etc.. Exercise 3 \u00b6 Digital signatures \u00b6 Creating and verifying signatures uses the public/private keypair in an operation different from encryption and decryption. A signature is created using the private key of the signer. The signature can be verified using the corresponding public key. To digitally sign a file Create a file named \u201csecret-file.txt\u201d with the text \u201cHello All\u201d in it. Type: [ying@serverXY ying]$ echo \"Hello All\" > secret1.txt Use cat to view the contents of the file. Use the file command to see the kind of file it is. Now sign the file with your digital signature. Type: [ying@serverXY ying]$ gpg -s secret1.txt Input your passphrase when prompted. The above command will create another file \u201csecret1.txt.gpg\u201d which is compressed and has a signature attached to it. Run the \u201cfile\u201d command on the file to check this. View the file with cat \uf04a Check the signature on the signed \u201csecret1.txt.gpg\u201d file. Type: [ying@serverXY ying]$ gpg --verify secret1.txt.gpg gpg: Signature made Thu 16 Oct 2003 07:29:37 AM PDT using DSA key ID 1D12E484 gpg: Good signature from \"Ying Yang (my test) <ying@serverXY>\" Create another file secret2.txt with the text \u201c Hello All\u201d in it. Sign the secret2.txt file but this time let the file be ASCII armored. Type: [ying@serverXY ying]$ gpg -sa secret2.txt An ASCII armored file called \u201csecret2.txt.asc\u201d will be created in your pwd. Use the cat command to view the contents of the ASCII armored file created for you above. Create another file called \u201csecret3.txt\u201d with the text \u201chello dude\u201d in it. Type: [ying@serverXY ying]$ echo \"hello dude\" > secret3.txt Append your signature to the body of the file you created above. Type: [ying@serverXY ying]$ gpg --clearsign secret3.txt This will create an uncompressed file (secret3.txt.asc) that is wrapped in your ASCII-armored signature. Write down the command to verify the signature of the file that was created for you. Open up the file to view its contents with any pager. Can you read the text you entered into the file? MAKE SURE THAT YOUR PARTNER HAS PERFORMED THE WHOLE OF \u201cEXERCISES -1, 2, 3\u201d ABOVE BEFORE YOU CONTINUE TO \u201cEXERCISE 4\u201d BELOW IF YOU DON\u2019T HAVE A PARTNER. LOG OFF USER YING\u2019s ACCOUNT AND LOG INTO THE SYSTEM AS THE USER \u201cme\u201d. THEN REPEAT THE WHOLE OF \u201cEXECISES -1,2,3\u201d AS THE USER \u201cme\u201d. YOU MAY THEN PERFORM EXERCISE 4 BELOW. REPLACE ALL REFERENCES TO THE USER YING AT \u201cserverPR\u201d WITH - USER \u201cme\u201d AT serverXY (i.e. your localhost) YOU CAN USE EITHER - USER \u201cme@serverXY\u201d or USER \u201cying@serverPR\u201d AS YOUR PARTNER IN THE NEXT EXERCISE. Exercise 4 \u00b6 In this exercise you will begin the actual communication with another user, using the so called \u201cWeb of Trust\u201d. Importing public keys Log into the system as user ying. Make your ASCII-armored public-key file (ying-pub.asc) available to your partner ( use either - me@serverXY or ying@serverPR) NOTE: There are several ways of doing this e.g. e-mail, copying and pasting, scp, ftp, Saving on a diskette etc... Select the most efficient method for yourself. Ask your partner to also make their public-key file available to you. Assuming your partner\u2019s public key is store in a file called \u201c me-pub.asc\u201d in your pwd; Import the key into your key-ring. Type: [ying@serverXY ying]$ gpg --import me-pub.asc gpg: key 1D0D7654: public key \"Me Mao (my test) <me@serverXY>\" imported gpg: Total number processed: 1 gpg: imported: 1 Now list the keys in your key-ring. Type: [ying@serverXY ying]$ gpg --list-keys /home/ying/.gnupg/pubring.gpg pub 1024D/1D12E484 2003-10-16 Ying Yang (my test) <ying@serverXY> sub 1024g/1EDB00AC 2003-10-16 [expires: 2004-10-15] pub 1024D/1D0D7654 2003-10-16 Me Mao (my test) <me@serverXY> sub 1024g/FD20DBF1 2003-10-16 [expires: 2004-10-15] In particular list the key that is associated with the user-ID me@serverXY. Type: [ying@serverXY ying]$ gpg --list-keys me@serverXY View the fingerprint of the key for me@serverXY. Type: [ying@serverXY ying]$ gpg --fingerprint me@serverXY Encrypting and decrypting files The procedure for encrypting and decrypting files or documents is straight forward. If you want to encrypt a message to the user ying, you will encrypt it using user ying\u2019s public key. Upon receipt, ying will need to decrypt the message with ying\u2019s private key. ONLY ying can decrypt the message or file that was encrypted with ying\u2019s public key To encrypt a file While logged into the system as the user ying, create a file called encrypt-sec.txt. Type: [ying@serverXY ying]$ echo \"hello\" > encrypt-sec.txt Make sure you can read the contents of the file using cat. Encrypt the file encrypt-sec.txt, such that only the user \u201cme\u201d can view the file. i.e. you will encrypt it using me@serverXY\u2019s public key ( which you now have in your key-ring). Type: [ying@serverXY ying]$ gpg --encrypt --recipient me@serverXY encrypt-sec.txt The above command will create an encrypted file called \u201cencrypt-sec.txt.gpg\u201d in your pwd. To decrypt a file The file you encrypted above was meant for me@serverXY. Try to decrypt the file. Type: [ying@serverXY ying]$ gpg --decrypt encrypt-sec.txt.gpg gpg: encrypted with 1024-bit ELG-E key, ID FD20DBF1, created 2003-10-16 \"Me Mao (my test) <me@serverXY>\" gpg: decryption failed: secret key not available Have we learnt any valuable lesson here? Make the encrypted file you created available to the correct owner and have them run the above command to decrypt the file. Were they more successful in decrypting the file. NOTE: Be very careful when decrypting binary files ( e.g. programs), because after successfully decrypting a file gpg will attempt to send the contents of the file to standard output. Make a habit of using the command below instead when decrypting files: [ying@serverXY ying]$ gpg --output encrypt-sec --decrypt encrypt-sec.txt.gpg This forces sending the output to a file called \u201cencrypt-sec\u201d. Which can then be viewed (or run) using any program that is suited for the file (or content) type. TIPS !! Most of the commands and options used with the gpg program also have short forms that results in less typing for the user at the command line. e.g. gpg --encrypt --recipient me@serverXY encrypt-sec.txt The short form of the above command is: gpg -e -r me@serverXY encrypt-sec.txt To encrypt the string \"hello\" and mails it as an ASCII armored message to the user with the mail address ying@serverXY; Use the command below: echo \"hello\" | gpg -ea -r ying@serverXY | mail ying@serverXY To encrypt the file \"your_file\" with the public key of \"me@serverXY\" and write it to \"your_file.gpg\" after signing it with your user id (using your digital signature); Use the command below: gpg -se -r me@serverXY your_file There is a publicly available key server at wwwkeys.pgp.net. You can use gpg to upload your key there with: gpg --send-keys <your_real_email_address> --keyserver wwwkeys.pgp.net OpenSSH (www.openssh.org) OpenSSH is OpenBSD's SSH (Secure SHell) protocol implementation. It is a FREE version of the SSH protocol suite of network connectivity tools. OpenSSH encrypts all traffic (including passwords) to effectively eliminate eavesdropping, connection hijacking, and other network-level attacks. Additionally, OpenSSH provides a plethora of secure tunneling capabilities, as well as a variety of authentication methods. It helps to provide secure encrypted communications between two untrusted hosts over an insecure network (such as the internet). It includes both the server side components and the client side suite of programs. sshd The server side includes the secure shell daemon (sshd). sshd is the daemon that listens for connections from clients. It forks a new daemon for each incoming connection. The forked daemons handle key exchange, encryption, authentication, command execution, and data exchange. According to sshd\u2019s man page, sshd works as follows: For SSH protocol version 2\u2026.. Each host has a host-specific key (RSA or DSA) used to identify the host. When the daemon starts, it does not generate a server key (As is the case in SSH protocol version 1). Forward security is provided through a Diffie-Hellman key agreement. This key agreement results in a shared session key. The rest of the session is encrypted using a symmetric cipher, currently 128 bit AES, Blowfish, 3DES, CAST128, Arcfour, 192 bit AES, or 256 bit AES. The client selects the encryption algorithm to use from those offered by the server. Additionally, session integrity is provided through a cryptographic message authentication code (hmac-sha1 or hmac-md5). Protocol version 2 provides a public key based user (PubkeyAuthentication) or client host (HostbasedAuthentication) authentication method, conventional password authentication and challenge response based methods. The SSH2 protocol implemented in OpenSSH is standardized by the \u201cIETF secsh\u201d working group ssh The clients suite of programs include \u201cssh\u201d. This is a program used for logging into remote systems and can also be used for executing commands on remote systems. Exercise 5 \u00b6 sshd \u00b6 Usage: sshd [options] Options: -f file Configuration file (default /etc/ssh/sshd_config) -d Debugging mode (multiple -d means more debugging) -i Started from inetd -D Do not fork into daemon mode -t Only test configuration file and keys -q Quiet (no logging) -p port Listen on the specified port (default: 22) -k seconds Regenerate server key every this many seconds (default: 3600) -g seconds Grace period for authentication (default: 600) -b bits Size of server RSA key (default: 768 bits) -h file File from which to read host key (default: /etc/ssh/ssh_host_key) -u len Maximum hostname length for utmp recording -4 Use IPv4 only -6 Use IPv6 only -o option Process the option as if it was read from a configuration file. Most Linux systems out of the box already have the OpenSSH server configured and running with some defaults. The configuration file for sshd usually resides under - /etc/ssh/ - and is called sshd_config. sshd_config Open up the ssh server\u2019s config file with any pager and study it. Type: [root@serverXY root]# less /etc/ssh/sshd_config NOTE: sshd_config is a rather odd configuration file. You will notice that unlike other Linux config files - comments (#) in the sshd_config file denotes the defaults values of the options. i.e. comments represents already compiled-in defaults. Consult the man page for sshd_config and explain what the options below do? AuthorizedKeysFile Ciphers HostKey Port Protocol X11Forwarding HostKey Change your pwd to the /etc/ssh/ directory. List all the files in the directory below: Creating host keys Your ssh server already has hosts keys that it uses. Those keys were generated when your system was first installed. In this exercise you will learn how to create host type keys for your server. But you wont actually use the keys. To generate host keys for your server Create a new directory under your pwd. Call it spare-keys. cd to the new directory. Type: [root@serverXY ssh]# mkdir spare-keys && cd spare-keys Use the ssh-keygen program to create a host key with the following characteristics: a. key type should be \u201crsa\u201d b. Key should have no comments c. Private key file should be named - ssh_host_rsa_key d. The key should not use any passphrase Type: [root@serverXY spare-keys]# ssh-keygen -q -t rsa -f ssh_host_rsa_key -C '' -N '' View the fingerprint of the key you created above. Type: [root@serverXY spare-keys]# ssh-keygen -l -f ssh_host_rsa_key Write down the command to create a dsa type key called \u201cssh_host_dsa_key\u201d with no comments, and no passphrase? Exercise 6 \u00b6 ssh \u00b6 Usage:- ssh \\[-l login\\_name\\] hostname | user@hostname \\[command\\] ssh \\[-afgknqstvxACNTX1246\\] \\[-b bind\\_address\\] \\[-c cipher\\_spec\\] \\[-e escape\\_char\\] \\[-i identity\\_file\\] \\[-l login\\_name\\] \\[-m mac\\_spec\\] \\[-o option\\] \\[-p port\\] \\[-F configfile\\] \\[-L port:host:hostport\\] \\[-R port:host:hostport\\] \\[-D port\\] hostname | user@hostname \\[command\\] To use ssh Log into serverXY as the user me. Use ssh to connect to serverPR. Type: [me@serverXY me]$ ssh serverPR Type in me\u2019s password when prompted. If you get any warning messages type \u201cyes\u201d to continue. After logging in, create a directory called - myexport and create an empty file. Type: [me@serverPR me]$ mkdir ~/myexport && touch myexport/$$ Make a note of the random file that was created for you, under ~/myexport ? Log off serverPR. Type: [me@serverPR me]$ exit You will be returned to your local shell at serverXY. Use ssh to remotely execute the \u201cls\u201d command to view the list of files in ying\u2019s home directory at serverPR. Type: [me@serverXY me]$ ssh ying@serverPR \u201cls /home/ying\u201d Type in ying\u2019s password when prompted. If you get any warning messages type \u201cyes\u201d to continue. While still logged in as me on serverXY, log into serverPR as the user ying. Type: [me@serverXY me]$ ssh -l ying serverPR Type in ying\u2019s password when prompted. Type \u201cexit\u201d to log off serverPR and return to serverXY. scp scp - secure copy (remote file copy program) scp copies files between hosts on a network. It uses ssh for data transfer, and uses the same authentication and provides the same security as ssh. Usage:- scp \\[-pqrvBC46\\] \\[-F ssh\\_config\\] \\[-S program\\] \\[-P port\\] \\[-c cipher\\] \\[-i identity\\_file\\] \\[-o ssh\\_option\\] \\[\\[user@\\]host1:\\] file1 \\[...\\] \\[\\[user@\\]host2:\\] file2 ``` To use scp 1. Make sure you are still logged in as the user me on serverXY. 2. Create a directory under your home directory called myimport and cd to the directory. 3. Copy over all the files under the \u201c/home/me/myexport/\u201d directory on serverPR. Type: \\[me@serverXY myimports\\]$ ***scp serverPR:/home/me/myexport .*** 4. List the contents of your pwd ? Was that totally cool or what ? 5. What is the command to copy over all the under \u201c/home/me/.gnugp/\u201d on serverPR ? 6. Now copy over all the files under ying\u2019s home directory on serverPR. Type: \\[me@serverXY myimports\\]$ ***scp -r ying@serverPR:/home/ying/\\* .*** # Exercise 7 ## Creating User Public and Private keys for SSH Each individual user that wants to use SSH with RSA or DSA authentication needs a set of public keys and private keys. The ssh-keygen program can be used to create these keys ( just as it was used earlier when you created spare keys for your system) The only \u201cadvised\u201d difference when creating user keys is to also create a passphrase. The passphrase is a password that the is used to encrypt the private key before it is stored on the file system. The public is store in a file with the same file name as the private key but with the extension \u201c.pub\u201d appended to it. There is no way to recover a lost passphrase. If the passphrase is lost or forgotten, a new key must be generated. To create ying\u2019s authentication keys 1. Log into your local machine as the user ying. 2. Run the \u201cssh-keygen\u201d program to create a \u201c***dsa***\u201d type key with the default length. Type: \\[ying@serverXY ying\\]$ ***ssh-keygen -t dsa*** Generating public/private dsa key pair. Press \\[ENTER\\] to accept the default file location. Enter file in which to save the key (/home/ying/.ssh/id\\_dsa): \\[ENTER\\] Enter a very good passphrase when prompted - i.e. one that is difficult to guess. Created directory '/home/ying/.ssh'. Enter passphrase (empty for no passphrase): \\*\\*\\*\\*\\*\\*\\*\\*\\* Enter same passphrase again: \\*\\*\\*\\*\\*\\*\\*\\*\\* Your identification has been saved in /home/ying/.ssh/id\\_dsa. Your public key has been saved in /home/ying/.ssh/id\\_dsa.pub. The key fingerprint is: 61:68:aa:c2:0c:af:9b:49:4a:11:b8:aa:b5:84:18:10 ying@serverXY.example.org 3. cd to your \u201c**~/.ssh/**\u201d directory. List the files in the directory? 4. What is the \u201cssh-keygen\u201d command to view the fingerprint of your keys? 5. Use the cat command to view the contents of your public-key file (i.e. \u201c**~/.ssh/id\\_rsa.pub**\u201d). # Exercise 8 ## Authenticating via Public-Key Thus far you have been using a password based authentication scheme to log into user accounts at serverPR. This means that, you had to have known the corresponding account\u2019s password on the remote side to have been able to log in successfully. In this exercise you will configure public-key authentication between your user account on serverXY and the ying\u2019s user account at serverPR. To configure public-key authentication 1. Log into your local system as the user ying. 2. cd to your \u201c~/.ssh\u201d directory. 3. Type in the horrible looking command below: \\[ying@serverXY .ssh\\]$ ***cat id\\_dsa.pub | ssh ying@serverPR \\\\*** '(cd ~/.ssh && cat - &gt;&gt; authorized\\_keys && chmod 600 authorized\\_keys)' The above command reads: a. cat the contents of your dsa public-key file, but send the out to the pipe ( | ) instead of the usual standard out. b. run the command \u201c***cd ~/.ssh && cat - &gt;&gt; authorized\\_keys && chmod 600 authorized\\_keys\u201d*** as the user ying on serverPR. c. The whole point of the command is simply to copy and append the contents of your public-key file to the \u201c/home/ying/.ssh/authorized\\_keys\u201d on serverPR and give it the correct permissions. If you know of any other manual way to achieve the same result, please do so. 4. After you have added your public-key to the authorized\\_keys file on the remote system. Attempt to login to serverPR as ying via ssh. Type: \\[ying@serverXY .ssh\\]$ ***ssh serverPR*** Enter passphrase for key '/home/ying/.ssh/id\\_dsa': \\*\\*\\*\\*\\*\\*\\*\\*\\*\\* Note very carefully that, you are being prompted for your passphrase this time instead of the password. Enter the passphrase you created earlier when you created your keys. 5. After successfully logging into serverPR; Log back out. # Exercise 9 ## ssh-agent According to the man page - ssh-agent is a program to hold private keys used for public key authentication (RSA, DSA). The idea is that ssh-agent is started in the beginning of an X-session or a login session, and all other windows or programs are started as clients to the ssh-agent program. Through use of environment variables the agent can be located and automatically used for authentication when logging into other machines using ssh. Usage ssh-agent [-a bind_address] [-c | -s] [-d] [command [args ...]] ssh-agent [-c | -s] -k ``` In this exercise you will learn how to configure the agent such that you wont have to type in your passphrase every time you want to connect to another system using public-key authentication. Make sure you are logged into your local system as the user ying. Type in the command below: [ying@serverXY .ssh]$ eval `ssh-agent` Agent pid 5623 Take note of the PID of the agent: Use the \u201c ssh-add \u201d program to add your keys to the agent you launched above. Type: [ying@serverXY .ssh]$ ssh-add Enter your passphrase when prompted. Enter passphrase for /home/ying/.ssh/id_dsa: Identity added: /home/ying/.ssh/id_dsa (/home/ying/.ssh/id_dsa) Now connect to serverPR as the user ying. You WILL NOT be prompted for a password or passphrase (i.e if everything has been done correctly). Type: [ying@serverXY .ssh]$ ssh serverPR Enjoy.","title":"Lab 9: Cryptography"},{"location":"labs/security/rocky-lab9-cryptography/#lab-9-cryptography","text":"Objectives After completing this lab, you will be able to apply cryptographic concepts in securing data and communication Estimated time to complete this lab: 120 minutes Table of Contents Common cryptography terms and definitions Exercise 1 Gnupg Exercise 2 Key Administration Exercise 3 Digital Signatures","title":"Lab 9: Cryptography"},{"location":"labs/security/rocky-lab9-cryptography/#common-cryptography-terms-and-definitions","text":"Cryptography In general everyday usage, Cryptography is the act or art of writing in secret characters. In technical jargon it may be defined as the science of using mathematics to encrypt and decrypt data. Cryptanalysis Cryptanalysis is the study of how to compromise (defeat) cryptographic mechanisms. It is the science of cracking code, decoding secrets, violating authentication schemes, and in general, breaking cryptographic protocols. Cryptology Cryptology is the discipline of cryptography and cryptanalysis combined. Cryptology is the branch of mathematics that studies the mathematical foundations of cryptographic methods. Encryption Encryption is the transformation of data into a form that is as close to impossible as possible to read without the appropriate knowledge (e.g. a key). Its purpose is to ensure privacy by keeping information hidden from anyone for whom it is not intended. Decryption Decryption is the reverse of encryption; it is the transformation of encrypted data back into an intelligible form. Cipher A method of encryption and decryption is called a cipher. Hash Functions (Digest algorithms) Cryptographic hash functions are used in various contexts, for example to compute the message digest when making a digital signature. A hash function compresses the bits of a message to a fixed-size hash value in a way that distributes the possible messages evenly among the possible hash values. A cryptographic hash function does this in a way that makes it extremely difficult to come up with a message that would hash to a particular hash value. Some examples of the best known and most widely used hash functions are described below. a) - SHA-1 (Secure Hash Algorithm) -This is a cryptographic hash algorithm published by the United States Government. It produces a 160 bit hash value from an arbitrary length string. It is considered to be very good. b) - MD5 (Message Digest Algorithm 5) - is a cryptographic hash algorithm developed at RSA Laboratories. It can be used to hash an arbitrary length byte string into a 128 bit value. Algorithm It describes a step-by-step problem-solving procedure, especially an established, recursive computational procedure for solving a problem in a finite number of steps. Technically, an algorithm must reach a result after a finite number of steps. The efficiency of an algorithm can be measured as the number of elementary steps it takes to solve the problem. There are two classes of key-based algorithms. They are: a) -- Symmetric Encryption Algorithms ( secret-key) Symmetric algorithms use the same key for encryption and decryption (or the decryption key is easily derived from the encryption key). Secret key algorithms use the same key for both encryption and decryption (or one is easily derivable from the other). This is the more straightforward approach to data encryption, it is mathematically less complicated than public-key cryptography. Symmetric algorithms can be divided into stream ciphers and block ciphers. Stream ciphers can encrypt a single bit of plaintext at a time, whereas block ciphers take a number of bits (typically 64 bits in modern ciphers), and encrypt them as a single unit. Symmetric algorithms are much faster to execute on a computer than asymmetric ones. Examples of symmetric algorithms are: AES, 3DES, Blowfish, CAST5, IDEA and Twofish. b) -- Asymmetric algorithms (Public-key algorithms) Asymmetric algorithms on the other hand use a different key for encryption and decryption, and the decryption key cannot be derived from the encryption key. Asymmetric ciphers permit the encryption key to be public, allowing anyone to encrypt with the key, whereas only the proper recipient (who knows the decryption key) can decrypt the message. The encryption key is also called the public key and the decryption key the private key or secret key. RSA is probably the best known asymmetric encryption algorithm. Digital Signature A digital signature binds a document to the owner of a particular key. Digital signatures are used to verify that a message really comes from the claimed sender. The digital signature of a document is a piece of information based on both the document and the signer's private key. It is typically created through the use of a hash function and a private signing function (encrypting with the signer's private key). A digital signature is a small amount of data that was created using some secret key, and there is a public key that can be used to verify that the signature was really generated using the corresponding private key. Several methods for making and verifying digital signatures are freely available but the most widely known algorithm is the RSA public-key algorithm. Cryptographic Protocols Cryptography works on many levels. On one level you have algorithms, such as block ciphers and public key cryptosystems. Building upon these you obtain protocols, and building upon protocols you find applications (or other protocols). Below is a list of common everyday applications that make use of cryptographic protocols. These protocols are built on lower level cryptographic algorithms. i.) Domain Name Server Security (DNSSEC) This is a protocol for secure distributed name services. It is currently available as an Internet Draft. ii.) Secure Socket Layer (SSL) SSL is one of the two protocols used for secure WWW connections (the other is SHTTP). WWW security has become important as, increasing amounts of sensitive information, such as credit card numbers, are being transmitted over the Internet. iii.) Secure Hypertext Transfer Protocol (SHTTP) This is another protocol for providing more security for WWW transactions. iv) E-Mail security and related services GnuPG - The GNU Privacy Guard - is compliant with the proposed OpenPGP Internet standard as described in RFC2440. v) SSH2 Protocol This protocol is versatile for the needs of the internet, and is currently used in the SSH2 software. The protocol is used to secure terminal sessions and TCP connections. The following exercises examine two particular applications that make use of cryptographic protocols - GnuPG and OpenSSH.","title":"Common Cryptography terms and definitions"},{"location":"labs/security/rocky-lab9-cryptography/#exercise-1","text":"","title":"Exercise 1"},{"location":"labs/security/rocky-lab9-cryptography/#gnupg","text":"GnuPG (GNU Privacy Guard) is a set of programs for public key encryption and digital signatures. The tools can be used to encrypt data and to create digital signatures. It also includes an advanced key management facility. GnuPG uses public-key cryptography to enable users to communicate securely Perform the following exercises as a regular user. e.g. user ying To create a new keypair Log into the system as user \u201c ying \u201d Make sure that the GnuPG package is installed on your system. Type: [ying@serverXY ying]$ ***rpm -q gnupg*** gnupg-*.* If it isn\u2019t, get the super-user to install it. List and make a note of all the hidden directories in your home directory. List the keys you currently have in your key-ring. Type: [ying@serverXY ying]$ ***gpg --list-keys*** NOTE :- You shouldn\u2019t have any keys in your key-ring yet. But the above command will also help create a default environment to enable you create a new key-pair successfully the first time. List the hidden directories in your home directory again. What is the name of the new directory added? Use the gpg program to create your new key-pairs. Type: [ying@serverXY ying\\]$ ***gpg --gen-key*** ...................................... gpg: keyring \\`/home/ying/.gnupg/secring.gpg' created gpg: keyring \\`/home/ying/.gnupg/pubring.gpg' created Please select what kind of key you want: (1) DSA and ElGamal (default) (2) DSA (sign only) (5) RSA (sign only) Your selection? 1 At the prompt for the type of key your want to create accept the default i.e.(DSA and ElGamal). Type 1 NOTES : Option (1) will create two key-pairs for you. The DSA key-pair will be the primary keypair - for making digital signatures and a subordinate ELGamel keypair for data encryption. You will create an ELG-E keysize of 1024. Accept the default again at the prompt below: DSA keypair will have 1024 bits. About to generate a new ELG-E keypair. minimum keysize is 768 bits default keysize is 1024 bits highest suggested keysize is 2048 bits What keysize do you want? (1024) 1024 Create keys that will expire in a year. Type \u201c1y\u201d at the prompt below: Please specify how long the key should be valid. 0 = key does not expire <n> = key expires in n days <n>w = key expires in n weeks <n>m = key expires in n months <n>y = key expires in n years Key is valid for? (0) 1y Type \u201cy\u201d to accept the expiry date shown at the prompt: Is this correct (y/n)? y Create a User-ID to identify your key with: You need a User-ID to identify your key; the software constructs the user id from Real Name, Comment and Email Address in this form: \"Firstname Lastname (any comment) <yourname@serverXY>\" Real name: Ying Yang[ENTER] Comment : my test[ENTER] Email address: ying@serverXY [ENTER] At the confirmation prompt type \u201co\u201d (Okay) to accept the correct values. You selected this USER-ID: \"Ying Yang (my test) <ying@serverXY>\" Change (N)ame, (C)omment, (E)mail or (O)kay/(Q)uit? O Select a passphrase that you WILL NOT forget at the next prompt: Enter passphrase: ******** Repeat passphrase: ********","title":"GnuPG"},{"location":"labs/security/rocky-lab9-cryptography/#exercise-2","text":"","title":"Exercise 2"},{"location":"labs/security/rocky-lab9-cryptography/#key-administration","text":"The gpg program is also used in key administration. Listing your keys While still logged into the system as the user ying. Display the keys in your key-ring. Type: [ying@serverXY ying]$ gpg --list-keys gpg: WARNING: using insecure memory! /home/ying/.gnupg/pubring.gpg pub 1024D/1D12E484 2003-10-16 Ying Yang (my test) <ying@serverXY> sub 1024g/1EDB00AC 2003-10-16 [expires: 2004-10-15] To suppress the somewhat annoying \u201cwarning\u201d about \u201cinsecure memory\u201d add the following option to your personal gpg configuration file. Type: [ying@serverXY ying]$ echo \"no-secmem-warning\" >> ~/.gnupg/gpg.conf Run the command to list your keys again. to make sure your change is in effect. List your keys along with their signatures. Type: [ying@serverXY ying]$ gpg --list-sigs /home/ying/.gnupg/pubring.gpg ........<SNIP>............. List only your secret keys. Type: [ying@serverXY ying]$ gpg --list-secret-keys /home/ying/.gnupg/secring.gpg sec 1024D/1D12E484 2003-10-16 Ying Yang (my test) <ying@serverXY> ssb 1024g/1EDB00AC 2003-10-16 Display the key fingerprints. Type: [ying@serverXY ying]$ gpg --fingerprint /home/ying/.gnupg/pubring.gpg pub 1024D/1D12E484 2003-10-16 Ying Yang (my test) <ying@serverXY> Key fingerprint = D61E 1538 EA12 9049 4ED3 5590 3BC4 A3C1 1D12 E484 sub 1024g/1EDB00AC 2003-10-16 [expires: 2004-10-15] Revocation certificates Revocation certificates are used revoking keys in case someone gets knowledge of your secret key or incase you forget your passphrase. They are also useful for other various functions. To create a revocation certificate While still logged in as the user ying. Create a revocation certificate. It will be displayed on your standard output. Type: [ying@serverXY ying]$ gpg --gen-revoke ying@serverXY Follow the prompts and enter your passphrase when prompted to do so. Now create a revocation certificate that will be stored in an ASCII format in a file called - \u201crevoke.asc\u201d. Type: [ying@serverXY ying]$ gpg --output revoke.asc --gen-revoke ying@serverXY You should store the revocation certificate in a safe place and even make a hard printed copy. Exporting Public Keys The whole point of all this encrypting, signing and decrypting business is because people wish to communicate with one another - but they also wish to do so in as secure a manner as possible. With that said - the perhaps not to so obvious has to be stated: To communicate with other people using a public-key based cryptosystem - you must exchange public keys. Or at least make your public key available in any publicly accessible place (Bill-boards, web pages, key servers, radio, T.V, SPAMMING via e-mail ..etc \u2026.. \uf04a) To export your public keys Export your public key in binary format to a file called \u201cying-pub.gpg\u201d. Type: [ying@serverXY ying]$ gpg --output ying-pub.gpg --export <your_key\u2019s_user_ID> NOTE: Please replace <your_key\u2019s_user_ID> with any string that correctly identifies your keys. On our sample system this value can be any one of the following: ying@serverXY, ying, yang OR The actual key ID - 1D12E484 Export your public key to a file called \u201cying-pub.asc\u201d. But this time generate it in ASCII-armored format. Type: [ying@serverXY ying]$ gpg --output ying-pub.asc --armor --export ying@serverXY Use the cat command to view the binary version of ying\u2019s public key (ying-pub.gpg) \uf04a \uf04a (To reset your terminal type: \u201creset\u201d) Use the cat command to view the ASCII version of ying\u2019s public key (ying-pub.asc) You will observe that the ASCII version is more suited for posting on web-pages or spamming etc..","title":"Key Administration"},{"location":"labs/security/rocky-lab9-cryptography/#exercise-3","text":"","title":"Exercise 3"},{"location":"labs/security/rocky-lab9-cryptography/#digital-signatures","text":"Creating and verifying signatures uses the public/private keypair in an operation different from encryption and decryption. A signature is created using the private key of the signer. The signature can be verified using the corresponding public key. To digitally sign a file Create a file named \u201csecret-file.txt\u201d with the text \u201cHello All\u201d in it. Type: [ying@serverXY ying]$ echo \"Hello All\" > secret1.txt Use cat to view the contents of the file. Use the file command to see the kind of file it is. Now sign the file with your digital signature. Type: [ying@serverXY ying]$ gpg -s secret1.txt Input your passphrase when prompted. The above command will create another file \u201csecret1.txt.gpg\u201d which is compressed and has a signature attached to it. Run the \u201cfile\u201d command on the file to check this. View the file with cat \uf04a Check the signature on the signed \u201csecret1.txt.gpg\u201d file. Type: [ying@serverXY ying]$ gpg --verify secret1.txt.gpg gpg: Signature made Thu 16 Oct 2003 07:29:37 AM PDT using DSA key ID 1D12E484 gpg: Good signature from \"Ying Yang (my test) <ying@serverXY>\" Create another file secret2.txt with the text \u201c Hello All\u201d in it. Sign the secret2.txt file but this time let the file be ASCII armored. Type: [ying@serverXY ying]$ gpg -sa secret2.txt An ASCII armored file called \u201csecret2.txt.asc\u201d will be created in your pwd. Use the cat command to view the contents of the ASCII armored file created for you above. Create another file called \u201csecret3.txt\u201d with the text \u201chello dude\u201d in it. Type: [ying@serverXY ying]$ echo \"hello dude\" > secret3.txt Append your signature to the body of the file you created above. Type: [ying@serverXY ying]$ gpg --clearsign secret3.txt This will create an uncompressed file (secret3.txt.asc) that is wrapped in your ASCII-armored signature. Write down the command to verify the signature of the file that was created for you. Open up the file to view its contents with any pager. Can you read the text you entered into the file? MAKE SURE THAT YOUR PARTNER HAS PERFORMED THE WHOLE OF \u201cEXERCISES -1, 2, 3\u201d ABOVE BEFORE YOU CONTINUE TO \u201cEXERCISE 4\u201d BELOW IF YOU DON\u2019T HAVE A PARTNER. LOG OFF USER YING\u2019s ACCOUNT AND LOG INTO THE SYSTEM AS THE USER \u201cme\u201d. THEN REPEAT THE WHOLE OF \u201cEXECISES -1,2,3\u201d AS THE USER \u201cme\u201d. YOU MAY THEN PERFORM EXERCISE 4 BELOW. REPLACE ALL REFERENCES TO THE USER YING AT \u201cserverPR\u201d WITH - USER \u201cme\u201d AT serverXY (i.e. your localhost) YOU CAN USE EITHER - USER \u201cme@serverXY\u201d or USER \u201cying@serverPR\u201d AS YOUR PARTNER IN THE NEXT EXERCISE.","title":"Digital signatures"},{"location":"labs/security/rocky-lab9-cryptography/#exercise-4","text":"In this exercise you will begin the actual communication with another user, using the so called \u201cWeb of Trust\u201d. Importing public keys Log into the system as user ying. Make your ASCII-armored public-key file (ying-pub.asc) available to your partner ( use either - me@serverXY or ying@serverPR) NOTE: There are several ways of doing this e.g. e-mail, copying and pasting, scp, ftp, Saving on a diskette etc... Select the most efficient method for yourself. Ask your partner to also make their public-key file available to you. Assuming your partner\u2019s public key is store in a file called \u201c me-pub.asc\u201d in your pwd; Import the key into your key-ring. Type: [ying@serverXY ying]$ gpg --import me-pub.asc gpg: key 1D0D7654: public key \"Me Mao (my test) <me@serverXY>\" imported gpg: Total number processed: 1 gpg: imported: 1 Now list the keys in your key-ring. Type: [ying@serverXY ying]$ gpg --list-keys /home/ying/.gnupg/pubring.gpg pub 1024D/1D12E484 2003-10-16 Ying Yang (my test) <ying@serverXY> sub 1024g/1EDB00AC 2003-10-16 [expires: 2004-10-15] pub 1024D/1D0D7654 2003-10-16 Me Mao (my test) <me@serverXY> sub 1024g/FD20DBF1 2003-10-16 [expires: 2004-10-15] In particular list the key that is associated with the user-ID me@serverXY. Type: [ying@serverXY ying]$ gpg --list-keys me@serverXY View the fingerprint of the key for me@serverXY. Type: [ying@serverXY ying]$ gpg --fingerprint me@serverXY Encrypting and decrypting files The procedure for encrypting and decrypting files or documents is straight forward. If you want to encrypt a message to the user ying, you will encrypt it using user ying\u2019s public key. Upon receipt, ying will need to decrypt the message with ying\u2019s private key. ONLY ying can decrypt the message or file that was encrypted with ying\u2019s public key To encrypt a file While logged into the system as the user ying, create a file called encrypt-sec.txt. Type: [ying@serverXY ying]$ echo \"hello\" > encrypt-sec.txt Make sure you can read the contents of the file using cat. Encrypt the file encrypt-sec.txt, such that only the user \u201cme\u201d can view the file. i.e. you will encrypt it using me@serverXY\u2019s public key ( which you now have in your key-ring). Type: [ying@serverXY ying]$ gpg --encrypt --recipient me@serverXY encrypt-sec.txt The above command will create an encrypted file called \u201cencrypt-sec.txt.gpg\u201d in your pwd. To decrypt a file The file you encrypted above was meant for me@serverXY. Try to decrypt the file. Type: [ying@serverXY ying]$ gpg --decrypt encrypt-sec.txt.gpg gpg: encrypted with 1024-bit ELG-E key, ID FD20DBF1, created 2003-10-16 \"Me Mao (my test) <me@serverXY>\" gpg: decryption failed: secret key not available Have we learnt any valuable lesson here? Make the encrypted file you created available to the correct owner and have them run the above command to decrypt the file. Were they more successful in decrypting the file. NOTE: Be very careful when decrypting binary files ( e.g. programs), because after successfully decrypting a file gpg will attempt to send the contents of the file to standard output. Make a habit of using the command below instead when decrypting files: [ying@serverXY ying]$ gpg --output encrypt-sec --decrypt encrypt-sec.txt.gpg This forces sending the output to a file called \u201cencrypt-sec\u201d. Which can then be viewed (or run) using any program that is suited for the file (or content) type. TIPS !! Most of the commands and options used with the gpg program also have short forms that results in less typing for the user at the command line. e.g. gpg --encrypt --recipient me@serverXY encrypt-sec.txt The short form of the above command is: gpg -e -r me@serverXY encrypt-sec.txt To encrypt the string \"hello\" and mails it as an ASCII armored message to the user with the mail address ying@serverXY; Use the command below: echo \"hello\" | gpg -ea -r ying@serverXY | mail ying@serverXY To encrypt the file \"your_file\" with the public key of \"me@serverXY\" and write it to \"your_file.gpg\" after signing it with your user id (using your digital signature); Use the command below: gpg -se -r me@serverXY your_file There is a publicly available key server at wwwkeys.pgp.net. You can use gpg to upload your key there with: gpg --send-keys <your_real_email_address> --keyserver wwwkeys.pgp.net OpenSSH (www.openssh.org) OpenSSH is OpenBSD's SSH (Secure SHell) protocol implementation. It is a FREE version of the SSH protocol suite of network connectivity tools. OpenSSH encrypts all traffic (including passwords) to effectively eliminate eavesdropping, connection hijacking, and other network-level attacks. Additionally, OpenSSH provides a plethora of secure tunneling capabilities, as well as a variety of authentication methods. It helps to provide secure encrypted communications between two untrusted hosts over an insecure network (such as the internet). It includes both the server side components and the client side suite of programs. sshd The server side includes the secure shell daemon (sshd). sshd is the daemon that listens for connections from clients. It forks a new daemon for each incoming connection. The forked daemons handle key exchange, encryption, authentication, command execution, and data exchange. According to sshd\u2019s man page, sshd works as follows: For SSH protocol version 2\u2026.. Each host has a host-specific key (RSA or DSA) used to identify the host. When the daemon starts, it does not generate a server key (As is the case in SSH protocol version 1). Forward security is provided through a Diffie-Hellman key agreement. This key agreement results in a shared session key. The rest of the session is encrypted using a symmetric cipher, currently 128 bit AES, Blowfish, 3DES, CAST128, Arcfour, 192 bit AES, or 256 bit AES. The client selects the encryption algorithm to use from those offered by the server. Additionally, session integrity is provided through a cryptographic message authentication code (hmac-sha1 or hmac-md5). Protocol version 2 provides a public key based user (PubkeyAuthentication) or client host (HostbasedAuthentication) authentication method, conventional password authentication and challenge response based methods. The SSH2 protocol implemented in OpenSSH is standardized by the \u201cIETF secsh\u201d working group ssh The clients suite of programs include \u201cssh\u201d. This is a program used for logging into remote systems and can also be used for executing commands on remote systems.","title":"Exercise 4"},{"location":"labs/security/rocky-lab9-cryptography/#exercise-5","text":"","title":"Exercise 5"},{"location":"labs/security/rocky-lab9-cryptography/#sshd","text":"Usage: sshd [options] Options: -f file Configuration file (default /etc/ssh/sshd_config) -d Debugging mode (multiple -d means more debugging) -i Started from inetd -D Do not fork into daemon mode -t Only test configuration file and keys -q Quiet (no logging) -p port Listen on the specified port (default: 22) -k seconds Regenerate server key every this many seconds (default: 3600) -g seconds Grace period for authentication (default: 600) -b bits Size of server RSA key (default: 768 bits) -h file File from which to read host key (default: /etc/ssh/ssh_host_key) -u len Maximum hostname length for utmp recording -4 Use IPv4 only -6 Use IPv6 only -o option Process the option as if it was read from a configuration file. Most Linux systems out of the box already have the OpenSSH server configured and running with some defaults. The configuration file for sshd usually resides under - /etc/ssh/ - and is called sshd_config. sshd_config Open up the ssh server\u2019s config file with any pager and study it. Type: [root@serverXY root]# less /etc/ssh/sshd_config NOTE: sshd_config is a rather odd configuration file. You will notice that unlike other Linux config files - comments (#) in the sshd_config file denotes the defaults values of the options. i.e. comments represents already compiled-in defaults. Consult the man page for sshd_config and explain what the options below do? AuthorizedKeysFile Ciphers HostKey Port Protocol X11Forwarding HostKey Change your pwd to the /etc/ssh/ directory. List all the files in the directory below: Creating host keys Your ssh server already has hosts keys that it uses. Those keys were generated when your system was first installed. In this exercise you will learn how to create host type keys for your server. But you wont actually use the keys. To generate host keys for your server Create a new directory under your pwd. Call it spare-keys. cd to the new directory. Type: [root@serverXY ssh]# mkdir spare-keys && cd spare-keys Use the ssh-keygen program to create a host key with the following characteristics: a. key type should be \u201crsa\u201d b. Key should have no comments c. Private key file should be named - ssh_host_rsa_key d. The key should not use any passphrase Type: [root@serverXY spare-keys]# ssh-keygen -q -t rsa -f ssh_host_rsa_key -C '' -N '' View the fingerprint of the key you created above. Type: [root@serverXY spare-keys]# ssh-keygen -l -f ssh_host_rsa_key Write down the command to create a dsa type key called \u201cssh_host_dsa_key\u201d with no comments, and no passphrase?","title":"sshd"},{"location":"labs/security/rocky-lab9-cryptography/#exercise-6","text":"","title":"Exercise 6"},{"location":"labs/security/rocky-lab9-cryptography/#ssh","text":"Usage:- ssh \\[-l login\\_name\\] hostname | user@hostname \\[command\\] ssh \\[-afgknqstvxACNTX1246\\] \\[-b bind\\_address\\] \\[-c cipher\\_spec\\] \\[-e escape\\_char\\] \\[-i identity\\_file\\] \\[-l login\\_name\\] \\[-m mac\\_spec\\] \\[-o option\\] \\[-p port\\] \\[-F configfile\\] \\[-L port:host:hostport\\] \\[-R port:host:hostport\\] \\[-D port\\] hostname | user@hostname \\[command\\] To use ssh Log into serverXY as the user me. Use ssh to connect to serverPR. Type: [me@serverXY me]$ ssh serverPR Type in me\u2019s password when prompted. If you get any warning messages type \u201cyes\u201d to continue. After logging in, create a directory called - myexport and create an empty file. Type: [me@serverPR me]$ mkdir ~/myexport && touch myexport/$$ Make a note of the random file that was created for you, under ~/myexport ? Log off serverPR. Type: [me@serverPR me]$ exit You will be returned to your local shell at serverXY. Use ssh to remotely execute the \u201cls\u201d command to view the list of files in ying\u2019s home directory at serverPR. Type: [me@serverXY me]$ ssh ying@serverPR \u201cls /home/ying\u201d Type in ying\u2019s password when prompted. If you get any warning messages type \u201cyes\u201d to continue. While still logged in as me on serverXY, log into serverPR as the user ying. Type: [me@serverXY me]$ ssh -l ying serverPR Type in ying\u2019s password when prompted. Type \u201cexit\u201d to log off serverPR and return to serverXY. scp scp - secure copy (remote file copy program) scp copies files between hosts on a network. It uses ssh for data transfer, and uses the same authentication and provides the same security as ssh. Usage:- scp \\[-pqrvBC46\\] \\[-F ssh\\_config\\] \\[-S program\\] \\[-P port\\] \\[-c cipher\\] \\[-i identity\\_file\\] \\[-o ssh\\_option\\] \\[\\[user@\\]host1:\\] file1 \\[...\\] \\[\\[user@\\]host2:\\] file2 ``` To use scp 1. Make sure you are still logged in as the user me on serverXY. 2. Create a directory under your home directory called myimport and cd to the directory. 3. Copy over all the files under the \u201c/home/me/myexport/\u201d directory on serverPR. Type: \\[me@serverXY myimports\\]$ ***scp serverPR:/home/me/myexport .*** 4. List the contents of your pwd ? Was that totally cool or what ? 5. What is the command to copy over all the under \u201c/home/me/.gnugp/\u201d on serverPR ? 6. Now copy over all the files under ying\u2019s home directory on serverPR. Type: \\[me@serverXY myimports\\]$ ***scp -r ying@serverPR:/home/ying/\\* .*** # Exercise 7 ## Creating User Public and Private keys for SSH Each individual user that wants to use SSH with RSA or DSA authentication needs a set of public keys and private keys. The ssh-keygen program can be used to create these keys ( just as it was used earlier when you created spare keys for your system) The only \u201cadvised\u201d difference when creating user keys is to also create a passphrase. The passphrase is a password that the is used to encrypt the private key before it is stored on the file system. The public is store in a file with the same file name as the private key but with the extension \u201c.pub\u201d appended to it. There is no way to recover a lost passphrase. If the passphrase is lost or forgotten, a new key must be generated. To create ying\u2019s authentication keys 1. Log into your local machine as the user ying. 2. Run the \u201cssh-keygen\u201d program to create a \u201c***dsa***\u201d type key with the default length. Type: \\[ying@serverXY ying\\]$ ***ssh-keygen -t dsa*** Generating public/private dsa key pair. Press \\[ENTER\\] to accept the default file location. Enter file in which to save the key (/home/ying/.ssh/id\\_dsa): \\[ENTER\\] Enter a very good passphrase when prompted - i.e. one that is difficult to guess. Created directory '/home/ying/.ssh'. Enter passphrase (empty for no passphrase): \\*\\*\\*\\*\\*\\*\\*\\*\\* Enter same passphrase again: \\*\\*\\*\\*\\*\\*\\*\\*\\* Your identification has been saved in /home/ying/.ssh/id\\_dsa. Your public key has been saved in /home/ying/.ssh/id\\_dsa.pub. The key fingerprint is: 61:68:aa:c2:0c:af:9b:49:4a:11:b8:aa:b5:84:18:10 ying@serverXY.example.org 3. cd to your \u201c**~/.ssh/**\u201d directory. List the files in the directory? 4. What is the \u201cssh-keygen\u201d command to view the fingerprint of your keys? 5. Use the cat command to view the contents of your public-key file (i.e. \u201c**~/.ssh/id\\_rsa.pub**\u201d). # Exercise 8 ## Authenticating via Public-Key Thus far you have been using a password based authentication scheme to log into user accounts at serverPR. This means that, you had to have known the corresponding account\u2019s password on the remote side to have been able to log in successfully. In this exercise you will configure public-key authentication between your user account on serverXY and the ying\u2019s user account at serverPR. To configure public-key authentication 1. Log into your local system as the user ying. 2. cd to your \u201c~/.ssh\u201d directory. 3. Type in the horrible looking command below: \\[ying@serverXY .ssh\\]$ ***cat id\\_dsa.pub | ssh ying@serverPR \\\\*** '(cd ~/.ssh && cat - &gt;&gt; authorized\\_keys && chmod 600 authorized\\_keys)' The above command reads: a. cat the contents of your dsa public-key file, but send the out to the pipe ( | ) instead of the usual standard out. b. run the command \u201c***cd ~/.ssh && cat - &gt;&gt; authorized\\_keys && chmod 600 authorized\\_keys\u201d*** as the user ying on serverPR. c. The whole point of the command is simply to copy and append the contents of your public-key file to the \u201c/home/ying/.ssh/authorized\\_keys\u201d on serverPR and give it the correct permissions. If you know of any other manual way to achieve the same result, please do so. 4. After you have added your public-key to the authorized\\_keys file on the remote system. Attempt to login to serverPR as ying via ssh. Type: \\[ying@serverXY .ssh\\]$ ***ssh serverPR*** Enter passphrase for key '/home/ying/.ssh/id\\_dsa': \\*\\*\\*\\*\\*\\*\\*\\*\\*\\* Note very carefully that, you are being prompted for your passphrase this time instead of the password. Enter the passphrase you created earlier when you created your keys. 5. After successfully logging into serverPR; Log back out. # Exercise 9 ## ssh-agent According to the man page - ssh-agent is a program to hold private keys used for public key authentication (RSA, DSA). The idea is that ssh-agent is started in the beginning of an X-session or a login session, and all other windows or programs are started as clients to the ssh-agent program. Through use of environment variables the agent can be located and automatically used for authentication when logging into other machines using ssh. Usage ssh-agent [-a bind_address] [-c | -s] [-d] [command [args ...]] ssh-agent [-c | -s] -k ``` In this exercise you will learn how to configure the agent such that you wont have to type in your passphrase every time you want to connect to another system using public-key authentication. Make sure you are logged into your local system as the user ying. Type in the command below: [ying@serverXY .ssh]$ eval `ssh-agent` Agent pid 5623 Take note of the PID of the agent: Use the \u201c ssh-add \u201d program to add your keys to the agent you launched above. Type: [ying@serverXY .ssh]$ ssh-add Enter your passphrase when prompted. Enter passphrase for /home/ying/.ssh/id_dsa: Identity added: /home/ying/.ssh/id_dsa (/home/ying/.ssh/id_dsa) Now connect to serverPR as the user ying. You WILL NOT be prompted for a password or passphrase (i.e if everything has been done correctly). Type: [ying@serverXY .ssh]$ ssh serverPR Enjoy.","title":"ssh"}]}; var __search = { index: Promise.resolve(local_index) }